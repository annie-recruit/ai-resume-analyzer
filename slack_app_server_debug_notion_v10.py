import os
import json
import requests
import logging
from flask import Flask, request, jsonify, make_response
from docx import Document
from openai import OpenAI
from notion_client import Client
import PyPDF2
import io
from datetime import datetime
from io import BytesIO
import fitz
import matplotlib
matplotlib.use('Agg')  # ë°˜ë“œì‹œ plt import ì „ì— ì„¤ì •í•´ì•¼ í•¨
import matplotlib.pyplot as plt
import matplotlib.font_manager as fm
import numpy as np
from wordcloud import WordCloud
import base64
import re
import plotly.graph_objects as go
import plotly.io as pio
from plotly.subplots import make_subplots
import tempfile
from slack_sdk import WebClient
from slack_sdk.errors import SlackApiError
import math
from reportlab.lib.pagesizes import A4
from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Table, TableStyle, Image as RLImage
from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
from reportlab.lib.units import inch
from reportlab.lib import colors
from reportlab.pdfbase import pdfmetrics
from reportlab.pdfbase.ttfonts import TTFont
from PIL import Image
import hashlib
import pickle
# ìŠ¤í¬ë˜í•‘ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì¶”ê°€
from bs4 import BeautifulSoup
import time
from urllib.parse import urljoin, quote
from collections import Counter
# Selenium ì¶”ê°€
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from webdriver_manager.chrome import ChromeDriverManager
import threading

# Configure logging
logging.basicConfig(level=logging.DEBUG, format='%(asctime)s - %(levelname)s - %(message)s')

# í•œê¸€ í°íŠ¸ ì„¤ì •
font_path = 'C:/Windows/Fonts/malgun.ttf'  # ë§‘ì€ ê³ ë”• í°íŠ¸ ê²½ë¡œ
font_prop = fm.FontProperties(fname=font_path)
plt.rcParams['font.family'] = 'Malgun Gothic'
plt.rcParams['axes.unicode_minus'] = False

# API í‚¤ ë° í† í°ì„ í™˜ê²½ë³€ìˆ˜ì—ì„œ ê°€ì ¸ì˜¤ê¸°
SLACK_BOT_TOKEN = os.getenv("SLACK_BOT_TOKEN", "your-slack-bot-token-here")
GPT_API_KEY = os.getenv("GPT_API_KEY", "your-openai-api-key-here")
NOTION_DATABASE_ID = os.getenv("NOTION_DATABASE_ID", "your-notion-database-id-here")
NOTION_TOKEN = os.getenv("NOTION_TOKEN", "your-notion-token-here")
JD_STORAGE_FILE = "stored_jd.pkl"  # JD ë°ì´í„° ì €ì¥ íŒŒì¼

# Notion í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
notion = Client(auth=NOTION_TOKEN)

# Slack WebClient ì´ˆê¸°í™”
client = WebClient(token=SLACK_BOT_TOKEN)

# JD ë°ì´í„° ì €ì¥/ë¶ˆëŸ¬ì˜¤ê¸° í•¨ìˆ˜ë“¤
def save_jd_data():
    """JD ë°ì´í„°ë¥¼ íŒŒì¼ë¡œ ì €ì¥"""
    try:
        with open(JD_STORAGE_FILE, 'wb') as f:
            pickle.dump(stored_jd, f)
        logging.info(f"JD data saved to {JD_STORAGE_FILE}")
    except Exception as e:
        logging.error(f"Failed to save JD data: {str(e)}")

def load_jd_data():
    """íŒŒì¼ì—ì„œ JD ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ê¸°"""
    try:
        if os.path.exists(JD_STORAGE_FILE):
            with open(JD_STORAGE_FILE, 'rb') as f:
                data = pickle.load(f)
            logging.info(f"JD data loaded from {JD_STORAGE_FILE}")
            return data
        else:
            logging.info("No existing JD data file found")
            return {}
    except Exception as e:
        logging.error(f"Failed to load JD data: {str(e)}")
        return {}

# Global variables for PDF generation and JD storage
last_analysis_result = None
last_analysis_user_id = None
stored_jd = load_jd_data()  # ì‹œì‘ ì‹œ ì €ì¥ëœ JD ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
processed_messages = set()  # ì²˜ë¦¬ëœ ë©”ì‹œì§€ ID ìºì‹œ
user_last_message = {}  # ì‚¬ìš©ìë³„ ë§ˆì§€ë§‰ ë©”ì‹œì§€ ì¶”ì : {user_id: (timestamp, message_hash)}

SLACK_HEADERS = {
    "Authorization": f"Bearer {SLACK_BOT_TOKEN}",
    "Content-Type": "application/json"
}

app = Flask(__name__)

def get_message_hash(user_id, text, timestamp):
    """ë©”ì‹œì§€ì˜ ê³ ìœ  í•´ì‹œ ìƒì„±"""
    content = f"{user_id}:{text[:100]}:{timestamp}"  # ì‚¬ìš©ìID:í…ìŠ¤íŠ¸100ì:íƒ€ì„ìŠ¤íƒ¬í”„
    return hashlib.md5(content.encode()).hexdigest()

def send_dm(user_id, text, blocks=None, file_url=None):
    """ ìŠ¬ë™ DM + ë²„íŠ¼ ì˜µì…˜ """
    payload = {
        "channel": user_id,
        "text": text,
    }
    
    if blocks:
        payload["blocks"] = blocks
        
    if file_url:
        # ì‚¬ìš©ìì—ê²Œ ë“±ë¡ëœ JD ëª©ë¡ í™•ì¸
        user_jds = []
        if user_id in stored_jd:
            user_jds = [jd_name for jd_name in stored_jd[user_id].keys() 
                       if not jd_name.startswith("_")]
        
        if len(user_jds) == 0:
            # JDê°€ ì—†ëŠ” ê²½ìš° ê¸°ë³¸ ë²„íŠ¼
            payload["attachments"] = [{
                "text": "ì•„ë˜ ë²„íŠ¼ì„ ëˆŒëŸ¬ ë¶„ì„ì„ ì‹œì‘í• ê¹Œìš”?",
                "fallback": "ë¶„ì„ì„ ì‹œì‘í• ê¹Œìš”?",
                "callback_id": "resume_analysis",
                "color": "#3AA3E3",
                "actions": [
                    {
                        "name": "analyze_resume",
                        "text": "ë¶„ì„í•´ì¤˜!",
                        "type": "button",
                        "value": file_url,
                        "style": "primary"
                    },
                    {
                        "name": "download_resume",
                        "text": "ì´ë ¥ì„œ ë‹¤ìš´ë¡œë“œ",
                        "type": "button",
                        "url": file_url,
                        "style": "default"
                    }
                ]
            }]
        elif len(user_jds) == 1:
            # JDê°€ 1ê°œì¸ ê²½ìš° ìë™ ì„ íƒ
            jd_name = user_jds[0]
            payload["attachments"] = [{
                "text": f"ë“±ë¡ëœ JD: **{jd_name}**",
                "fallback": "ë¶„ì„ì„ ì‹œì‘í• ê¹Œìš”?",
                "callback_id": "resume_analysis",
                "color": "#3AA3E3",
                "actions": [
                    {
                        "name": "analyze_resume_with_jd",
                        "text": "ë¶„ì„í•´ì¤˜!",
                        "type": "button",
                        "value": f"{file_url}|{jd_name}",
                        "style": "primary"
                    },
                    {
                        "name": "download_resume",
                        "text": "ì´ë ¥ì„œ ë‹¤ìš´ë¡œë“œ",
                        "type": "button",
                        "url": file_url,
                        "style": "default"
                    }
                ]
            }]
        else:
            # JDê°€ ì—¬ëŸ¬ê°œì¸ ê²½ìš° ë“œë¡­ë‹¤ìš´ ì„ íƒ
            jd_options = []
            for jd_name in user_jds:
                jd_options.append({
                    "text": jd_name,
                    "value": f"{file_url}|{jd_name}"
                })
            
            payload["attachments"] = [{
                "text": "ë¶„ì„í•  JDë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”:",
                "fallback": "ë¶„ì„ì„ ì‹œì‘í• ê¹Œìš”?",
                "callback_id": "resume_analysis",
                "color": "#3AA3E3",
                "actions": [
                    {
                        "name": "select_jd_for_analysis",
                        "text": "JD ì„ íƒ í›„ ë¶„ì„",
                        "type": "select",
                        "options": jd_options,
                        "style": "primary"
                    },
                    {
                        "name": "analyze_resume",
                        "text": "JD ì—†ì´ ë¶„ì„",
                        "type": "button",
                        "value": file_url,
                        "style": "default"
                    },
                    {
                        "name": "download_resume",
                        "text": "ì´ë ¥ì„œ ë‹¤ìš´ë¡œë“œ",
                        "type": "button",
                        "url": file_url,
                        "style": "default"
                    }
                ]
            }]
    
    res = requests.post(
        "https://slack.com/api/chat.postMessage", 
        headers=SLACK_HEADERS, 
        json=payload  # data=json.dumps(payload) ëŒ€ì‹  json=payload ì‚¬ìš©
    )
    print("DM ì „ì†¡ê²°ê³¼:", res.status_code, res.text)

def search_notion_db(query):
    """Notion DBì—ì„œ ê²€ìƒ‰ì„ ìˆ˜í–‰í•˜ëŠ” í•¨ìˆ˜"""
    try:
        # ê²€ìƒ‰ í•„í„° ì„¤ì •
        filter_conditions = {
            "or": [
                {
                    "property": "ì„±ëª…",
                    "title": {
                        "contains": query
                    }
                },
                {
                    "property": "ê°•ì  Top3",
                    "rich_text": {
                        "contains": query
                    }
                },
                {
                    "property": "ì—­ëŸ‰ì¹´ë“œ ìš”ì•½",
                    "rich_text": {
                        "contains": query
                    }
                }
            ]
        }
        
        # Notion DB ê²€ìƒ‰ ì‹¤í–‰
        results = notion.databases.query(
            database_id=NOTION_DATABASE_ID,
            filter=filter_conditions
        )
        
        return results.get('results', [])
    except Exception as e:
        logging.error(f"Notion DB ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return []

def create_search_result_blocks(notion_page):
    """ê²€ìƒ‰ ê²°ê³¼ë¥¼ Slack ë¸”ë¡ìœ¼ë¡œ ë³€í™˜"""
    try:
        if not notion_page or 'id' not in notion_page:
            logging.error("Invalid notion_page object or missing ID")
            return None
            
        blocks = []
        
        # ì œëª© ì„¹ì…˜
        blocks.append({
            "type": "header",
            "text": {
                "type": "plain_text",
                "text": notion_page.get('properties', {}).get('ì´ë¦„', {}).get('title', [{}])[0].get('text', {}).get('content', 'ì œëª© ì—†ìŒ'),
                "emoji": True
            }
        })
        
        # ì£¼ìš” ì„¹ì…˜ë“¤ ì¶”ê°€
        sections = ['ê¸°ìˆ ìŠ¤íƒ', 'ê²½ë ¥ê¸°ê°„', 'ì£¼ìš”ì—…ë¬´']
        for section in sections:
            content = notion_page.get('properties', {}).get(section, {}).get('rich_text', [{}])[0].get('text', {}).get('content', '')
            if content:
                blocks.append({
                    "type": "section",
                    "text": {
                        "type": "mrkdwn",
                        "text": f"*{section}*\n{content}"
                    }
                })
        
        # Notion í˜ì´ì§€ ë§í¬ ë²„íŠ¼ ì¶”ê°€
        page_id = notion_page['id'].replace('-', '')
        blocks.extend([
            {
                "type": "divider"
            },
            {
                "type": "actions",
                "elements": [
                    {
                        "type": "button",
                        "text": {
                            "type": "plain_text",
                            "text": "ğŸ“š Notionì—ì„œ ìì„¸íˆ ë³´ê¸°",
                            "emoji": True
                        },
                        "url": f"https://www.notion.so/{page_id}",
                        "style": "primary"
                    }
                ]
            }
        ])
        
        return blocks
    except Exception as e:
        logging.error(f"ê²€ìƒ‰ ê²°ê³¼ ë¸”ë¡ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return None

@app.route("/slack/events", methods=["GET", "POST"])
def slack_events():
    # GET ìš”ì²­ ì²˜ë¦¬ (URL ê²€ì¦ìš©)
    if request.method == "GET":
        return "OK"
        
    # POST ìš”ì²­ ì²˜ë¦¬
    try:
        # Content-Type í™•ì¸ ë° ë°ì´í„° íŒŒì‹±
        content_type = request.headers.get('Content-Type', '')
        logging.info(f"Received request with Content-Type: {content_type}")
        
        if content_type.startswith('application/json'):
            data = request.get_json()
        elif content_type.startswith('application/x-www-form-urlencoded'):
            # form ë°ì´í„°ì—ì„œ payload ì¶”ì¶œ ë° JSON íŒŒì‹±
            form_data = request.form
            if 'payload' in form_data:
                data = json.loads(form_data['payload'])
            else:
                data = {k: v for k, v in form_data.items()}
        else:
            logging.error(f"Unsupported Content-Type: {content_type}")
            return jsonify({"error": "Unsupported Content-Type"}), 400
            
        if not data:
            logging.error("Empty request data")
            return jsonify({"error": "Empty request"}), 400
        
        logging.info(f"Received event data: {json.dumps(data, indent=2)}")
        
        # Interactive Message ì²˜ë¦¬
        if data.get("type") == "interactive_message":
            return handle_interactive_message(data)
        
        # URL ê²€ì¦ ì²˜ë¦¬
        if "challenge" in data:
            logging.info(f"Handling URL verification: {data['challenge']}")
            return jsonify({
                "challenge": data["challenge"]
            })
        
        # ì´ë²¤íŠ¸ íƒ€ì… í™•ì¸
        if "event" not in data:
            logging.error("No event in data")
            return jsonify({"error": "No event"}), 400
        
        event = data.get("event", {})
        event_type = event.get("type")
        logging.info(f"Processing event type: {event_type}")
        
        # íŒŒì¼ ê³µìœ  ì´ë²¤íŠ¸ ì²˜ë¦¬
        if event_type == "file_shared":
            try:
                file_id = event["file_id"]
                user_id = event["user_id"]
                logging.info(f"File shared - file_id: {file_id}, user_id: {user_id}")

                # íŒŒì¼ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
                info = requests.get(
                    f"https://slack.com/api/files.info?file={file_id}",
                    headers=SLACK_HEADERS
                ).json()
                
                if not info.get("ok"):
                    logging.error(f"Failed to get file info: {info.get('error')}")
                    return make_response("", 200)

                # ë´‡ì´ ì—…ë¡œë“œí•œ íŒŒì¼ì€ ë¬´ì‹œ
                uploader_id = info["file"].get("user")
                if uploader_id == "U08TYB64MD3":  # ë´‡ ID
                    logging.info("Ignoring file uploaded by resume-bot")
                    return make_response("", 200)

                file_url = info["file"]["url_private_download"]
                send_dm(user_id, ":page_facing_up: ìƒˆ ì´ë ¥ì„œê°€ ì—…ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤. ë¶„ì„ì„ ì‹œì‘í• ê¹Œìš”?", file_url=file_url)
                
            except Exception as e:
                logging.error(f"Error processing file_shared event: {str(e)}")
                return make_response("", 200)
                
        # ë©”ì‹œì§€ ì´ë²¤íŠ¸ ì²˜ë¦¬
        elif event_type == "message" and event.get("channel_type") == "im":
            try:
                # ë©”ì‹œì§€ ì¤‘ë³µ ì²˜ë¦¬ ë°©ì§€
                message_id = event.get("ts")
                if message_id in processed_messages:
                    logging.info(f"Message {message_id} already processed, skipping")
                    return make_response("", 200)
                
                # ë´‡ ë©”ì‹œì§€ ë¬´ì‹œ (ê°•í™”ëœ í•„í„°ë§)
                if event.get("bot_id") or event.get("subtype") == "bot_message":
                    logging.info("Ignoring bot message")
                    return make_response("", 200)
                    
                user_id = event.get("user")
                
                # ë´‡ ìì‹ ì˜ ë©”ì‹œì§€ ë¬´ì‹œ (ì‚¬ìš©ì IDë¡œ ì¶”ê°€ í™•ì¸)
                if user_id == "U08TYB64MD3":  # ë´‡ì˜ ì‚¬ìš©ì ID
                    logging.info("Ignoring message from bot user")
                    return make_response("", 200)
                
                # ì‚¬ìš©ì IDê°€ ì—†ëŠ” ê²½ìš° ë¬´ì‹œ
                if not user_id:
                    logging.info("No user ID in message event")
                    return make_response("", 200)
                
                text = event.get("text", "").strip()
                timestamp = float(message_id)
                
                # ë©”ì‹œì§€ í•´ì‹œ ìƒì„±
                message_hash = get_message_hash(user_id, text, message_id)
                
                # ì‚¬ìš©ìë³„ ì¤‘ë³µ ë©”ì‹œì§€ ì²´í¬ (ë” ê°•í™”ëœ ë¡œì§)
                if user_id in user_last_message:
                    last_timestamp, last_hash = user_last_message[user_id]
                    # ê°™ì€ í•´ì‹œì´ê±°ë‚˜ 5ì´ˆ ì´ë‚´ ì¤‘ë³µ ë©”ì‹œì§€ì¸ ê²½ìš° ë¬´ì‹œ
                    if message_hash == last_hash or (timestamp - last_timestamp < 5):
                        logging.info(f"Duplicate message from user {user_id}, skipping. Hash: {message_hash}")
                        return make_response("", 200)
                
                # ì‚¬ìš©ìë³„ ë§ˆì§€ë§‰ ë©”ì‹œì§€ ì—…ë°ì´íŠ¸
                user_last_message[user_id] = (timestamp, message_hash)
                
                # ë©”ì‹œì§€ë¥¼ ì²˜ë¦¬ëœ ëª©ë¡ì— ì¶”ê°€
                processed_messages.add(message_id)
                
                # ìºì‹œ í¬ê¸° ì œí•œ (ìµœê·¼ 1000ê°œ ë©”ì‹œì§€ë§Œ ìœ ì§€)
                if len(processed_messages) > 1000:
                    # ê°€ì¥ ì˜¤ë˜ëœ 500ê°œ ì œê±°
                    old_messages = list(processed_messages)[:500]
                    for old_msg in old_messages:
                        processed_messages.discard(old_msg)
                
                logging.info(f"Processing message - user_id: {user_id}, hash: {message_hash}, text: {text[:50]}...")
                
                # JD ë“±ë¡ í‚¤ì›Œë“œ ê°ì§€
                jd_registration_keywords = ["jd ë“±ë¡", "JD ë“±ë¡", "jdë“±ë¡", "JDë“±ë¡", "jd ë“±ë¡í•˜ê¸°", "JD ë“±ë¡í•˜ê¸°"]
                if any(keyword in text for keyword in jd_registration_keywords):
                    trigger_jd_registration(user_id)
                    return make_response("", 200)
                
                # JD ëª©ë¡ ì¡°íšŒ í‚¤ì›Œë“œ ê°ì§€
                jd_list_keywords = ["jd ëª©ë¡", "JD ëª©ë¡", "ë“±ë¡ëœ jd", "ë“±ë¡ëœ JD", "jdë¦¬ìŠ¤íŠ¸", "JDë¦¬ìŠ¤íŠ¸", "jd ë¦¬ìŠ¤íŠ¸", "JD ë¦¬ìŠ¤íŠ¸"]
                if any(keyword in text for keyword in jd_list_keywords):
                    user_jds = []
                    if user_id in stored_jd:
                        user_jds = [jd_name for jd_name in stored_jd[user_id].keys() 
                                   if not jd_name.startswith("_")]
                    
                    if user_jds:
                        jd_list_message = f"ğŸ“‹ **ë“±ë¡ëœ JD ëª©ë¡** ({len(user_jds)}ê°œ):\n\n"
                        for i, jd_name in enumerate(user_jds, 1):
                            jd_list_message += f"{i}. {jd_name}\n"
                        jd_list_message += "\nğŸ’¡ ì´ë ¥ì„œë¥¼ ì—…ë¡œë“œí•˜ë©´ ë“±ë¡ëœ JDì™€ ë§¤ì¹­ ë¶„ì„ì„ ì‹¤ì‹œí•©ë‹ˆë‹¤!"
                        send_dm(user_id, jd_list_message)
                    else:
                        send_dm(user_id, "ğŸ“‹ ë“±ë¡ëœ JDê°€ ì—†ìŠµë‹ˆë‹¤.\n\n\"JD ë“±ë¡í•˜ê¸°\"ë¼ê³  ë§ì”€í•´ì£¼ì‹œë©´ ìƒˆë¡œìš´ JDë¥¼ ë“±ë¡í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
                    return make_response("", 200)
                
                # JD ë“±ë¡ í”„ë¡œì„¸ìŠ¤ ì²˜ë¦¬
                if user_id in stored_jd and stored_jd[user_id].get("_registration_mode"):
                    mode = stored_jd[user_id]["_registration_mode"]
                    
                    if mode == "waiting_for_jd_name":
                        # JD ì´ë¦„ ì €ì¥í•˜ê³  ë‹¤ìŒ ë‹¨ê³„ë¡œ
                        jd_name = text.strip()
                        if len(jd_name) > 50:
                            send_dm(user_id, "âŒ JD ì´ë¦„ì´ ë„ˆë¬´ ê¹ë‹ˆë‹¤. 50ì ì´ë‚´ë¡œ ì…ë ¥í•´ì£¼ì„¸ìš”.")
                            return make_response("", 200)
                        
                        stored_jd[user_id]["_pending_jd_name"] = jd_name
                        stored_jd[user_id]["_registration_mode"] = "waiting_for_jd_content"
                        
                        send_dm(user_id, f"âœ… JD ì´ë¦„: **{jd_name}**\n\nì´ì œ ì±„ìš©ê³µê³  ì „ë¬¸ì„ ë³µì‚¬í•´ì„œ ë³´ë‚´ì£¼ì„¸ìš”.")
                        return make_response("", 200)
                    
                    elif mode == "waiting_for_jd_content":
                        # JD ë‚´ìš© ë¶„ì„í•˜ê³  ì €ì¥
                        jd_content = text.strip()
                        if len(jd_content) < 100:
                            send_dm(user_id, "âŒ ì±„ìš©ê³µê³  ë‚´ìš©ì´ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤. ë” ìì„¸í•œ ë‚´ìš©ì„ ë³´ë‚´ì£¼ì„¸ìš”. (ìµœì†Œ 100ì)")
                            return make_response("", 200)
                        
                        send_dm(user_id, "ğŸ“‹ ì±„ìš©ê³µê³ ë¥¼ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤...")
                        
                        # JD ë¶„ì„
                        jd_data = analyze_jd(jd_content)
                        if jd_data:
                            jd_name = stored_jd[user_id]["_pending_jd_name"]
                            
                            # JD ì €ì¥
                            if user_id not in stored_jd:
                                stored_jd[user_id] = {}
                            stored_jd[user_id][jd_name] = jd_data
                            
                            # íŒŒì¼ë¡œ ì €ì¥
                            save_jd_data()
                            
                            # ë“±ë¡ ëª¨ë“œ ì •ë¦¬
                            if "_registration_mode" in stored_jd[user_id]:
                                del stored_jd[user_id]["_registration_mode"]
                            if "_pending_jd_name" in stored_jd[user_id]:
                                del stored_jd[user_id]["_pending_jd_name"]
                            
                            # JD ë¶„ì„ ê²°ê³¼ ì „ì†¡
                            blocks = create_jd_analysis_blocks(jd_data, jd_name)
                            send_dm(user_id, f"âœ… **{jd_name}** JDê°€ ì„±ê³µì ìœ¼ë¡œ ë“±ë¡ë˜ì—ˆìŠµë‹ˆë‹¤!", blocks=blocks)
                        else:
                            send_dm(user_id, "âŒ ì±„ìš©ê³µê³  ë¶„ì„ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
                        
                        return make_response("", 200)
                
                # ì¼ë°˜ ê²€ìƒ‰ ë° ë„ì›€ë§
                results = search_notion_db(text)
                
                if not results:
                    # ë“±ë¡ëœ JD ëª©ë¡ í‘œì‹œ
                    user_jds = []
                    if user_id in stored_jd:
                        user_jds = [jd_name for jd_name in stored_jd[user_id].keys() 
                                   if not jd_name.startswith("_")]
                    
                    jd_list_text = ""
                    if user_jds:
                        jd_list_text = f"\n\nğŸ“‹ **ë“±ë¡ëœ JD ëª©ë¡**: {', '.join(user_jds)}"
                    
                    help_message = f"""
ğŸ¤– **ì‚¬ìš© ë°©ë²•**:

1. **JD ë“±ë¡**: "JD ë“±ë¡í•˜ê¸°" ë¼ê³  ë§í•´ì£¼ì„¸ìš”
2. **ì´ë ¥ì„œ ë¶„ì„**: ì´ë ¥ì„œ ë³´ê´€ ì±„ë„ì— íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”
3. **ê²€ìƒ‰**: í‚¤ì›Œë“œë¡œ ê¸°ì¡´ ë¶„ì„ ê²°ê³¼ë¥¼ ê²€ìƒ‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤{jd_list_text}

ğŸ’¡ JDë¥¼ ë¨¼ì € ë“±ë¡í•˜ë©´ ì´ë ¥ì„œ ë¶„ì„ ì‹œ ë§¤ì¹­ ì ìˆ˜ë„ í•¨ê»˜ ì œê³µë©ë‹ˆë‹¤!
                    """
                    send_dm(user_id, help_message.strip())
                    return make_response("", 200)
                    
                # ê²€ìƒ‰ ê²°ê³¼ ì „ì†¡
                for page in results[:3]:  # ìµœëŒ€ 3ê°œ ê²°ê³¼ë§Œ í‘œì‹œ
                    blocks = create_search_result_blocks(page)
                    if blocks:
                        send_dm(user_id, f"ğŸ” '{text}' ê²€ìƒ‰ ê²°ê³¼ì…ë‹ˆë‹¤.", blocks=blocks)
                    else:
                        send_dm(user_id, "âŒ ê²€ìƒ‰ ê²°ê³¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
                        
            except Exception as e:
                logging.error(f"Error processing message event: {str(e)}")
                return make_response("", 200)
                
        # DMì—ì„œ "ëŒ€ì‹œë³´ë“œ" ë˜ëŠ” "dashboard" í‚¤ì›Œë“œ ê°ì§€
        if event.get("channel_type") == "im" and ("ëŒ€ì‹œë³´ë“œ" in text or "dashboard" in text.lower()):
            send_dm(user_id, "ğŸ’¡ ëŒ€ì‹œë³´ë“œ ê¸°ëŠ¥ì„ ì‚¬ìš©í•˜ë ¤ë©´ `/dashboard` ìŠ¬ë˜ì‹œ ëª…ë ¹ì–´ë¥¼ ì‚¬ìš©í•´ì£¼ì„¸ìš”!")
            return "OK"
                
    except Exception as e:
        logging.error(f"Error processing request: {str(e)}")
        return make_response("", 200)
    
    return make_response("", 200)

def handle_interactive_message(data):
    # Global variables for PDF generation
    global last_analysis_result, last_analysis_user_id
    
    logging.debug("Handling interactive message: %s", data)
    try:
        # Extract user ID and file URL
        user_id = data["user"]["id"]
        actions = data.get("actions", [])
        if not actions:
            logging.error("No actions in interactive message")
            return make_response("", 200)
        
        action = actions[0]
        action_name = action.get("name")
        
        if action_name == "analyze_resume":
            # JD ì—†ì´ ì´ë ¥ì„œë§Œ ë¶„ì„
            file_url = action.get("value")
            if not file_url:
                logging.error("No file URL in action")
                return make_response("", 200)
            
            logging.debug("Processing resume for user %s with file %s", user_id, file_url)
            perform_complete_analysis(user_id, file_url)
                
        elif action_name == "analyze_resume_with_jd":
            # JD 1ê°œê°€ ìˆëŠ” ê²½ìš° (ìë™ ì„ íƒ)
            value = action.get("value")
            if not value or "|" not in value:
                logging.error("Invalid value format for JD analysis")
                return make_response("", 200)
            
            file_url, jd_name = value.split("|", 1)
            logging.debug("Processing resume with JD for user %s, file %s, JD %s", user_id, file_url, jd_name)
            perform_complete_analysis(user_id, file_url, jd_name)
            
        elif action_name == "select_jd_for_analysis":
            # ë“œë¡­ë‹¤ìš´ì—ì„œ JD ì„ íƒí•œ ê²½ìš°
            selected_option = action.get("selected_options", [{}])[0]
            value = selected_option.get("value")
            if not value or "|" not in value:
                logging.error("Invalid selection value")
                return make_response("", 200)
            
            file_url, jd_name = value.split("|", 1)
            logging.debug("Processing resume with selected JD for user %s, file %s, JD %s", user_id, file_url, jd_name)
            perform_complete_analysis(user_id, file_url, jd_name)
            
        else:
            # ê¸°ë³¸ì ìœ¼ë¡œ ê¸°ì¡´ ë¡œì§ ìˆ˜í–‰ (ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ ë“±)
            logging.debug("Handling other action: %s", action_name)
        
        return make_response("", 200)
        
    except Exception as e:
        logging.error("Error in handle_interactive_message: %s", str(e), exc_info=True)
        try:
            user_id = data.get("user", {}).get("id")
            if user_id:
                send_dm(user_id, "âŒ ì´ë ¥ì„œ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
        except:
            pass
        return make_response("", 200)

@app.route("/slack/interact", methods=["POST", "GET"])
def slack_interact():
    # Global variables for PDF generation
    global last_analysis_result, last_analysis_user_id
    
    if request.method == "GET":
        return "OK"
    
    try:
        # Content-Type í™•ì¸ ë° ë°ì´í„° íŒŒì‹±
        content_type = request.headers.get('Content-Type', '')
        
        if content_type.startswith('application/json'):
            data = request.get_json()
        elif content_type.startswith('application/x-www-form-urlencoded'):
            form_data = request.form
            if 'payload' in form_data:
                data = json.loads(form_data['payload'])
            else:
                # ìŠ¬ë˜ì‹œ ëª…ë ¹ì–´ëŠ” /slack/commandsë¡œ ë¼ìš°íŒ…ë˜ì–´ì•¼ í•¨
                return jsonify({"error": "Use /slack/commands for slash commands"}), 400
        else:
            return jsonify({"error": "Unsupported Content-Type"}), 400
        
        if not data:
            return jsonify({"error": "Empty request"}), 400
        
        # Modal submission ì²˜ë¦¬
        if data.get("type") == "view_submission":
            return handle_modal_submission(data)
        
        # ë²„íŠ¼ í´ë¦­ ì²˜ë¦¬ (ê¸°ì¡´ ì½”ë“œ ë³µì›)
        if data.get("type") == "interactive_message":
            return handle_interactive_message(data)
        
        # Block actions ì²˜ë¦¬ (PDF ìƒì„± ë“±)
        if data.get("type") == "block_actions":
            try:
                user_id = data.get("user", {}).get("id")
                if not user_id:
                    raise ValueError("User ID not found in payload")
                
                actions = data.get("actions", [])
                if actions:
                    action = actions[0]
                    action_id = action.get("action_id")
                    
                    if action_id == "generate_pdf_report":
                        # PDF ë³´ê³ ì„œ ìƒì„±
                        try:
                            if last_analysis_result is None:
                                send_dm(user_id, "âŒ ë¶„ì„ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ì´ë ¥ì„œë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”.")
                                return make_response("", 200)
                            
                            # ê¸°ìˆ  ìŠ¤í‚¬ ì°¨íŠ¸ ì¬ìƒì„±
                            tech_skills = last_analysis_result.get("skill_cards", {}).get("tech_skills", "")
                            skills_dict = parse_skills(tech_skills)
                            chart_image = None
                            
                            if skills_dict:
                                chart_image = create_plotly_radar_chart(skills_dict)
                            
                            # PDF ìƒì„±
                            pdf_bytes = create_pdf_report(last_analysis_result, chart_image)
                            
                            if pdf_bytes:
                                # DM ì±„ë„ ID ê°€ì ¸ì˜¤ê¸°
                                dm_response = client.conversations_open(users=[user_id])
                                if dm_response.get("ok"):
                                    dm_channel_id = dm_response["channel"]["id"]
                                    
                                    # PDF ì—…ë¡œë“œ
                                    temp_pdf_file = f"resume_analysis_report_{user_id}.pdf"
                                    with open(temp_pdf_file, 'wb') as f:
                                        f.write(pdf_bytes)
                                    
                                    upload_response = client.files_upload_v2(
                                        channel=dm_channel_id,
                                        title="ì´ë ¥ì„œ ë¶„ì„ ë³´ê³ ì„œ",
                                        filename="resume_analysis_report.pdf",
                                        file=temp_pdf_file,
                                        initial_comment="ğŸ“Š ì´ë ¥ì„œ ë¶„ì„ ë³´ê³ ì„œê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤!"
                                    )
                                    
                                    # ì„ì‹œ íŒŒì¼ ì‚­ì œ
                                    if os.path.exists(temp_pdf_file):
                                        os.remove(temp_pdf_file)
                                    
                                    if upload_response.get("file"):
                                        logging.info("PDF report uploaded successfully")
                                else:
                                    send_dm(user_id, "âŒ DM ì±„ë„ ì •ë³´ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                            else:
                                send_dm(user_id, "âŒ PDF ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
                        
                        except Exception as e:
                            logging.error(f"PDF generation error: {str(e)}")
                            send_dm(user_id, f"âŒ PDF ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
                        
                        return make_response("", 200)
                    
                    elif action_id == "refresh_market_data":
                        # ì‹œì¥ ë°ì´í„° ìƒˆë¡œê³ ì¹¨
                        try:
                            # ì‚¬ìš©ìì—ê²Œ ë¡œë”© ë©”ì‹œì§€ ì „ì†¡
                            send_dm(user_id, "ğŸ”„ ì‹¤ì‹œê°„ ì±„ìš© ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ê³  ìˆìŠµë‹ˆë‹¤... (ì•½ 10ì´ˆ ì†Œìš”)")
                            
                            # ì—…ë°ì´íŠ¸ëœ Modal ìƒì„± (ê°•ì œ ìŠ¤í¬ë˜í•‘ ì‹¤í–‰)
                            updated_modal = create_market_intelligence_modal(force_scraping=True)
                            
                            # Modal ì—…ë°ì´íŠ¸
                            response = client.views_update(
                                view_id=data["view"]["id"],
                                hash=data["view"]["hash"],
                                view=updated_modal
                            )
                            
                            if response.get("ok"):
                                logging.info("Market intelligence modal refreshed successfully")
                                send_dm(user_id, "âœ… ìµœì‹  ì±„ìš© ì‹œì¥ ë°ì´í„°ë¡œ ì—…ë°ì´íŠ¸ ì™„ë£Œ!")
                            else:
                                logging.error(f"Failed to refresh modal: {response}")
                                send_dm(user_id, "âŒ ë°ì´í„° ìƒˆë¡œê³ ì¹¨ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
                            
                        except Exception as e:
                            logging.error(f"Market data refresh error: {str(e)}")
                            send_dm(user_id, f"âŒ ë°ì´í„° ìƒˆë¡œê³ ì¹¨ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
                        
                        return make_response("", 200)
                
                return make_response("", 200)
                
            except Exception as e:
                logging.error(f"Error handling block actions: {str(e)}")
                return make_response("", 200)
            
        return make_response("", 200)
        
    except Exception as e:
        logging.error(f"Error in slack_interact: {str(e)}")
        return make_response("", 500)

# ìŠ¬ë˜ì‹œ ëª…ë ¹ì–´ ì²˜ë¦¬ í•¨ìˆ˜ ì¶”ê°€
def handle_slash_command(form_data):
    """ìŠ¬ë˜ì‹œ ëª…ë ¹ì–´ ì²˜ë¦¬"""
    try:
        command = form_data.get('command', '')
        user_id = form_data.get('user_id', '')
        trigger_id = form_data.get('trigger_id', '')
        
        logging.info(f"Received slash command: {command} from user: {user_id}")
        
        if command == '/dashboard':
            logging.info("=== ì´ë ¥ì„œ ëŒ€ì‹œë³´ë“œ ëª…ë ¹ì–´ ì²˜ë¦¬ ì‹œì‘ ===")
            
            if not trigger_id:
                return jsonify({"text": "âŒ trigger_idê°€ ì—†ìŠµë‹ˆë‹¤."}), 200
            
            try:
                # ê¸°ì¡´ ì´ë ¥ì„œ ê´€ë¦¬ ëŒ€ì‹œë³´ë“œ ëª¨ë‹¬ ì—´ê¸°
                dashboard_modal = create_dashboard_modal()
                
                response = client.views_open(
                    trigger_id=trigger_id,
                    view=dashboard_modal
                )
                
                if not response.get("ok"):
                    logging.error(f"ëŒ€ì‹œë³´ë“œ ëª¨ë‹¬ ì—´ê¸° ì‹¤íŒ¨: {response}")
                    return jsonify({"text": f"âŒ ëª¨ë‹¬ ì—´ê¸° ì‹¤íŒ¨: {response.get('error', 'ì•Œ ìˆ˜ ì—†ìŒ')}"}), 200
                
                logging.info("ì´ë ¥ì„œ ëŒ€ì‹œë³´ë“œ ëª¨ë‹¬ ì—´ê¸° ì„±ê³µ")
                return "", 200
                
            except Exception as e:
                logging.error(f"ì´ë ¥ì„œ ëŒ€ì‹œë³´ë“œ ëª¨ë‹¬ ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}", exc_info=True)
                return jsonify({"text": f"âŒ ëŒ€ì‹œë³´ë“œ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"}), 200
        
        elif command == '/market':
            logging.info("=== ì‹œì¥ ì¸í…”ë¦¬ì „ìŠ¤ ëª…ë ¹ì–´ ì²˜ë¦¬ ì‹œì‘ ===")
            
            if not trigger_id:
                return jsonify({"text": "âŒ trigger_idê°€ ì—†ìŠµë‹ˆë‹¤."}), 200
            
            try:
                # ì¦‰ì‹œ ë¡œë”© ëª¨ë‹¬ í‘œì‹œ
                loading_modal = {
                    "type": "modal",
                    "callback_id": "market_loading",
                    "title": {
                        "type": "plain_text",
                        "text": "ğŸ“Š ì±„ìš© ì‹œì¥ ì¸í…”ë¦¬ì „ìŠ¤"
                    },
                    "blocks": [
                        {
                            "type": "section",
                            "text": {
                                "type": "mrkdwn",
                                "text": "ğŸ”„ *ì‹¤ì‹œê°„ ì±„ìš© ì‹œì¥ ë°ì´í„° ìˆ˜ì§‘ ì¤‘...*\n\nâ€¢ ì›í‹°ë“œ ì±„ìš©ê³µê³  ìŠ¤í¬ë˜í•‘ ì¤‘\nâ€¢ ê¸°ì—…ë³„ í†µê³„ ë¶„ì„ ì¤‘\nâ€¢ ê¸°ìˆ ìŠ¤íƒ íŠ¸ë Œë“œ ë¶„ì„ ì¤‘\n\nì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”! â³"
                            }
                        }
                    ],
                    "close": {
                        "type": "plain_text",
                        "text": "ì·¨ì†Œ"
                    }
                }
                
                # ë¡œë”© ëª¨ë‹¬ ì—´ê¸°
                response = client.views_open(
                    trigger_id=trigger_id,
                    view=loading_modal
                )
                
                if not response.get("ok"):
                    logging.error(f"ë¡œë”© ëª¨ë‹¬ ì—´ê¸° ì‹¤íŒ¨: {response}")
                    return jsonify({"text": f"âŒ ëª¨ë‹¬ ì—´ê¸° ì‹¤íŒ¨: {response.get('error', 'ì•Œ ìˆ˜ ì—†ìŒ')}"}), 200
                
                view_id = response["view"]["id"]
                logging.info(f"ë¡œë”© ëª¨ë‹¬ ì—´ê¸° ì„±ê³µ, view_id: {view_id}")
                
                # ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì‹¤ì œ ë°ì´í„° ì²˜ë¦¬
                def process_market_modal():
                    try:
                        logging.info("ë°±ê·¸ë¼ìš´ë“œ ì‹œì¥ ì¸í…”ë¦¬ì „ìŠ¤ ë°ì´í„° ì²˜ë¦¬ ì‹œì‘")
                        
                        # ì‹¤ì œ ìŠ¤í¬ë˜í•‘ ì‹œë„
                        try:
                            scraped_jobs = scrape_wanted_jobs()
                            if scraped_jobs and len(scraped_jobs) > 0:
                                logging.info(f"ì‹¤ì œ ìŠ¤í¬ë˜í•‘ ì„±ê³µ: {len(scraped_jobs)}ê°œ ê³µê³ ")
                                analyzed_data = analyze_scraped_data(scraped_jobs)
                                data_source = "ì‹¤ì‹œê°„ ë°ì´í„°"
                            else:
                                logging.warning("ìŠ¤í¬ë˜í•‘ ê²°ê³¼ ì—†ìŒ, ëª©ì—… ë°ì´í„° ì‚¬ìš©")
                                analyzed_data = get_mock_data()
                                data_source = "ë°ëª¨ ë°ì´í„°"
                        except Exception as e:
                            logging.error(f"ìŠ¤í¬ë˜í•‘ ì‹¤íŒ¨: {str(e)}")
                            analyzed_data = get_mock_data()
                            data_source = "ë°ëª¨ ë°ì´í„°"
                        
                        # ì‹œì¥ ì¸í…”ë¦¬ì „ìŠ¤ ëª¨ë‹¬ ìƒì„±
                        market_modal = create_market_intelligence_modal_with_data(analyzed_data, data_source)
                        
                        # ëª¨ë‹¬ ì—…ë°ì´íŠ¸
                        update_response = client.views_update(
                            view_id=view_id,
                            view=market_modal
                        )
                        
                        if update_response.get("ok"):
                            logging.info("ì‹œì¥ ì¸í…”ë¦¬ì „ìŠ¤ ëª¨ë‹¬ ì—…ë°ì´íŠ¸ ì„±ê³µ")
                        else:
                            logging.error(f"ëª¨ë‹¬ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {update_response}")
                            
                    except Exception as e:
                        logging.error(f"ë°±ê·¸ë¼ìš´ë“œ ì‹œì¥ ì¸í…”ë¦¬ì „ìŠ¤ ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}", exc_info=True)
                        
                        # ì—ëŸ¬ ëª¨ë‹¬ í‘œì‹œ
                        error_modal = {
                            "type": "modal",
                            "callback_id": "market_error",
                            "title": {
                                "type": "plain_text",
                                "text": "âŒ ì˜¤ë¥˜ ë°œìƒ"
                            },
                            "blocks": [
                                {
                                    "type": "section",
                                    "text": {
                                        "type": "mrkdwn",
                                        "text": f"*ì‹œì¥ ì¸í…”ë¦¬ì „ìŠ¤ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.*\n\n```{str(e)}```\n\nì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
                                    }
                                }
                            ],
                            "close": {
                                "type": "plain_text",
                                "text": "ë‹«ê¸°"
                            }
                        }
                        
                        try:
                            client.views_update(view_id=view_id, view=error_modal)
                        except:
                            pass
                
                # ë°±ê·¸ë¼ìš´ë“œ ìŠ¤ë ˆë“œ ì‹œì‘
                import threading
                thread = threading.Thread(target=process_market_modal)
                thread.daemon = True
                thread.start()
                
                return "", 200
                
            except Exception as e:
                logging.error(f"ì‹œì¥ ì¸í…”ë¦¬ì „ìŠ¤ ëª¨ë‹¬ ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}", exc_info=True)
                return jsonify({"text": f"âŒ ì‹œì¥ ì¸í…”ë¦¬ì „ìŠ¤ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"}), 200
        
        return "ì•Œ ìˆ˜ ì—†ëŠ” ëª…ë ¹ì–´ì…ë‹ˆë‹¤.", 200
        
    except Exception as e:
        logging.error(f"ìŠ¬ë˜ì‹œ ì»¤ë§¨ë“œ ì „ì²´ ì˜¤ë¥˜: {str(e)}", exc_info=True)
        return f"ëª…ë ¹ì–´ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}", 200

# Modal submission ì²˜ë¦¬ í•¨ìˆ˜ ì¶”ê°€
def handle_modal_submission(data):
    """Modal ì œì¶œ ì²˜ë¦¬"""
    try:
        callback_id = data.get("view", {}).get("callback_id", "")
        user_id = data.get("user", {}).get("id", "")
        
        if callback_id == "dashboard_modal":
            # í•„í„° ê°’ë“¤ ì¶”ì¶œ
            state_values = data.get("view", {}).get("state", {}).get("values", {})
            
            job_filter = "all"
            years_filter = "all" 
            sort_filter = "latest"
            
            if "job_filter" in state_values:
                job_selection = state_values["job_filter"]["select_job"].get("selected_option")
                if job_selection:
                    job_filter = job_selection["value"]
            
            if "years_filter" in state_values:
                years_selection = state_values["years_filter"]["select_years"].get("selected_option")
                if years_selection:
                    years_filter = years_selection["value"]
                    
            if "sort_filter" in state_values:
                sort_selection = state_values["sort_filter"]["select_sort"].get("selected_option")
                if sort_selection:
                    sort_filter = sort_selection["value"]
            
            logging.info(f"Dashboard filters: job={job_filter}, years={years_filter}, sort={sort_filter}")
            
            # Notion ë°ì´í„° ì¡°íšŒ ë° í•„í„°ë§
            try:
                notion_pages = get_all_resumes_from_notion()
                all_data = parse_notion_resume_data(notion_pages)
                filtered_data = apply_filters(all_data, job_filter, years_filter, sort_filter)
                
                logging.info(f"Found {len(all_data)} total resumes, {len(filtered_data)} after filtering")
                
                # ì°¨íŠ¸ ìƒì„±
                chart_image = create_dashboard_chart(filtered_data)
                
                # ìƒˆë¡œìš´ Modal ì»¨í…ì¸  ìƒì„±
                new_blocks = [
                    {
                        "type": "section",
                        "text": {
                            "type": "mrkdwn",
                            "text": "*ğŸ“Š ì´ë ¥ì„œ ëŒ€ì‹œë³´ë“œ - í•„í„° ê²°ê³¼*"
                        }
                    },
                    {
                        "type": "divider"
                    }
                ]
                
                # í•„í„°ë§ëœ ê²°ê³¼ ë¸”ë¡ ì¶”ê°€
                result_blocks = create_filtered_results_blocks(filtered_data, len(all_data))
                new_blocks.extend(result_blocks)
                
                # ì°¨íŠ¸ê°€ ìˆëŠ” ê²½ìš° ì—…ë¡œë“œ
                if chart_image:
                    try:
                        chart_file_id = upload_image_to_slack(chart_image, "ë§¤ì¹­ë¥  ë¶„í¬ ì°¨íŠ¸", user_id)
                        if chart_file_id:
                            new_blocks.insert(-1, {
                                "type": "section",
                                "text": {
                                    "type": "mrkdwn",
                                    "text": "ğŸ“Š *ë§¤ì¹­ë¥  ë¶„í¬ ì°¨íŠ¸ê°€ DMìœ¼ë¡œ ì „ì†¡ë˜ì—ˆìŠµë‹ˆë‹¤.*"
                                }
                            })
                    except Exception as chart_error:
                        logging.error(f"Chart upload error: {str(chart_error)}")
                
                # Modal ì—…ë°ì´íŠ¸
                updated_modal = {
                    "type": "modal",
                    "callback_id": "dashboard_modal",
                    "title": {
                        "type": "plain_text",
                        "text": "ğŸ“Š ì´ë ¥ì„œ ëŒ€ì‹œë³´ë“œ"
                    },
                    "blocks": new_blocks,
                    "close": {
                        "type": "plain_text",
                        "text": "ë‹«ê¸°"
                    }
                }
                
                # Modal ì—…ë°ì´íŠ¸ ì‹œë„
                view_id = data.get("view", {}).get("id")
                if view_id:
                    update_response = client.views_update(
                        view_id=view_id,
                        view=updated_modal
                    )
                    
                    if update_response.get("ok"):
                        logging.info("Modal updated successfully")
                    else:
                        logging.error(f"Failed to update modal: {update_response}")
                
                return "", 200
                
            except Exception as data_error:
                logging.error(f"Data processing error: {str(data_error)}")
                
                # ì—ëŸ¬ Modal ì—…ë°ì´íŠ¸
                error_modal = {
                    "type": "modal",
                    "callback_id": "dashboard_modal",
                    "title": {
                        "type": "plain_text",
                        "text": "ğŸ“Š ì´ë ¥ì„œ ëŒ€ì‹œë³´ë“œ"
                    },
                    "blocks": [
                        {
                            "type": "section",
                            "text": {
                                "type": "mrkdwn",
                                "text": "âŒ *ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.*\nì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
                            }
                        }
                    ],
                    "close": {
                        "type": "plain_text",
                        "text": "ë‹«ê¸°"
                    }
                }
                
                view_id = data.get("view", {}).get("id")
                if view_id:
                    client.views_update(view_id=view_id, view=error_modal)
                
                return "", 200
        
        return "", 200
        
    except Exception as e:
        logging.error(f"Error handling modal submission: {str(e)}")
        return "", 500

def replace_emojis_for_pdf(text):
    """PDFìš©ìœ¼ë¡œ ì´ëª¨ì§€ë¥¼ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜"""
    emoji_replacements = {
        'ğŸ“Š': '[ì°¨íŠ¸]',
        'ğŸ‘¤': '[ì¸ë¬¼]',
        'ğŸ’«': '[ë³„]',
        'â­': '[ë³„ì ]',
        'ğŸ“ˆ': '[ê·¸ë˜í”„]',
        'ğŸ¯': '[ëª©í‘œ]',
        'ğŸ“Œ': '[í•€]',
        'ğŸ’»': '[ì»´í“¨í„°]',
        'ğŸ‘¥': '[ì‚¬ëŒë“¤]',
        'âœ…': '[ì²´í¬]',
        'ğŸ“š': '[ì±…]',
        'ğŸ”': '[ê²€ìƒ‰]',
        'âŒ': '[X]',
        'ğŸ“‹': '[í´ë¦½ë³´ë“œ]',
        'ğŸ‰': '[ì¶•í•˜]',
        'ğŸ’¡': '[ì „êµ¬]',
        'ğŸš€': '[ë¡œì¼“]',
        'ğŸ†': '[íŠ¸ë¡œí”¼]',
        'ğŸ“': '[ë©”ëª¨]',
        'âš¡': '[ë²ˆê°œ]',
        'ğŸŒŸ': '[ë³„]',
        'ğŸ¨': '[íŒ”ë ˆíŠ¸]',
        'ğŸ”§': '[ë„êµ¬]',
        'ğŸ“–': '[ì—´ë¦°ì±…]',
        'ğŸ­': '[ì—°ê·¹]',
        'ğŸª': '[ì„œì»¤ìŠ¤]',
        'ğŸ¸': '[ê¸°íƒ€]',
        'ğŸ¯': '[ë‹¤íŠ¸]'
    }
    
    result = text
    for emoji, replacement in emoji_replacements.items():
        result = result.replace(emoji, replacement)
    
    return result

def create_pdf_report(result, chart_image=None):
    """ë¶„ì„ ê²°ê³¼ë¥¼ PDF ë³´ê³ ì„œë¡œ ìƒì„± (reportlab ì‚¬ìš©)"""
    try:
        buffer = BytesIO()
        doc = SimpleDocTemplate(buffer, pagesize=A4, topMargin=1*inch, bottomMargin=1*inch)
        
        # í•œê¸€ í°íŠ¸ ë“±ë¡
        try:
            # ë§‘ì€ ê³ ë”• í°íŠ¸ ë“±ë¡
            pdfmetrics.registerFont(TTFont('MalgunGothic', 'C:/Windows/Fonts/malgun.ttf'))
            pdfmetrics.registerFont(TTFont('MalgunGothic-Bold', 'C:/Windows/Fonts/malgunbd.ttf'))
            font_name = 'MalgunGothic'
            bold_font_name = 'MalgunGothic-Bold'
        except:
            try:
                # ëŒ€ì²´ í°íŠ¸: ë‚˜ëˆ”ê³ ë”•
                pdfmetrics.registerFont(TTFont('NanumGothic', 'C:/Windows/Fonts/NanumGothic.ttf'))
                pdfmetrics.registerFont(TTFont('NanumGothic-Bold', 'C:/Windows/Fonts/NanumGothicBold.ttf'))
                font_name = 'NanumGothic'
                bold_font_name = 'NanumGothic-Bold'
            except:
                # ê¸°ë³¸ í°íŠ¸ ì‚¬ìš© (í•œê¸€ ê¹¨ì§ˆ ìˆ˜ ìˆìŒ)
                font_name = 'Helvetica'
                bold_font_name = 'Helvetica-Bold'
        
        # ìŠ¤íƒ€ì¼ ì„¤ì • (í•œê¸€ í°íŠ¸ ì ìš©)
        styles = getSampleStyleSheet()
        title_style = ParagraphStyle(
            'TitleStyle',
            parent=styles['Title'],
            fontName=bold_font_name,
            fontSize=24,
            spaceAfter=30,
            textColor=colors.darkblue,
            alignment=1  # center
        )
        
        heading_style = ParagraphStyle(
            'HeadingStyle',
            parent=styles['Heading2'],
            fontName=bold_font_name,
            fontSize=14,
            spaceAfter=12,
            textColor=colors.darkblue,
            spaceBefore=20
        )
        
        normal_style = ParagraphStyle(
            'NormalStyle',
            parent=styles['Normal'],
            fontName=font_name,
            fontSize=11,
            spaceAfter=8,
            leftIndent=20
        )
        
        info_style = ParagraphStyle(
            'InfoStyle',
            parent=styles['Normal'],
            fontName=font_name,
            fontSize=10,
            spaceAfter=8
        )
        
        # PDF ì»¨í…ì¸  êµ¬ì„±
        story = []
        
        # ì œëª©
        story.append(Paragraph(replace_emojis_for_pdf("ğŸ“Š ì´ë ¥ì„œ ë¶„ì„ ë³´ê³ ì„œ"), title_style))
        story.append(Spacer(1, 20))
        
        # ê¸°ë³¸ ì •ë³´
        current_time = datetime.now().strftime('%Yë…„ %mì›” %dì¼ %H:%M')
        story.append(Paragraph(f"ìƒì„±ì¼ì‹œ: {current_time}", info_style))
        story.append(Spacer(1, 20))
        
        # ë¶„ì„ ëŒ€ìƒì ì •ë³´
        story.append(Paragraph(replace_emojis_for_pdf("ğŸ‘¤ ë¶„ì„ ëŒ€ìƒì ì •ë³´"), heading_style))
        story.append(Paragraph(f"â€¢ ì´ë¦„: {result.get('name', 'ë¯¸ê¸°ì¬')}", normal_style))
        story.append(Paragraph(f"â€¢ ì´ ê²½ë ¥: {result.get('total_years', 'N/A')}ë…„", normal_style))
        story.append(Spacer(1, 15))
        
        # ìºì¹˜í”„ë ˆì´ì¦ˆ
        story.append(Paragraph(replace_emojis_for_pdf("ğŸ’« ìºì¹˜í”„ë ˆì´ì¦ˆ"), heading_style))
        catchphrase = result.get('catchphrase', 'N/A')
        story.append(Paragraph(f"'{replace_emojis_for_pdf(catchphrase)}'", normal_style))
        story.append(Spacer(1, 15))
        
        # ê°•ì  Top 3
        story.append(Paragraph(replace_emojis_for_pdf("â­ ê°•ì  Top 3"), heading_style))
        for i, strength in enumerate(result.get('top_strengths', []), 1):
            story.append(Paragraph(f"{i}. {replace_emojis_for_pdf(strength)}", normal_style))
        story.append(Spacer(1, 15))
        
        # ê¸°ìˆ  ìŠ¤í‚¬ ì°¨íŠ¸ (ìˆëŠ” ê²½ìš°)
        if chart_image:
            story.append(Paragraph(replace_emojis_for_pdf("ğŸ“ˆ ê¸°ìˆ  ìŠ¤í‚¬ ë ˆì´ë” ì°¨íŠ¸"), heading_style))
            try:
                # ì°¨íŠ¸ ì´ë¯¸ì§€ë¥¼ ë©”ëª¨ë¦¬ì—ì„œ ì§ì ‘ ì²˜ë¦¬ (ì„ì‹œ íŒŒì¼ ì—†ì´)
                from PIL import Image
                import io
                
                # BytesIO ê°ì²´ì—ì„œ ì´ë¯¸ì§€ ìƒì„±
                image_buffer = io.BytesIO(chart_image)
                pil_image = Image.open(image_buffer)
                
                # PIL ì´ë¯¸ì§€ë¥¼ reportlab Imageë¡œ ì§ì ‘ ë³€í™˜
                chart_img = RLImage(pil_image, width=5*inch, height=5*inch)
                story.append(chart_img)
                story.append(Spacer(1, 15))
                
                logging.info("Chart image successfully added to PDF")
                    
            except Exception as e:
                logging.error(f"Chart image processing error: {str(e)}")
                story.append(Paragraph(replace_emojis_for_pdf("ğŸ“ˆ ê¸°ìˆ  ìŠ¤í‚¬ ë ˆì´ë” ì°¨íŠ¸"), heading_style))
                story.append(Paragraph("ì°¨íŠ¸ ì´ë¯¸ì§€ë¥¼ í¬í•¨í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.", normal_style))
                story.append(Spacer(1, 15))
        
        # ì—­ëŸ‰ ì¹´ë“œ
        story.append(Paragraph(replace_emojis_for_pdf("ğŸ¯ ì—­ëŸ‰ ë¶„ì„"), heading_style))
        
        skill_cards = result.get('skill_cards', {})
        
        # Domain Knowledge
        story.append(Paragraph(replace_emojis_for_pdf("ğŸ“Œ Domain Knowledge"), heading_style))
        domain_knowledge = skill_cards.get('domain_knowledge', 'N/A')
        story.append(Paragraph(replace_emojis_for_pdf(domain_knowledge), normal_style))
        story.append(Spacer(1, 10))
        
        # Tech Skills
        story.append(Paragraph(replace_emojis_for_pdf("ğŸ’» Tech Skills"), heading_style))
        tech_skills = skill_cards.get('tech_skills', 'N/A')
        story.append(Paragraph(replace_emojis_for_pdf(tech_skills), normal_style))
        story.append(Spacer(1, 10))
        
        # Soft Skills
        story.append(Paragraph(replace_emojis_for_pdf("ğŸ‘¥ Soft Skills"), heading_style))
        soft_skills = skill_cards.get('soft_skills', 'N/A')
        story.append(Paragraph(replace_emojis_for_pdf(soft_skills), normal_style))
        
        # PDF ìƒì„±
        doc.build(story)
        buffer.seek(0)
        return buffer.getvalue()
        
    except Exception as e:
        logging.error(f"PDF generation error: {str(e)}")
        raise

def create_stat_card_blocks(result):
    blocks = [
        {
            "type": "header",
            "text": {
                "type": "plain_text",
                "text": f"ğŸ“Š {result.get('name', '')}ë‹˜ì˜ ì´ë ¥ì„œ ë¶„ì„ ê²°ê³¼",
                "emoji": True
            }
        },
        {
            "type": "divider"
        },
        # ê¸°ë³¸ ì •ë³´
        {
            "type": "section",
            "fields": [
                {
                    "type": "mrkdwn",
                    "text": f"*ğŸ“ˆ ì´ ê²½ë ¥ ì—°ì°¨*\n{result.get('total_years', 'N/A')}ë…„"
                },
                {
                    "type": "mrkdwn",
                    "text": f"*ğŸ“… ë¶„ì„ ì™„ë£Œ*\n{datetime.now().strftime('%Y.%m.%d')}"
                }
            ]
        },
        {
            "type": "divider"
        },
        # ìºì¹˜í”„ë ˆì´ì¦ˆ
        {
            "type": "section",
            "text": {
                "type": "mrkdwn",
                "text": f"*ğŸ’« ìºì¹˜í”„ë ˆì´ì¦ˆ*\n_{result.get('catchphrase', 'N/A')}_"
            }
        },
        {
            "type": "divider"
        },
        # ê°•ì  Top 3
        {
            "type": "section",
            "text": {
                "type": "mrkdwn",
                "text": "*â­ ê°•ì  Top 3*"
            }
        }
    ]
    
    # ê°•ì ë“¤ì„ í‘œì‹œ
    strengths = result.get('top_strengths', [])
    if strengths:
        if len(strengths) >= 2:
            blocks.append({
                "type": "section",
                "fields": [
                    {
                        "type": "mrkdwn",
                        "text": f"*1ï¸âƒ£ {strengths[0]}*"
                    },
                    {
                        "type": "mrkdwn", 
                        "text": f"*2ï¸âƒ£ {strengths[1]}*"
                    }
                ]
            })
        
        if len(strengths) >= 3:
            blocks.append({
                "type": "section",
                "text": {
                    "type": "mrkdwn",
                    "text": f"*3ï¸âƒ£ {strengths[2]}*"
                }
            })
    
    blocks.extend([
        {
            "type": "divider"
        },
        # Domain Knowledge
        {
            "type": "section",
            "text": {
                "type": "mrkdwn",
                "text": "*ğŸ¯ Domain Knowledge*"
            }
        },
        {
            "type": "section",
            "text": {
                "type": "mrkdwn",
                "text": f">{result.get('skill_cards', {}).get('domain_knowledge', 'N/A')}"
            }
        },
        {
            "type": "divider"
        },
        # Tech Skills
        {
            "type": "section",
            "text": {
                "type": "mrkdwn",
                "text": "*ğŸ’» Tech Skills*"
            }
        },
        {
            "type": "section",
            "text": {
                "type": "mrkdwn",
                "text": f">{result.get('skill_cards', {}).get('tech_skills', 'N/A')}"
            }
        },
        {
            "type": "divider"
        },
        # Soft Skills
        {
            "type": "section",
            "text": {
                "type": "mrkdwn",
                "text": "*ğŸ‘¥ Soft Skills*"
            }
        },
        {
            "type": "section",
            "text": {
                "type": "mrkdwn",
                "text": f">{result.get('skill_cards', {}).get('soft_skills', 'N/A')}"
            }
        },
        {
            "type": "divider"
        },
        # ì¶”ê°€ ì•¡ì…˜
        {
            "type": "section",
            "text": {
                "type": "mrkdwn",
                "text": "*ğŸ“Š ì¶”ê°€ ì•¡ì…˜*"
            }
        },
        {
            "type": "actions",
            "elements": [
                {
                    "type": "button",
                    "text": {
                        "type": "plain_text",
                        "text": "ğŸ“„ PDF ë³´ê³ ì„œ ë‹¤ìš´ë¡œë“œ",
                        "emoji": True
                    },
                    "action_id": "generate_pdf_report",
                    "style": "primary"
                }
            ]
        },
        {
            "type": "context",
            "elements": [
                {
                    "type": "mrkdwn",
                    "text": "âœ… ë¶„ì„ ì™„ë£Œ! ê²°ê³¼ëŠ” Notionì—ë„ ìë™ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤."
                }
            ]
        }
    ])
    
    return blocks

def safe_text(t):
    """í…ìŠ¤íŠ¸ë¥¼ ì•ˆì „í•˜ê²Œ ì²˜ë¦¬í•˜ëŠ” í•¨ìˆ˜"""
    if isinstance(t, bytearray):
        return t.decode("utf-8", errors="ignore")
    elif isinstance(t, bytes):
        return t.decode("utf-8", errors="ignore")
    return str(t)

def upload_to_slack(file_content, filename, user_id):
    """ìƒì„±ëœ PDFë¥¼ Slackì— ì—…ë¡œë“œ"""
    try:
        files = {
            'file': (filename, file_content, 'application/pdf')
        }
        params = {
            'channels': user_id,
            'initial_comment': 'ğŸ“Š ì´ë ¥ì„œ ë¶„ì„ ë³´ê³ ì„œê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.'
        }
        response = requests.post(
            'https://slack.com/api/files.upload',
            headers={'Authorization': f'Bearer {SLACK_BOT_TOKEN}'},
            params=params,
            files=files
        )
        return response.json()
    except Exception as e:
        print(f"Slack upload error: {str(e)}")
        raise

def create_simple_test_chart():
    """ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ ì°¨íŠ¸ ìƒì„±"""
    logging.debug("Creating simple test chart")
    
    try:
        # ê°„ë‹¨í•œ SVG ì°¨íŠ¸
        svg = '''<?xml version="1.0" encoding="UTF-8"?>
<svg width="400" height="400" xmlns="http://www.w3.org/2000/svg">
    <style>
        .title { font-family: Arial; font-size: 16px; fill: #333; }
        .bar { fill: #4CAF50; }
        .label { font-family: Arial; font-size: 12px; fill: #333; }
    </style>
    
    <text x="200" y="30" text-anchor="middle" class="title">ê¸°ìˆ  ìŠ¤í‚¬ ì°¨íŠ¸</text>
    
    <rect x="50" y="60" width="120" height="30" class="bar"/>
    <text x="60" y="80" class="label">Python: 90%</text>
    
    <rect x="50" y="100" width="100" height="30" class="bar"/>
    <text x="60" y="120" class="label">SQL: 80%</text>
    
    <rect x="50" y="140" width="110" height="30" class="bar"/>
    <text x="60" y="160" class="label">Figma: 85%</text>
    
    <rect x="50" y="180" width="90" height="30" class="bar"/>
    <text x="60" y="200" class="label">GCP: 75%</text>
</svg>'''
        
        svg_bytes = svg.encode('utf-8')
        logging.debug("Simple test chart created, size: %d bytes", len(svg_bytes))
        return svg_bytes
        
    except Exception as e:
        logging.error("Error creating simple test chart: %s", str(e))
        return None

def create_plotly_radar_chart(skills_dict):
    """matplotlibì„ ì‚¬ìš©í•œ ë ˆì´ë” ì°¨íŠ¸ ìƒì„± (PNG í˜•ì‹)"""
    logging.debug("Creating radar chart with matplotlib - skills: %s", skills_dict)
    
    if not skills_dict:
        logging.error("Empty skills dictionary provided")
        return None
        
    try:
        # ë°ì´í„° ì •ì œ - ìƒìœ„ 8ê°œ ìŠ¤í‚¬ë§Œ ì„ íƒ
        sorted_skills = dict(sorted(skills_dict.items(), key=lambda x: x[1], reverse=True)[:8])
        logging.debug("Selected top 8 skills: %s", sorted_skills)
        
        # ë°ì´í„° ì¤€ë¹„
        categories = list(sorted_skills.keys())
        values = list(sorted_skills.values())
        N = len(categories)
        
        if N == 0:
            logging.error("No skills to chart")
            return None
        
        # ê°ë„ ê³„ì‚° (360ë„ë¥¼ Nê°œë¡œ ë¶„í• )
        angles = [n / N * 2 * np.pi for n in range(N)]
        angles += angles[:1]  # ì›ì„ ì™„ì„±í•˜ê¸° ìœ„í•´ ì²« ë²ˆì§¸ ê°’ì„ ë§ˆì§€ë§‰ì— ì¶”ê°€
        
        # ê°’ë„ ìˆœí™˜ ì™„ì„±
        values += values[:1]
        
        # ê·¸ë˜í”„ ìƒì„±
        fig, ax = plt.subplots(figsize=(10, 10), subplot_kw=dict(projection='polar'))
        
        # ì°¨íŠ¸ ìƒ‰ìƒ ì„¤ì •
        ax.plot(angles, values, 'o-', linewidth=2, label='ê¸°ìˆ  ìŠ¤í‚¬', color='#36A2EB')
        ax.fill(angles, values, alpha=0.25, color='#36A2EB')
        
        # ì¹´í…Œê³ ë¦¬ ë¼ë²¨ ì„¤ì •
        ax.set_xticks(angles[:-1])
        ax.set_xticklabels(categories, fontsize=11)
        
        # Yì¶• (ë°˜ì§€ë¦„) ì„¤ì •
        ax.set_ylim(0, 100)
        ax.set_yticks([20, 40, 60, 80, 100])
        ax.set_yticklabels(['20%', '40%', '60%', '80%', '100%'], fontsize=9)
        
        # ê²©ì ìŠ¤íƒ€ì¼ ì„¤ì •
        ax.grid(True, alpha=0.3)
        ax.set_facecolor('#FAFAFA')
        
        # ì œëª© ì„¤ì •
        plt.title('ê¸°ìˆ  ìŠ¤í‚¬ ë ˆì´ë” ì°¨íŠ¸', size=16, fontweight='bold', pad=20)
        
        # ë²”ë¡€ ì„¤ì •
        plt.legend(loc='upper right', bbox_to_anchor=(1.2, 1.0))
        
        # ì—¬ë°± ì¡°ì •
        plt.tight_layout()
        
        # PNG ë°”ì´íŠ¸ë¡œ ë³€í™˜
        buffer = BytesIO()
        plt.savefig(buffer, format='png', dpi=150, bbox_inches='tight', 
                   facecolor='white', edgecolor='none')
        buffer.seek(0)
        png_bytes = buffer.read()
        buffer.close()
        
        # ë©”ëª¨ë¦¬ ì •ë¦¬
        plt.close(fig)
        
        logging.debug("Generated PNG size: %d bytes", len(png_bytes))
        return png_bytes
        
    except Exception as e:
        logging.error("Error creating radar chart: %s", str(e), exc_info=True)
        return None

def create_wordcloud(skills_dict):
    """ê¸°ìˆ  ìŠ¤í‚¬ ì›Œë“œí´ë¼ìš°ë“œ ìƒì„±"""
    if not skills_dict:
        return None
    
    # ë°ì´í„° ì „ì²˜ë¦¬
    word_freq = {}
    for skill, value in skills_dict.items():
        try:
            # Remove '%' and convert to float
            freq = float(str(value).replace('%', '').strip())
            word_freq[skill] = freq
        except (ValueError, TypeError):
            word_freq[skill] = 1
    
    # WordCloud ì„¤ì •
    wordcloud = WordCloud(
        width=800,
        height=400,
        background_color='white',
        font_path='C:/Windows/Fonts/malgun.ttf',  # í•œê¸€ í°íŠ¸ ê²½ë¡œ
        min_font_size=10,
        max_font_size=100,
        prefer_horizontal=0.7
    )
    
    # ì›Œë“œí´ë¼ìš°ë“œ ìƒì„±
    wordcloud.generate_from_frequencies(word_freq)
    
    # ì´ë¯¸ì§€ë¡œ ì €ì¥
    plt.figure(figsize=(10, 5))
    plt.imshow(wordcloud, interpolation='bilinear')
    plt.axis('off')
    
    # ì´ë¯¸ì§€ë¡œ ì €ì¥
    img_bytes = io.BytesIO()
    plt.savefig(img_bytes, format='png', bbox_inches='tight', dpi=300)
    img_bytes.seek(0)
    plt.close()
    
    return img_bytes

def parse_skills(skills_text):
    """ìŠ¤í‚¬ í…ìŠ¤íŠ¸ì—ì„œ ìŠ¤í‚¬:í¼ì„¼íŠ¸ í˜•ì‹ì„ íŒŒì‹±"""
    logging.debug("Starting skills parsing from text: %s", skills_text)
    
    if not skills_text:
        logging.error("Empty skills text provided")
        return {}
        
    try:
        # ë” ìœ ì—°í•œ ì •ê·œí‘œí˜„ì‹ íŒ¨í„´
        # Matches: "Skill Name: 90%" or "Skill Name:90%" or "Skill Name: 90" or "Skill/Name: 90%"
        skill_pattern = r'([^,]+?):\s*(\d+)%?'
        matches = re.findall(skill_pattern, skills_text)
        
        if not matches:
            logging.error("No skills found in text using pattern: %s", skill_pattern)
            return {}
            
        # Convert to dictionary and clean skill names
        skills_dict = {}
        for skill, percentage in matches:
            skill_name = skill.strip()
            try:
                percentage_value = int(percentage.strip())
                if 0 <= percentage_value <= 100:  # Validate percentage range
                    skills_dict[skill_name] = percentage_value
                    logging.debug("Parsed skill: %s = %d%%", skill_name, percentage_value)
                else:
                    logging.warning("Invalid percentage value for skill %s: %d", skill_name, percentage_value)
            except ValueError as ve:
                logging.error("Error converting percentage for skill %s: %s", skill_name, str(ve))
                
        if not skills_dict:
            logging.error("Failed to parse any valid skills")
        else:
            logging.info("Successfully parsed %d skills: %s", len(skills_dict), skills_dict)
            
        return skills_dict
        
    except Exception as e:
        logging.error("Error parsing skills: %s", str(e), exc_info=True)
        return {}

def upload_image_to_slack(image_bytes, title, channel_id):
    """PNG ì´ë¯¸ì§€ë¥¼ Slackì— ì—…ë¡œë“œ"""
    logging.debug("Starting Slack image upload - Title: %s, Channel: %s", title, channel_id)
    
    if not image_bytes:
        logging.error("No image bytes provided for upload")
        return None
        
    if not channel_id:
        logging.error("No channel ID provided")
        return None
        
    logging.debug("Image size: %d bytes", len(image_bytes))
    
    # Determine file extension based on image content
    file_extension = "png" if image_bytes.startswith(b'\x89PNG') else "svg"
    temp_file = f"temp_{title}.{file_extension}"
    
    try:
        with open(temp_file, 'wb') as f:
            f.write(image_bytes)
        logging.debug("Temporary file created: %s", temp_file)
        
        # Upload file to Slack
        logging.debug("Attempting to upload file to Slack")
        try:
            response = client.files_upload_v2(
                channel=channel_id,
                title=title,
                filename=f"{title}.{file_extension}",
                file=temp_file,
                request_file_info=True
            )
            logging.debug("Slack upload response: %s", response)
            
            if response and response.get("file"):
                file_id = response["file"]["id"]
                file_url = response["file"].get("url_private")
                logging.info("File uploaded successfully. File ID: %s, URL: %s", file_id, file_url)
                
                # For PNG files, try to display as inline image
                if file_extension == "png":
                    try:
                        blocks = [
                            {
                                "type": "image",
                                "title": {
                                    "type": "plain_text",
                                    "text": title
                                },
                                "image_url": file_url,
                                "alt_text": title
                            }
                        ]
                        
                        client.chat_postMessage(
                            channel=channel_id,
                            blocks=blocks,
                            text=f"ğŸ“Š {title}"
                        )
                        logging.debug("Posted PNG image block to channel")
                    except Exception as block_error:
                        logging.error("Error posting image block: %s", str(block_error))
                
                return file_id
            else:
                logging.error("Upload response missing file info: %s", response)
                return None
                
        except Exception as upload_error:
            logging.error("Error during Slack upload: %s", str(upload_error), exc_info=True)
            return None
            
    except Exception as file_error:
        logging.error("Error handling temporary file: %s", str(file_error))
        return None
        
    finally:
        # Clean up temporary file
        try:
            if os.path.exists(temp_file):
                os.remove(temp_file)
                logging.debug("Cleaned up temporary upload file")
        except Exception as cleanup_error:
            logging.error("Error cleaning up upload file: %s", str(cleanup_error))
            
    return None

def download_resume(file_url):
    """Download resume file from Slack"""
    logging.debug("Attempting to download resume from URL: %s", file_url)
    try:
        headers = {"Authorization": f"Bearer {SLACK_BOT_TOKEN}"}
        res = requests.get(file_url, headers=headers, timeout=30)
        
        if res.status_code != 200:
            logging.error("File download failed: Status code %d", res.status_code)
            return None

        file_path = "temp.pdf"
        with open(file_path, "wb") as f:
            f.write(res.content)
            
        # Extract text from PDF
        text = ""
        with fitz.open(file_path) as doc:
            for page in doc:
                text += page.get_text()
                
        if not text.strip():
            logging.error("No text could be extracted from the PDF")
            return None
            
        logging.debug("Successfully extracted text from PDF, length: %d", len(text))
        return text
        
    except Exception as e:
        logging.error("Error downloading resume: %s", str(e), exc_info=True)
        return None

def analyze_resume(text, user_id=None):
    """Analyze resume text using GPT-4"""
    logging.debug("Starting resume analysis")
    try:
        openai_client = OpenAI(api_key=GPT_API_KEY)
        prompt = f"""
        ì´ë ¥ì„œë¥¼ ë¶„ì„í•˜ì—¬ ì •í™•íˆ ì•„ë˜ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì¶œë ¥í•˜ì„¸ìš”. ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”.

        ì´ë ¥ì„œ ë‚´ìš©:
        {text}

        *** ì¤‘ìš” ì§€ì¹¨ ***
        - ëª¨ë“  ì‘ë‹µì€ ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œ ì‘ì„±
        - ì˜ì–´ ë‹¨ì–´ë‚˜ ë¬¸ì¥ ì‚¬ìš© ê¸ˆì§€
        - ê¸°ìˆ ëª…ì€ ì›ë˜ ì˜ì–´ ê·¸ëŒ€ë¡œ ìœ ì§€ (ì˜ˆ: Python, JavaScript)
        - ë‚˜ë¨¸ì§€ ëª¨ë“  ì„¤ëª…ê³¼ ë‚´ìš©ì€ í•œêµ­ì–´ë¡œ ì‘ì„±

        ì‘ë‹µì€ ë°˜ë“œì‹œ ë‹¤ìŒ í˜•ì‹ì˜ JSONë§Œ ì¶œë ¥:
        {{
            "name": "ì´ë¦„ (ì—†ìœ¼ë©´ 'ë¯¸ê¸°ì¬'ë¡œ í‘œì‹œ)",
            "total_years": ìˆ«ìë§Œ_ì…ë ¥,
            "top_strengths": [
                "ê°•ì 1 (í•œêµ­ì–´ë¡œ)",
                "ê°•ì 2 (í•œêµ­ì–´ë¡œ)",
                "ê°•ì 3 (í•œêµ­ì–´ë¡œ)"
            ],
            "catchphrase": "í•œ ë¬¸ì¥ìœ¼ë¡œ ëœ ìºì¹˜í”„ë ˆì´ì¦ˆ (í•œêµ­ì–´ë¡œ)",
            "skill_cards": {{
                "domain_knowledge": "ë„ë©”ì¸ ì§€ì‹ ì„¤ëª… (í•œêµ­ì–´ë¡œ)",
                "tech_skills": "ê° ê¸°ìˆ ì˜ ìˆ™ë ¨ë„ë¥¼ ë°±ë¶„ìœ¨ë¡œ í‘œì‹œ (ì˜ˆ: Python: 90%, Java: 80%, JavaScript: 75%)",
                "soft_skills": "ì†Œí”„íŠ¸ ìŠ¤í‚¬ ì„¤ëª… (í•œêµ­ì–´ë¡œ)"
            }}
        }}"""

        logging.info("API ìš”ì²­ ì‹œì‘ - openai_client: %s", openai_client)
        logging.info("API ìš”ì²­ ë°ì´í„°: %s", text[:100] + "...")
        
        print("GPT API í˜¸ì¶œ ì‹œì‘...")
        response = openai_client.chat.completions.create(
            model="gpt-4",
            messages=[
                {"role": "system", "content": "You are a Korean resume analyzer. You MUST respond in Korean language ONLY. All descriptions, explanations, and content must be in Korean. Only technical terms (like programming languages, tools) can remain in English. Always output ONLY valid JSON format in Korean."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.3
        )
        print("GPT API í˜¸ì¶œ ì™„ë£Œ")

        result = response.choices[0].message.content.strip()
        print(f"ë¶„ì„ ê²°ê³¼: {result[:200]}...")

        # JSON í˜•ì‹ ê²€ì¦
        try:
            parsed_result = json.loads(result)
            return parsed_result
            
        except Exception as e:
            error_msg = f"ë¶„ì„ ê²°ê³¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
            print(error_msg)
            if user_id:
                send_dm(user_id, f"âŒ {error_msg}")
            return None

    except Exception as e:
        logging.error("Error analyzing resume: %s", str(e), exc_info=True)
        if user_id:
            send_dm(user_id, f"âŒ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return None

def analyze_jd(jd_text):
    """JD í…ìŠ¤íŠ¸ë¥¼ ë¶„ì„í•˜ì—¬ ìš”êµ¬ì‚¬í•­ ì¶”ì¶œ"""
    try:
        openai_client = OpenAI(api_key=GPT_API_KEY)
        prompt = f"""
        ë‹¤ìŒ ì±„ìš©ê³µê³ (JD)ë¥¼ ë¶„ì„í•˜ì—¬ JSON í˜•ì‹ìœ¼ë¡œ ìš”êµ¬ì‚¬í•­ì„ ì¶”ì¶œí•´ì£¼ì„¸ìš”:

        JD ë‚´ìš©:
        {jd_text}

        ë‹¤ìŒ í˜•ì‹ì˜ JSONë§Œ ì¶œë ¥:
        {{
            "position": "ì±„ìš© í¬ì§€ì…˜ëª…",
            "required_skills": ["í•„ìˆ˜ ê¸°ìˆ 1", "í•„ìˆ˜ ê¸°ìˆ 2", "í•„ìˆ˜ ê¸°ìˆ 3"],
            "preferred_skills": ["ìš°ëŒ€ ê¸°ìˆ 1", "ìš°ëŒ€ ê¸°ìˆ 2", "ìš°ëŒ€ ê¸°ìˆ 3"],
            "required_experience": ìµœì†Œê²½ë ¥ë…„ìˆ˜_ìˆ«ì,
            "preferred_experience": ìš°ëŒ€ê²½ë ¥ë…„ìˆ˜_ìˆ«ì,
            "education": "í•™ë ¥ ìš”êµ¬ì‚¬í•­",
            "responsibilities": ["ì£¼ìš” ì—…ë¬´1", "ì£¼ìš” ì—…ë¬´2", "ì£¼ìš” ì—…ë¬´3"],
            "company_culture": "íšŒì‚¬ ë¬¸í™”ë‚˜ ì¸ì¬ìƒ",
            "domain": "ì—…ë¬´ ë„ë©”ì¸ (ì˜ˆ: í•€í…Œí¬, ì´ì»¤ë¨¸ìŠ¤, AI ë“±)"
        }}
        """

        response = openai_client.chat.completions.create(
            model="gpt-4",
            messages=[
                {"role": "system", "content": "You are a JD analyzer that outputs ONLY valid JSON format."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.3
        )

        result = response.choices[0].message.content.strip()
        return json.loads(result)

    except Exception as e:
        logging.error(f"JD ë¶„ì„ ì˜¤ë¥˜: {str(e)}")
        return None

def calculate_matching_score(resume_result, jd_data, original_resume_text=None):
    """ì´ë ¥ì„œì™€ JD ë§¤ì¹­ ì ìˆ˜ ê³„ì‚° (ë²”ìš©ì  ì˜ë¯¸ì  ë§¤ì¹­)"""
    try:
        openai_client = OpenAI(api_key=GPT_API_KEY)
        
        # ë””ë²„ê¹…: ì…ë ¥ ë°ì´í„° ë¡œê¹…
        print("=== ë§¤ì¹­ ë¶„ì„ ë””ë²„ê¹… ì •ë³´ ===")
        print(f"ì´ë ¥ì„œ ìš”ì•½ ë°ì´í„°: {json.dumps(resume_result, ensure_ascii=False, indent=2)}")
        print(f"ì›ë³¸ ì´ë ¥ì„œ í…ìŠ¤íŠ¸ ê¸¸ì´: {len(original_resume_text) if original_resume_text else 0}ì")
        if original_resume_text:
            print(f"ì›ë³¸ ì´ë ¥ì„œ ìƒ˜í”Œ: {original_resume_text[:300]}...")
        print(f"JD ë°ì´í„°: {json.dumps(jd_data, ensure_ascii=False, indent=2)}")
        print("=" * 50)
        
        # ë²”ìš©ì ì´ê³  ì ê·¹ì ì¸ ì˜ë¯¸ì  ë§¤ì¹­ í”„ë¡¬í”„íŠ¸
        prompt = f"""
        ì´ë ¥ì„œì™€ JDë¥¼ ì˜ë¯¸ì ìœ¼ë¡œ ë§¤ì¹­ ë¶„ì„í•˜ì—¬ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì¶œë ¥í•˜ì„¸ìš”. ëª¨ë“  ì‘ë‹µì€ í•œêµ­ì–´ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.

        *** í•µì‹¬ ë§¤ì¹­ ì² í•™ ***
        1. ì—…ë¬´ì˜ ë³¸ì§ˆê³¼ ëª©ì ì´ ë¹„ìŠ·í•˜ë©´ í‚¤ì›Œë“œê°€ ë‹¬ë¼ë„ ë°˜ë“œì‹œ ë§¤ì¹­ìœ¼ë¡œ íŒë‹¨
        2. ì§ì ‘ì  ê²½í—˜ë¿ë§Œ ì•„ë‹ˆë¼ ê´€ë ¨ ê²½í—˜, ìœ ì‚¬ ê²½í—˜ë„ ì ê·¹ì ìœ¼ë¡œ ë§¤ì¹­ìœ¼ë¡œ ì¸ì •
        3. ë¶€ë¶„ì  ê²½í—˜ì´ë¼ë„ í•´ë‹¹ ë¶„ì•¼ì™€ ì—°ê´€ì„±ì´ ìˆìœ¼ë©´ ê¸ì •ì ìœ¼ë¡œ í‰ê°€
        4. ì˜ì‹¬ìŠ¤ëŸ¬ìš°ë©´ ë§¤ì¹­ìœ¼ë¡œ íŒë‹¨ (ë³´ìˆ˜ì ì´ì§€ ë§ê³  ì ê·¹ì ìœ¼ë¡œ ë§¤ì¹­)

        *** ì˜ë¯¸ì  ë§¤ì¹­ ê°€ì´ë“œë¼ì¸ ***
        - ë™ì˜ì–´ì™€ ìœ ì‚¬ í‘œí˜„ì„ ì ê·¹ì ìœ¼ë¡œ ì¸ì • (ì˜ˆ: ì†Œì‹±â†”ë°œêµ´, ê´€ë¦¬â†”ìš´ì˜, ê¸°íšâ†”ì„¤ê³„)
        - ìƒìœ„/í•˜ìœ„ ê°œë…ë„ ë§¤ì¹­ìœ¼ë¡œ ì¸ì • (ì˜ˆ: ì±„ìš© ê²½í—˜ â†’ ì¸ì¬ ê´€ë ¨ ì—…ë¬´ ë§¤ì¹­)
        - ì—…ë¬´ ë§¥ë½ì´ ë¹„ìŠ·í•˜ë©´ ë§¤ì¹­ (ì˜ˆ: êµìœ¡/ë©˜í† ë§ â†’ ì‚¬ëŒ ê´€ë¦¬ ê´€ë ¨ ì—…ë¬´)
        - ë„êµ¬ë‚˜ ë°©ë²•ë¡ ì˜ ì°¨ì´ëŠ” ë¬´ì‹œí•˜ê³  ì—…ë¬´ ëª©ì ì— ì§‘ì¤‘
        - ì˜ì–´/í•œêµ­ì–´ í˜¼ìš© í‘œí˜„ì˜ ì˜ë¯¸ì  ë™ì¼ì„± ì¸ì •

        *** ì ê·¹ì  ë§¤ì¹­ ì›ì¹™ ***
        - ì´ë ¥ì„œì—ì„œ ê´€ë ¨ í‚¤ì›Œë“œë‚˜ ë§¥ë½ì„ ì°¾ì•˜ë‹¤ë©´ "ë§¤ì¹­ ì—†ìŒ"ì´ ì•„ë‹Œ "ë§¤ì¹­ ìˆìŒ"ìœ¼ë¡œ íŒë‹¨
        - JD ìš”êµ¬ì‚¬í•­ì˜ í•µì‹¬ ì—…ë¬´ì™€ ì´ë ¥ì„œ ê²½í—˜ì˜ í•µì‹¬ì´ ê²¹ì¹˜ë©´ ë§¤ì¹­
        - ì™„ë²½í•œ ì¼ì¹˜ë¥¼ ìš”êµ¬í•˜ì§€ ë§ê³ , ì—°ê´€ì„±ê³¼ ì „ì´ ê°€ëŠ¥ì„±ì— ì§‘ì¤‘
        - ë§¤ì¹­ ì—¬ë¶€ë¥¼ íŒë‹¨í•  ë•Œ ê¸ì •ì  í¸ê²¬ì„ ê°€ì§€ê³  ë¶„ì„

        *** ì´ë ¥ì„œ ë¶„ì„ ë°ì´í„° ***
        ì´ë ¥ì„œ ìš”ì•½:
        {json.dumps(resume_result, ensure_ascii=False, indent=2)}

        ì›ë³¸ ì´ë ¥ì„œ ì „ì²´ ë‚´ìš©:
        {original_resume_text if original_resume_text else "ì›ë³¸ ì´ë ¥ì„œ í…ìŠ¤íŠ¸ ë¯¸ì œê³µ"}

        JD ì •ë³´:
        {json.dumps(jd_data, ensure_ascii=False, indent=2)}

        *** ë¶„ì„ í”„ë¡œì„¸ìŠ¤ ***
        1. JDì˜ ê° ìš”êµ¬ì‚¬í•­ì„ í•˜ë‚˜ì”© ë¶„ì„
        2. ì´ë ¥ì„œ ìš”ì•½ê³¼ ì›ë³¸ ì´ë ¥ì„œ ì „ì²´ì—ì„œ í•´ë‹¹ ìš”êµ¬ì‚¬í•­ê³¼ ì˜ë¯¸ì ìœ¼ë¡œ ì—°ê´€ë  ìˆ˜ ìˆëŠ” ëª¨ë“  ê²½í—˜ íƒìƒ‰
        3. ì§ì ‘ì  ë§¤ì¹­ + ê°„ì ‘ì  ë§¤ì¹­ + ì „ì´ ê°€ëŠ¥í•œ ê²½í—˜ ëª¨ë‘ ê³ ë ¤
        4. ì¡°ê¸ˆì´ë¼ë„ ê´€ë ¨ì„±ì´ ìˆë‹¤ë©´ ë§¤ì¹­ìœ¼ë¡œ íŒë‹¨
        5. ë§¤ì¹­ëœ ê²½ìš° êµ¬ì²´ì ì¸ ê·¼ê±°ì™€ ì„¤ëª… ì œê³µ

        ë°˜ë“œì‹œ ì•„ë˜ JSON í˜•ì‹ë§Œ ì¶œë ¥í•˜ì„¸ìš”:
        {{
            "step1_mapping": {{
                ê°_JD_ìš”êµ¬ì‚¬í•­ì—_ëŒ€í•´: {{
                    "matched": true_or_false,
                    "resume_evidence": "ì´ë ¥ì„œì—ì„œ ì°¾ì€ ê´€ë ¨ ê²½í—˜ (êµ¬ì²´ì ìœ¼ë¡œ)",
                    "explanation": "ë§¤ì¹­ íŒë‹¨ì˜ ë…¼ë¦¬ì  ê·¼ê±°ì™€ ì—°ê´€ì„± ì„¤ëª…"
                }}
            }},
            "overall_score": ì ì ˆí•œ_ì ìˆ˜,
            "skill_match": {{
                "required_skills_score": ì ìˆ˜,
                "preferred_skills_score": ì ìˆ˜,
                "matched_skills": ["ë§¤ì¹­ëœ ìš”êµ¬ì‚¬í•­ë“¤"],
                "missing_skills": ["ì •ë§ë¡œ ê´€ë ¨ ê²½í—˜ì´ ì „í˜€ ì—†ëŠ” ìš”êµ¬ì‚¬í•­ë“¤ë§Œ"],
                "skill_mapping": {{
                    "ë§¤ì¹­ëœ_ìš”êµ¬ì‚¬í•­": "í•´ë‹¹_ì´ë ¥ì„œ_ê²½í—˜"
                }}
            }},
            "experience_match": {{
                "score": ì ìˆ˜,
                "candidate_years": {resume_result.get('total_years', 0)},
                "required_years": {jd_data.get('required_experience', 0)},
                "assessment": "ê²½ë ¥ ìˆ˜ì¤€ í‰ê°€"
            }},
            "domain_match": {{
                "score": ì ìˆ˜,
                "assessment": "ë„ë©”ì¸ ì í•©ì„± í‰ê°€"
            }},
            "culture_match": {{
                "score": ì ìˆ˜,
                "assessment": "ë¬¸í™” ì í•©ì„± í‰ê°€"
            }},
            "strengths": ["ë§¤ì¹­ëœ ê²½í—˜ ê¸°ë°˜ ê°•ì ë“¤"],
            "improvement_areas": ["ì‹¤ì œë¡œ ë¶€ì¡±í•œ ì˜ì—­ë§Œ"],
            "recommendation": "ê· í˜•ìˆê³  ê±´ì„¤ì ì¸ ì¶”ì²œ ì˜ê²¬",
            "detailed_analysis": {{
                "resume_highlights": ["JDì™€ ë§¤ì¹­ë˜ëŠ” ì£¼ìš” ê²½í—˜ë“¤"],
                "jd_coverage": "JD ìš”êµ¬ì‚¬í•­ ì»¤ë²„ë¦¬ì§€ ë¶„ì„",
                "gap_analysis": "ì‹¤ì œ ë³´ì™„ í•„ìš” ì˜ì—­"
            }}
        }}
        """

        logging.info("ì ê·¹ì  ì˜ë¯¸ì  ë§¤ì¹­ ë¶„ì„ API í˜¸ì¶œ ì‹œì‘")
        logging.info(f"ì „ì²´ í”„ë¡¬í”„íŠ¸: {prompt}")
        
        print("GPT API í˜¸ì¶œ ì‹œì‘ (ì ê·¹ì  ì˜ë¯¸ì  ë§¤ì¹­)...")
        response = openai_client.chat.completions.create(
            model="gpt-4",
            messages=[
                {"role": "system", "content": "You are an expert Korean HR analyst specializing in AGGRESSIVE SEMANTIC MATCHING. Your core principle: when in doubt, match it. Look for ANY possible connection between resume experiences and JD requirements. Be extremely generous and positive in recognizing relevant experience. Focus on transferable skills, related competencies, and the essence of work rather than exact keywords. If there's even 30% relevance, mark it as matched. Always respond in Korean. Be an advocate for the candidate."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.3  # ì°½ì˜ì  ì—°ê²°ì„ ìœ„í•´ ì•½ê°„ ë†’ì„
        )
        print("GPT API í˜¸ì¶œ ì™„ë£Œ")

        result = response.choices[0].message.content.strip()
        
        # ë””ë²„ê¹…: GPT ì‘ë‹µ ì „ì²´ ë¡œê¹…
        print("=== GPT ì‘ë‹µ ì „ì²´ ===")
        print(result)
        print("=" * 50)
        
        logging.info(f"ì ê·¹ì  ì˜ë¯¸ì  ë§¤ì¹­ ë¶„ì„ ê²°ê³¼: {result}")
        
        # JSON í˜•ì‹ ì •ë¦¬ (ë” ê°•í™”ëœ íŒŒì‹±)
        cleaned_result = result.strip()
        
        # ì½”ë“œ ë¸”ë¡ ì œê±°
        if cleaned_result.startswith("```json"):
            cleaned_result = cleaned_result[7:]  # "```json" ì œê±°
        elif cleaned_result.startswith("```"):
            cleaned_result = cleaned_result[3:]   # "```" ì œê±°
            
        if cleaned_result.endswith("```"):
            cleaned_result = cleaned_result[:-3]  # ëì˜ "```" ì œê±°
            
        # JSON ì‹œì‘ê³¼ ë ì°¾ê¸°
        start_idx = cleaned_result.find("{")
        end_idx = cleaned_result.rfind("}")
        
        if start_idx != -1 and end_idx != -1 and start_idx < end_idx:
            cleaned_result = cleaned_result[start_idx:end_idx+1]
        
        logging.info(f"ì •ë¦¬ëœ JSON: {cleaned_result[:200]}...")
        
        # JSON íŒŒì‹±
        try:
            parsed_result = json.loads(cleaned_result)
            logging.info("ì ê·¹ì  ì˜ë¯¸ì  ë§¤ì¹­ ë¶„ì„ ì„±ê³µì ìœ¼ë¡œ íŒŒì‹±ë¨")
            return parsed_result
        except json.JSONDecodeError as json_err:
            logging.error(f"JSON íŒŒì‹± ì‹¤íŒ¨: {str(json_err)}")
            logging.error(f"ì›ë³¸ ì‘ë‹µ: {result}")
            logging.error(f"ì •ë¦¬ëœ ì‘ë‹µ: {cleaned_result}")
            
            # JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ None ë°˜í™˜í•˜ì—¬ ì—ëŸ¬ ì²˜ë¦¬
            return None

    except Exception as e:
        logging.error(f"ë§¤ì¹­ ì ìˆ˜ ê³„ì‚° ì˜¤ë¥˜: {str(e)}")
        return None

def create_jd_analysis_blocks(jd_data, jd_name=None):
    """JD ë¶„ì„ ê²°ê³¼ë¥¼ Slack ë¸”ë¡ìœ¼ë¡œ ë³€í™˜"""
    title = f"ğŸ“‹ JD ë¶„ì„ ê²°ê³¼"
    if jd_name:
        title += f": {jd_name}"
    else:
        title += f": {jd_data.get('position', 'N/A')}"
    
    blocks = [
        {
            "type": "header",
            "text": {
                "type": "plain_text",
                "text": title,
                "emoji": True
            }
        },
        {
            "type": "divider"
        },
        {
            "type": "section",
            "text": {
                "type": "mrkdwn",
                "text": f"*ğŸ¢ ë„ë©”ì¸:* {jd_data.get('domain', 'N/A')}\n*ğŸ“… ìš”êµ¬ ê²½ë ¥:* {jd_data.get('required_experience', 'N/A')}ë…„ ì´ìƒ"
            }
        },
        {
            "type": "section",
            "text": {
                "type": "mrkdwn",
                "text": "*ğŸ’» í•„ìˆ˜ ê¸°ìˆ *"
            }
        }
    ]
    
    # í•„ìˆ˜ ê¸°ìˆ 
    for skill in jd_data.get('required_skills', []):
        blocks.append({
            "type": "section",
            "text": {
                "type": "mrkdwn",
                "text": f"â€¢ {skill}"
            }
        })
    
    # ìš°ëŒ€ ê¸°ìˆ 
    if jd_data.get('preferred_skills'):
        blocks.extend([
            {
                "type": "section",
                "text": {
                    "type": "mrkdwn",
                    "text": "*â­ ìš°ëŒ€ ê¸°ìˆ *"
                }
            }
        ])
        
        for skill in jd_data.get('preferred_skills', []):
            blocks.append({
                "type": "section",
                "text": {
                    "type": "mrkdwn",
                    "text": f"â€¢ {skill}"
                }
            })
    
    # ì£¼ìš” ì—…ë¬´
    if jd_data.get('responsibilities'):
        blocks.extend([
            {
                "type": "divider"
            },
            {
                "type": "section",
                "text": {
                    "type": "mrkdwn",
                    "text": "*ğŸ¯ ì£¼ìš” ì—…ë¬´*"
                }
            }
        ])
        
        for responsibility in jd_data.get('responsibilities', []):
            blocks.append({
                "type": "section",
                "text": {
                    "type": "mrkdwn",
                    "text": f"â€¢ {responsibility}"
                }
            })
    
    blocks.extend([
        {
            "type": "divider"
        },
        {
            "type": "context",
            "elements": [
                {
                    "type": "mrkdwn",
                    "text": "âœ… JD ë“±ë¡ ì™„ë£Œ! ì´ì œ ì´ë ¥ì„œë¥¼ ì—…ë¡œë“œí•˜ë©´ ë§¤ì¹­ ë¶„ì„ì„ ì§„í–‰í•©ë‹ˆë‹¤."
                }
            ]
        }
    ])
    
    return blocks

def create_matching_result_blocks(matching_result, jd_data, jd_name=None):
    """ë§¤ì¹­ ê²°ê³¼ë¥¼ Slack ë¸”ë¡ìœ¼ë¡œ ë³€í™˜ (ì´ì „ ì™„ë²½ ë²„ì „)"""
    overall_score = matching_result.get('overall_score', 0)
    
    # ì ìˆ˜ì— ë”°ë¥¸ ìƒ‰ìƒ ê²°ì •
    if overall_score >= 80:
        color = "ğŸŸ¢"
        status = "ë§¤ìš° ì í•©"
    elif overall_score >= 60:
        color = "ğŸŸ¡"
        status = "ì í•©"
    elif overall_score >= 40:
        color = "ğŸŸ "
        status = "ë³´í†µ"
    else:
        color = "ğŸ”´"
        status = "ë¶€ì¡±"
    
    # í—¤ë” ì œëª© ì„¤ì •
    header_title = "ğŸ¯ JD ë§¤ì¹­ ë¶„ì„ ê²°ê³¼"
    if jd_name:
        header_title += f" ({jd_name})"
    
    blocks = [
        {
            "type": "header",
            "text": {
                "type": "plain_text",
                "text": header_title,
                "emoji": True
            }
        },
        {
            "type": "section",
            "text": {
                "type": "mrkdwn",
                "text": f"*ğŸ“Š ì „ì²´ ë§¤ì¹­ ì ìˆ˜*\n{color} **{overall_score}ì ** ({status})"
            }
        },
        {
            "type": "divider"
        }
    ]
    
    # ì„¸ë¶€ ì ìˆ˜
    skill_match = matching_result.get('skill_match', {})
    experience_match = matching_result.get('experience_match', {})
    domain_match = matching_result.get('domain_match', {})
    
    blocks.append({
        "type": "section",
        "fields": [
            {
                "type": "mrkdwn",
                "text": f"*ğŸ’» í•„ìˆ˜ê¸°ìˆ  ë§¤ì¹­*\n{skill_match.get('required_skills_score', 0)}ì "
            },
            {
                "type": "mrkdwn",
                "text": f"*ğŸ“… ê²½ë ¥ ë§¤ì¹­*\n{experience_match.get('score', 0)}ì "
            },
            {
                "type": "mrkdwn",
                "text": f"*ğŸ¢ ë„ë©”ì¸ ë§¤ì¹­*\n{domain_match.get('score', 0)}ì "
            },
            {
                "type": "mrkdwn",
                "text": f"*â­ ìš°ëŒ€ê¸°ìˆ  ë§¤ì¹­*\n{skill_match.get('preferred_skills_score', 0)}ì "
            }
        ]
    })
    
    # ìŠ¤í‚¬ ë§¤í•‘ ì •ë³´ (ìƒˆë¡œ ì¶”ê°€)
    if skill_match.get('skill_mapping'):
        blocks.extend([
            {
                "type": "section",
                "text": {
                    "type": "mrkdwn",
                    "text": "*ğŸ” ìƒì„¸ ë§¤ì¹­ ë¶„ì„*"
                }
            }
        ])
        
        # step1_mapping ì •ë³´ í‘œì‹œ (ë” íˆ¬ëª…í•œ ë¶„ì„)
        if matching_result.get('step1_mapping'):
            for jd_req, mapping_info in matching_result['step1_mapping'].items():
                status_icon = "âœ…" if mapping_info.get('matched') else "âŒ"
                evidence = mapping_info.get('resume_evidence', 'N/A')
                explanation = mapping_info.get('explanation', 'N/A')
                
                blocks.append({
                    "type": "section",
                    "text": {
                        "type": "mrkdwn",
                        "text": f"{status_icon} *{jd_req}*\nğŸ“‹ ì¦ê±°: {evidence}\nğŸ’­ íŒë‹¨: {explanation}"
                    }
                })
        else:
            # ê¸°ì¡´ skill_mapping ë°©ì‹ (fallback)
            skill_mapping = skill_match.get('skill_mapping', {})
            for jd_requirement, resume_experience in skill_mapping.items():
                if jd_requirement != "JDìš”êµ¬ì‚¬í•­":  # í—¤ë” ì œì™¸
                    blocks.append({
                        "type": "section",
                        "text": {
                            "type": "mrkdwn",
                            "text": f"â€¢ *{jd_requirement}*\n  âœ“ {resume_experience}"
                        }
                    })
    
    # ë§¤ì¹­ëœ ê¸°ìˆ 
    if skill_match.get('matched_skills'):
        blocks.extend([
            {
                "type": "section",
                "text": {
                    "type": "mrkdwn",
                    "text": "*âœ… ë§¤ì¹­ëœ ê¸°ìˆ *"
                }
            },
            {
                "type": "section",
                "text": {
                    "type": "mrkdwn",
                    "text": "â€¢ " + "\nâ€¢ ".join(skill_match.get('matched_skills', []))
                }
            }
        ])
    
    # ë¶€ì¡±í•œ ê¸°ìˆ  (ì •ë§ ë¶€ì¡±í•œ ê²ƒë§Œ)
    if skill_match.get('missing_skills'):
        blocks.extend([
            {
                "type": "section",
                "text": {
                    "type": "mrkdwn",
                    "text": "*âš ï¸ ì¶”ê°€ ë³´ì™„ í•„ìš”*"
                }
            },
            {
                "type": "section",
                "text": {
                    "type": "mrkdwn",
                    "text": "â€¢ " + "\nâ€¢ ".join(skill_match.get('missing_skills', []))
                }
            }
        ])
    
    # ê°•ì 
    if matching_result.get('strengths'):
        blocks.extend([
            {
                "type": "divider"
            },
            {
                "type": "section",
                "text": {
                    "type": "mrkdwn",
                    "text": "*ğŸš€ ì´ í¬ì§€ì…˜ì—ì„œì˜ ê°•ì *"
                }
            },
            {
                "type": "section",
                "text": {
                    "type": "mrkdwn",
                    "text": "â€¢ " + "\nâ€¢ ".join(matching_result.get('strengths', []))
                }
            }
        ])
    
    # ê°œì„  ì˜ì—­
    if matching_result.get('improvement_areas'):
        blocks.extend([
            {
                "type": "section",
                "text": {
                    "type": "mrkdwn",
                    "text": "*ğŸ“ˆ ê°œì„ ì´ í•„ìš”í•œ ì˜ì—­*"
                }
            },
            {
                "type": "section",
                "text": {
                    "type": "mrkdwn",
                    "text": "â€¢ " + "\nâ€¢ ".join(matching_result.get('improvement_areas', []))
                }
            }
        ])
    
    # ìƒì„¸ ë¶„ì„ (ìƒˆë¡œ ì¶”ê°€)
    detailed_analysis = matching_result.get('detailed_analysis', {})
    if detailed_analysis:
        blocks.extend([
            {
                "type": "divider"
            },
            {
                "type": "section",
                "text": {
                    "type": "mrkdwn",
                    "text": "*ğŸ“‹ ìƒì„¸ ë¶„ì„*"
                }
            }
        ])
        
        if detailed_analysis.get('resume_highlights'):
            blocks.append({
                "type": "section",
                "text": {
                    "type": "mrkdwn",
                    "text": f"*ì£¼ëª©í•  ë§Œí•œ ê²½í—˜*\nâ€¢ " + "\nâ€¢ ".join(detailed_analysis.get('resume_highlights', []))
                }
            })
        
        if detailed_analysis.get('jd_coverage'):
            blocks.append({
                "type": "section",
                "text": {
                    "type": "mrkdwn",
                    "text": f"*JD ì»¤ë²„ë¦¬ì§€*\n{detailed_analysis.get('jd_coverage', 'N/A')}"
                }
            })
    
    # ì¶”ì²œ ì˜ê²¬
    if matching_result.get('recommendation'):
        blocks.extend([
            {
                "type": "divider"
            },
            {
                "type": "section",
                "text": {
                    "type": "mrkdwn",
                    "text": f"*ğŸ’¡ ì¶”ì²œ ì˜ê²¬*\n_{matching_result.get('recommendation', 'N/A')}_"
                }
            }
        ])
    
    # PDF ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ ì¶”ê°€ (JD ë§¤ì¹­ ë¶„ì„ìš©)
    blocks.extend([
        {
            "type": "divider"
        },
        {
            "type": "section",
            "text": {
                "type": "mrkdwn",
                "text": "*ğŸ“Š ì¶”ê°€ ì•¡ì…˜*"
            }
        },
        {
            "type": "actions",
            "elements": [
                {
                    "type": "button",
                    "text": {
                        "type": "plain_text",
                        "text": "ğŸ“„ PDF ë³´ê³ ì„œ ë‹¤ìš´ë¡œë“œ",
                        "emoji": True
                    },
                    "action_id": "generate_pdf_report",
                    "style": "primary"
                }
            ]
        },
        {
            "type": "context",
            "elements": [
                {
                    "type": "mrkdwn",
                    "text": "âœ… JD ë§¤ì¹­ ë¶„ì„ ì™„ë£Œ! PDF ë³´ê³ ì„œì—ëŠ” ë§¤ì¹­ ë¶„ì„ ê²°ê³¼ê°€ í¬í•¨ë©ë‹ˆë‹¤."
                }
            ]
        }
    ])
    
    return blocks

def trigger_jd_registration(user_id):
    """JD ë“±ë¡ í”„ë¡œì„¸ìŠ¤ë¥¼ ì‹œì‘í•˜ëŠ” í•¨ìˆ˜"""
    try:
        help_message = """
ğŸ“‹ **JD ë“±ë¡ í”„ë¡œì„¸ìŠ¤**

ë‹¤ìŒ ë‹¨ê³„ë¡œ JDë¥¼ ë“±ë¡í•´ì£¼ì„¸ìš”:

1ï¸âƒ£ **JD ì´ë¦„ì„ ì…ë ¥í•˜ì„¸ìš”** (ì˜ˆ: "ì±„ìš©ë‹´ë‹¹ì", "ì„œë¹„ìŠ¤ê¸°íšì")
2ï¸âƒ£ **ì±„ìš©ê³µê³  ì „ë¬¸ì„ ë³µì‚¬í•´ì„œ ë³´ë‚´ì£¼ì„¸ìš”**

JD ì´ë¦„ì„ ë¨¼ì € ë³´ë‚´ì£¼ì‹œë©´, ë‹¤ìŒì— ë°›ëŠ” ë©”ì‹œì§€ë¥¼ ì±„ìš©ê³µê³ ë¡œ ì¸ì‹í•˜ì—¬ ë¶„ì„í•©ë‹ˆë‹¤.

ì˜ˆì‹œ:
```
ì±„ìš©ë‹´ë‹¹ì
```
        """
        send_dm(user_id, help_message.strip())
        
        # ì‚¬ìš©ì ìƒíƒœë¥¼ JD ë“±ë¡ ëª¨ë“œë¡œ ì„¤ì •
        if user_id not in stored_jd:
            stored_jd[user_id] = {}
        stored_jd[user_id]["_registration_mode"] = "waiting_for_jd_name"
        
    except Exception as e:
        logging.error(f"JD ë“±ë¡ íŠ¸ë¦¬ê±° ì˜¤ë¥˜: {str(e)}")
        send_dm(user_id, "âŒ JD ë“±ë¡ í”„ë¡œì„¸ìŠ¤ ì‹œì‘ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")

def perform_complete_analysis(user_id, file_url, jd_name=None):
    """ì´ë ¥ì„œ ë¶„ì„ê³¼ JD ë§¤ì¹­ì„ í†µí•©í•´ì„œ ìˆ˜í–‰í•˜ëŠ” í•¨ìˆ˜"""
    try:
        # ì´ë ¥ì„œ ë‹¤ìš´ë¡œë“œ ë° í…ìŠ¤íŠ¸ ì¶”ì¶œ
        resume_text = download_resume(file_url)
        if not resume_text:
            send_dm(user_id, "âŒ ì´ë ¥ì„œ ë‹¤ìš´ë¡œë“œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
            return False
            
        # ì´ë ¥ì„œ ë¶„ì„
        parsed_result = analyze_resume(resume_text, user_id)
        if not parsed_result:
            send_dm(user_id, "âŒ ì´ë ¥ì„œ ë¶„ì„ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
            return False
        
        # ì „ì—­ ë³€ìˆ˜ì— ì €ì¥ (PDF ìƒì„±ìš©)
        global last_analysis_result, last_analysis_user_id
        last_analysis_result = parsed_result
        last_analysis_user_id = user_id
        
        # ê¸°ìˆ  ìŠ¤í‚¬ ì°¨íŠ¸ ìƒì„± ë° ì—…ë¡œë“œ
        tech_skills = parsed_result.get("skill_cards", {}).get("tech_skills", "")
        skills_dict = parse_skills(tech_skills)
        
        if skills_dict:
            chart_bytes = create_plotly_radar_chart(skills_dict)
            if chart_bytes:
                try:
                    dm_response = client.conversations_open(users=[user_id])
                    if dm_response.get("ok"):
                        dm_channel_id = dm_response["channel"]["id"]
                        file_id = upload_image_to_slack(chart_bytes, "Technical Skills Radar Chart", dm_channel_id)
                        if not file_id:
                            logging.error("Failed to upload chart")
                except Exception as e:
                    logging.error(f"Chart upload error: {str(e)}")
        
        # ì´ë ¥ì„œ ë¶„ì„ ê²°ê³¼ ì „ì†¡
        blocks = create_stat_card_blocks(parsed_result)
        send_dm(user_id, "âœ… ì´ë ¥ì„œ ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.", blocks=blocks)
        
        # JD ë§¤ì¹­ ë¶„ì„ (ì„ íƒëœ JDê°€ ìˆëŠ” ê²½ìš°)
        if jd_name and user_id in stored_jd and jd_name in stored_jd[user_id]:
            send_dm(user_id, f"ğŸ¯ **{jd_name}** JDì™€ì˜ ë§¤ì¹­ ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
            
            jd_data = stored_jd[user_id][jd_name]
            matching_result = calculate_matching_score(parsed_result, jd_data, resume_text)
            
            if matching_result:
                matching_blocks = create_matching_result_blocks(matching_result, jd_data, jd_name)
                send_dm(user_id, f"ğŸ¯ **{jd_name}** JD ë§¤ì¹­ ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!", blocks=matching_blocks)
            else:
                send_dm(user_id, "âŒ JD ë§¤ì¹­ ë¶„ì„ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
        elif user_id in stored_jd:
            # JDëŠ” ìˆì§€ë§Œ ì„ íƒë˜ì§€ ì•Šì€ ê²½ìš° ì•ˆë‚´
            user_jds = [name for name in stored_jd[user_id].keys() if not name.startswith("_")]
            if user_jds:
                send_dm(user_id, f"ğŸ’¡ ë“±ë¡ëœ JD({', '.join(user_jds)})ì™€ì˜ ë§¤ì¹­ ë¶„ì„ì„ ì›í•˜ì‹œë©´ JDë¥¼ ì„ íƒí•´ì„œ ë¶„ì„í•´ì£¼ì„¸ìš”.")
        
        return True
        
    except Exception as e:
        logging.error(f"Complete analysis error: {str(e)}")
        send_dm(user_id, f"âŒ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return False

# Modal ëŒ€ì‹œë³´ë“œ ê´€ë ¨ í•¨ìˆ˜ë“¤ ì¶”ê°€
def get_all_resumes_from_notion():
    """Notion DBì—ì„œ ëª¨ë“  ì´ë ¥ì„œ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜"""
    try:
        results = notion.databases.query(
            database_id=NOTION_DATABASE_ID
        )
        return results.get('results', [])
    except Exception as e:
        logging.error(f"Notion DB ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return []

def parse_notion_resume_data(notion_pages):
    """Notion í˜ì´ì§€ ë°ì´í„°ë¥¼ íŒŒì‹±í•˜ì—¬ ëŒ€ì‹œë³´ë“œìš© ë°ì´í„°ë¡œ ë³€í™˜"""
    parsed_data = []
    
    for page in notion_pages:
        try:
            properties = page.get('properties', {})
            
            # ê¸°ë³¸ ì •ë³´ ì¶”ì¶œ
            name = "ë¯¸ê¸°ì¬"
            if properties.get('ì„±ëª…', {}).get('title'):
                name = properties['ì„±ëª…']['title'][0]['text']['content']
            
            # ê²½ë ¥ ì—°ì°¨ ì¶”ì¶œ
            years = 0
            career_text = ""
            if properties.get('ê²½ë ¥ê¸°ê°„', {}).get('rich_text'):
                career_text = properties['ê²½ë ¥ê¸°ê°„']['rich_text'][0]['text']['content']
                # ìˆ«ì ì¶”ì¶œ (ì˜ˆ: "6ë…„" -> 6)
                years_match = re.search(r'(\d+)', career_text)
                if years_match:
                    years = int(years_match.group(1))
            
            # ë§¤ì¹­ë¥  ì¶”ì¶œ (ìˆëŠ” ê²½ìš°)
            matching_score = 0
            if properties.get('ë§¤ì¹­ë¥ ', {}).get('number'):
                matching_score = properties['ë§¤ì¹­ë¥ ']['number']
            
            # ì§ë¬´ ë¶„ë¥˜ (í‚¤ì›Œë“œ ê¸°ë°˜ìœ¼ë¡œ ì¶”ì •)
            job_category = "ê¸°íƒ€"
            strengths_text = ""
            if properties.get('ê°•ì  Top3', {}).get('rich_text'):
                strengths_text = properties['ê°•ì  Top3']['rich_text'][0]['text']['content']
                
            # ê¸°ìˆ ìŠ¤íƒ ì¶”ì¶œ
            tech_skills = ""
            if properties.get('ê¸°ìˆ ìŠ¤íƒ', {}).get('rich_text'):
                tech_skills = properties['ê¸°ìˆ ìŠ¤íƒ']['rich_text'][0]['text']['content']
            
            # ì§ë¬´ ë¶„ë¥˜ ë¡œì§
            combined_text = (strengths_text + " " + tech_skills).lower()
            if any(keyword in combined_text for keyword in ['ê°œë°œ', 'developer', 'programming', 'coding', 'python', 'javascript', 'java']):
                job_category = "ê°œë°œì"
            elif any(keyword in combined_text for keyword in ['ê¸°íš', 'pm', 'product', 'manager', 'í”„ë¡œë•íŠ¸']):
                job_category = "PM/ê¸°íšì"
            elif any(keyword in combined_text for keyword in ['ë””ìì¸', 'design', 'ui', 'ux', 'figma']):
                job_category = "ë””ìì´ë„ˆ"
            elif any(keyword in combined_text for keyword in ['ì±„ìš©', 'hr', 'ì¸ì‚¬', 'recruiting']):
                job_category = "HR/ì±„ìš©"
            elif any(keyword in combined_text for keyword in ['ë§ˆì¼€íŒ…', 'marketing', 'ê´‘ê³ ']):
                job_category = "ë§ˆì¼€íŒ…"
            
            # ë¶„ì„ ì¼ì‹œ
            created_time = page.get('created_time', '')
            
            parsed_data.append({
                'id': page['id'],
                'name': name,
                'years': years,
                'career_text': career_text,
                'job_category': job_category,
                'matching_score': matching_score,
                'strengths': strengths_text,
                'tech_skills': tech_skills,
                'created_time': created_time,
                'notion_url': f"https://www.notion.so/{page['id'].replace('-', '')}"
            })
            
        except Exception as e:
            logging.error(f"í˜ì´ì§€ íŒŒì‹± ì¤‘ ì˜¤ë¥˜: {str(e)}")
            continue
    
    return parsed_data

def create_dashboard_modal():
    """ëŒ€ì‹œë³´ë“œ Modal UI ìƒì„±"""
    return {
        "type": "modal",
        "callback_id": "dashboard_modal",
        "title": {
            "type": "plain_text",
            "text": "ğŸ“Š ì´ë ¥ì„œ ëŒ€ì‹œë³´ë“œ"
        },
        "blocks": [
            {
                "type": "section",
                "text": {
                    "type": "mrkdwn",
                    "text": "*ì´ë ¥ì„œ ë¶„ì„ ê²°ê³¼ë¥¼ í•œëˆˆì— í™•ì¸í•˜ì„¸ìš”!* ğŸš€"
                }
            },
            {
                "type": "divider"
            },
            {
                "type": "input",
                "block_id": "job_filter",
                "element": {
                    "type": "static_select",
                    "placeholder": {
                        "type": "plain_text",
                        "text": "ì§ë¬´ ì„ íƒ"
                    },
                    "options": [
                        {
                            "text": {
                                "type": "plain_text",
                                "text": "ì „ì²´"
                            },
                            "value": "all"
                        },
                        {
                            "text": {
                                "type": "plain_text",
                                "text": "ê°œë°œì"
                            },
                            "value": "developer"
                        },
                        {
                            "text": {
                                "type": "plain_text",
                                "text": "PM/ê¸°íšì"
                            },
                            "value": "pm"
                        },
                        {
                            "text": {
                                "type": "plain_text",
                                "text": "ë””ìì´ë„ˆ"
                            },
                            "value": "designer"
                        },
                        {
                            "text": {
                                "type": "plain_text",
                                "text": "HR/ì±„ìš©"
                            },
                            "value": "hr"
                        },
                        {
                            "text": {
                                "type": "plain_text",
                                "text": "ë§ˆì¼€íŒ…"
                            },
                            "value": "marketing"
                        }
                    ],
                    "action_id": "select_job"
                },
                "label": {
                    "type": "plain_text",
                    "text": "ì§ë¬´ í•„í„°"
                }
            },
            {
                "type": "input",
                "block_id": "years_filter",
                "element": {
                    "type": "static_select",
                    "placeholder": {
                        "type": "plain_text",
                        "text": "ê²½ë ¥ ì„ íƒ"
                    },
                    "options": [
                        {
                            "text": {
                                "type": "plain_text",
                                "text": "ì „ì²´"
                            },
                            "value": "all"
                        },
                        {
                            "text": {
                                "type": "plain_text",
                                "text": "ì‹ ì… (0-1ë…„)"
                            },
                            "value": "0-1"
                        },
                        {
                            "text": {
                                "type": "plain_text",
                                "text": "ì£¼ë‹ˆì–´ (2-3ë…„)"
                            },
                            "value": "2-3"
                        },
                        {
                            "text": {
                                "type": "plain_text",
                                "text": "ë¯¸ë“œë ˆë²¨ (4-6ë…„)"
                            },
                            "value": "4-6"
                        },
                        {
                            "text": {
                                "type": "plain_text",
                                "text": "ì‹œë‹ˆì–´ (7ë…„+)"
                            },
                            "value": "7+"
                        }
                    ],
                    "action_id": "select_years"
                },
                "label": {
                    "type": "plain_text",
                    "text": "ê²½ë ¥ í•„í„°"
                }
            },
            {
                "type": "input",
                "block_id": "sort_filter",
                "element": {
                    "type": "static_select",
                    "placeholder": {
                        "type": "plain_text",
                        "text": "ì •ë ¬ ê¸°ì¤€"
                    },
                    "options": [
                        {
                            "text": {
                                "type": "plain_text",
                                "text": "ìµœì‹ ìˆœ"
                            },
                            "value": "latest"
                        },
                        {
                            "text": {
                                "type": "plain_text",
                                "text": "ë§¤ì¹­ë¥  ë†’ì€ìˆœ"
                            },
                            "value": "matching_desc"
                        },
                        {
                            "text": {
                                "type": "plain_text",
                                "text": "ê²½ë ¥ ë†’ì€ìˆœ"
                            },
                            "value": "years_desc"
                        },
                        {
                            "text": {
                                "type": "plain_text",
                                "text": "ì´ë¦„ìˆœ"
                            },
                            "value": "name"
                        }
                    ],
                    "action_id": "select_sort"
                },
                "label": {
                    "type": "plain_text",
                    "text": "ì •ë ¬ ìˆœì„œ"
                }
            },
            {
                "type": "section",
                "block_id": "loading_section",
                "text": {
                    "type": "mrkdwn",
                    "text": "ğŸ“Š ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘..."
                }
            }
        ],
        "submit": {
            "type": "plain_text",
            "text": "í•„í„° ì ìš©"
        },
        "close": {
            "type": "plain_text",
            "text": "ë‹«ê¸°"
        }
    }

def apply_filters(data, job_filter="all", years_filter="all", sort_filter="latest"):
    """í•„í„°ë§ ë° ì •ë ¬ ì ìš©"""
    filtered_data = data.copy()
    
    # ì§ë¬´ í•„í„°
    if job_filter != "all":
        job_mapping = {
            "developer": "ê°œë°œì",
            "pm": "PM/ê¸°íšì", 
            "designer": "ë””ìì´ë„ˆ",
            "hr": "HR/ì±„ìš©",
            "marketing": "ë§ˆì¼€íŒ…"
        }
        target_job = job_mapping.get(job_filter, job_filter)
        filtered_data = [item for item in filtered_data if item['job_category'] == target_job]
    
    # ê²½ë ¥ í•„í„°
    if years_filter != "all":
        if years_filter == "0-1":
            filtered_data = [item for item in filtered_data if item['years'] <= 1]
        elif years_filter == "2-3":
            filtered_data = [item for item in filtered_data if 2 <= item['years'] <= 3]
        elif years_filter == "4-6":
            filtered_data = [item for item in filtered_data if 4 <= item['years'] <= 6]
        elif years_filter == "7+":
            filtered_data = [item for item in filtered_data if item['years'] >= 7]
    
    # ì •ë ¬
    if sort_filter == "latest":
        filtered_data.sort(key=lambda x: x['created_time'], reverse=True)
    elif sort_filter == "matching_desc":
        filtered_data.sort(key=lambda x: x['matching_score'], reverse=True)
    elif sort_filter == "years_desc":
        filtered_data.sort(key=lambda x: x['years'], reverse=True)
    elif sort_filter == "name":
        filtered_data.sort(key=lambda x: x['name'])
    
    return filtered_data

def create_dashboard_chart(data):
    """ëŒ€ì‹œë³´ë“œìš© ì°¨íŠ¸ ìƒì„±"""
    if not data:
        return None
        
    try:
        # ë§¤ì¹­ë¥  ë¶„í¬ íˆìŠ¤í† ê·¸ë¨ ìƒì„±
        matching_scores = [item['matching_score'] for item in data if item['matching_score'] > 0]
        
        if not matching_scores:
            return None
            
        fig = go.Figure()
        fig.add_trace(go.Histogram(
            x=matching_scores,
            nbinsx=10,
            name="ë§¤ì¹­ë¥  ë¶„í¬",
            marker_color='lightblue',
            opacity=0.7
        ))
        
        fig.update_layout(
            title="ğŸ“Š ë§¤ì¹­ë¥  ë¶„í¬",
            xaxis_title="ë§¤ì¹­ë¥  (%)",
            yaxis_title="ì¸ì› ìˆ˜",
            width=800,
            height=400,
            font=dict(family="Malgun Gothic", size=12),
            paper_bgcolor='white',
            plot_bgcolor='white',
            showlegend=False
        )
        
        # PNGë¡œ ë³€í™˜
        img_bytes = fig.to_image(format="png")
        return img_bytes
        
    except Exception as e:
        logging.error(f"ì°¨íŠ¸ ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}")
        return None

def create_filtered_results_blocks(data, total_count):
    """í•„í„°ë§ëœ ê²°ê³¼ë¥¼ Slack ë¸”ë¡ìœ¼ë¡œ ë³€í™˜"""
    blocks = []
    
    # ìš”ì•½ ì„¹ì…˜
    blocks.extend([
        {
            "type": "section",
            "text": {
                "type": "mrkdwn",
                "text": f"ğŸ“‹ *ê²€ìƒ‰ ê²°ê³¼: {len(data)}ëª…* (ì „ì²´ {total_count}ëª… ì¤‘)"
            }
        },
        {
            "type": "divider"
        }
    ])
    
    # í†µê³„ ìš”ì•½
    if data:
        avg_years = sum(item['years'] for item in data) / len(data)
        avg_matching = sum(item['matching_score'] for item in data if item['matching_score'] > 0)
        if avg_matching > 0:
            avg_matching = avg_matching / len([item for item in data if item['matching_score'] > 0])
        
        # ì§ë¬´ë³„ ë¶„í¬
        job_counts = {}
        for item in data:
            job = item['job_category']
            job_counts[job] = job_counts.get(job, 0) + 1
        
        job_summary = ", ".join([f"{job}: {count}ëª…" for job, count in job_counts.items()])
        
        blocks.extend([
            {
                "type": "section",
                "fields": [
                    {
                        "type": "mrkdwn",
                        "text": f"*ğŸ“ˆ í‰ê·  ê²½ë ¥*\n{avg_years:.1f}ë…„"
                    },
                    {
                        "type": "mrkdwn",
                        "text": f"*ğŸ¯ í‰ê·  ë§¤ì¹­ë¥ *\n{avg_matching:.1f}%" if avg_matching > 0 else "*ğŸ¯ í‰ê·  ë§¤ì¹­ë¥ *\nN/A"
                    }
                ]
            },
            {
                "type": "section",
                "text": {
                    "type": "mrkdwn",
                    "text": f"*ğŸ‘¥ ì§ë¬´ë³„ ë¶„í¬*\n{job_summary}"
                }
            },
            {
                "type": "divider"
            }
        ])
    
    # ê°œë³„ ì´ë ¥ì„œ ëª©ë¡ (ìµœëŒ€ 10ê°œ)
    for i, item in enumerate(data[:10]):
        matching_emoji = "ğŸŸ¢" if item['matching_score'] >= 80 else "ğŸŸ¡" if item['matching_score'] >= 60 else "ğŸ”´" if item['matching_score'] > 0 else "âšª"
        
        blocks.append({
            "type": "section",
            "text": {
                "type": "mrkdwn",
                "text": f"*{item['name']}* {matching_emoji}\n"
                        f"ğŸ“‹ {item['job_category']} â€¢ ğŸ“… {item['years']}ë…„ì°¨"
                        + (f" â€¢ ğŸ¯ {item['matching_score']}%" if item['matching_score'] > 0 else "")
            },
            "accessory": {
                "type": "button",
                "text": {
                    "type": "plain_text",
                    "text": "ğŸ“„ ìƒì„¸ë³´ê¸°"
                },
                "url": item['notion_url'],
                "action_id": f"view_resume_{item['id']}"
            }
        })
    
    # ë” ë§ì€ ê²°ê³¼ê°€ ìˆëŠ” ê²½ìš°
    if len(data) > 10:
        blocks.append({
            "type": "context",
            "elements": [
                {
                    "type": "mrkdwn",
                    "text": f"... ì™¸ {len(data) - 10}ëª… ë” ìˆìŠµë‹ˆë‹¤."
                }
            ]
        })
    
    return blocks

# ìŠ¬ë˜ì‹œ ëª…ë ¹ì–´ ì „ìš© ì—”ë“œí¬ì¸íŠ¸ ì¶”ê°€
@app.route("/slack/commands", methods=["POST"])
def slack_commands():
    try:
        command = request.form.get("command")
        user_id = request.form.get("user_id")
        trigger_id = request.form.get("trigger_id")
        
        logging.info(f"ìŠ¬ë˜ì‹œ ì»¤ë§¨ë“œ ìˆ˜ì‹ : {command}, user_id: {user_id}, trigger_id: {trigger_id}")
        
        if command == "/dashboard":
            logging.info("=== ì´ë ¥ì„œ ëŒ€ì‹œë³´ë“œ ëª…ë ¹ì–´ ì²˜ë¦¬ ì‹œì‘ ===")
            
            if not trigger_id:
                return jsonify({"text": "âŒ trigger_idê°€ ì—†ìŠµë‹ˆë‹¤."}), 200
            
            try:
                # ê¸°ì¡´ ì´ë ¥ì„œ ê´€ë¦¬ ëŒ€ì‹œë³´ë“œ ëª¨ë‹¬ ì—´ê¸°
                dashboard_modal = create_dashboard_modal()
                
                response = client.views_open(
                    trigger_id=trigger_id,
                    view=dashboard_modal
                )
                
                if not response.get("ok"):
                    logging.error(f"ëŒ€ì‹œë³´ë“œ ëª¨ë‹¬ ì—´ê¸° ì‹¤íŒ¨: {response}")
                    return jsonify({"text": f"âŒ ëª¨ë‹¬ ì—´ê¸° ì‹¤íŒ¨: {response.get('error', 'ì•Œ ìˆ˜ ì—†ìŒ')}"}), 200
                
                logging.info("ì´ë ¥ì„œ ëŒ€ì‹œë³´ë“œ ëª¨ë‹¬ ì—´ê¸° ì„±ê³µ")
                return "", 200
                
            except Exception as e:
                logging.error(f"ì´ë ¥ì„œ ëŒ€ì‹œë³´ë“œ ëª¨ë‹¬ ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}", exc_info=True)
                return jsonify({"text": f"âŒ ëŒ€ì‹œë³´ë“œ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"}), 200
        
        elif command == '/market':
            logging.info("=== ì‹œì¥ ì¸í…”ë¦¬ì „ìŠ¤ ëª…ë ¹ì–´ ì²˜ë¦¬ ì‹œì‘ ===")
            
            if not trigger_id:
                return jsonify({"text": "âŒ trigger_idê°€ ì—†ìŠµë‹ˆë‹¤."}), 200
            
            try:
                # ì¦‰ì‹œ ë¡œë”© ëª¨ë‹¬ í‘œì‹œ
                loading_modal = {
                    "type": "modal",
                    "callback_id": "market_loading",
                    "title": {
                        "type": "plain_text",
                        "text": "ğŸ“Š ì±„ìš© ì‹œì¥ ì¸í…”ë¦¬ì „ìŠ¤"
                    },
                    "blocks": [
                        {
                            "type": "section",
                            "text": {
                                "type": "mrkdwn",
                                "text": "ğŸ”„ *ì‹¤ì‹œê°„ ì±„ìš© ì‹œì¥ ë°ì´í„° ìˆ˜ì§‘ ì¤‘...*\n\nâ€¢ ì›í‹°ë“œ ì±„ìš©ê³µê³  ìŠ¤í¬ë˜í•‘ ì¤‘\nâ€¢ ê¸°ì—…ë³„ í†µê³„ ë¶„ì„ ì¤‘\nâ€¢ ê¸°ìˆ ìŠ¤íƒ íŠ¸ë Œë“œ ë¶„ì„ ì¤‘\n\nì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”! â³"
                            }
                        }
                    ],
                    "close": {
                        "type": "plain_text",
                        "text": "ì·¨ì†Œ"
                    }
                }
                
                # ë¡œë”© ëª¨ë‹¬ ì—´ê¸°
                response = client.views_open(
                    trigger_id=trigger_id,
                    view=loading_modal
                )
                
                if not response.get("ok"):
                    logging.error(f"ë¡œë”© ëª¨ë‹¬ ì—´ê¸° ì‹¤íŒ¨: {response}")
                    return jsonify({"text": f"âŒ ëª¨ë‹¬ ì—´ê¸° ì‹¤íŒ¨: {response.get('error', 'ì•Œ ìˆ˜ ì—†ìŒ')}"}), 200
                
                view_id = response["view"]["id"]
                logging.info(f"ë¡œë”© ëª¨ë‹¬ ì—´ê¸° ì„±ê³µ, view_id: {view_id}")
                
                # ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì‹¤ì œ ë°ì´í„° ì²˜ë¦¬
                def process_market_modal():
                    try:
                        logging.info("ë°±ê·¸ë¼ìš´ë“œ ì‹œì¥ ì¸í…”ë¦¬ì „ìŠ¤ ë°ì´í„° ì²˜ë¦¬ ì‹œì‘")
                        
                        # ì‹¤ì œ ìŠ¤í¬ë˜í•‘ ì‹œë„
                        try:
                            scraped_jobs = scrape_wanted_jobs()
                            if scraped_jobs and len(scraped_jobs) > 0:
                                logging.info(f"ì‹¤ì œ ìŠ¤í¬ë˜í•‘ ì„±ê³µ: {len(scraped_jobs)}ê°œ ê³µê³ ")
                                analyzed_data = analyze_scraped_data(scraped_jobs)
                                data_source = "ì‹¤ì‹œê°„ ë°ì´í„°"
                            else:
                                logging.warning("ìŠ¤í¬ë˜í•‘ ê²°ê³¼ ì—†ìŒ, ëª©ì—… ë°ì´í„° ì‚¬ìš©")
                                analyzed_data = get_mock_data()
                                data_source = "ë°ëª¨ ë°ì´í„°"
                        except Exception as e:
                            logging.error(f"ìŠ¤í¬ë˜í•‘ ì‹¤íŒ¨: {str(e)}")
                            analyzed_data = get_mock_data()
                            data_source = "ë°ëª¨ ë°ì´í„°"
                        
                        # ì‹œì¥ ì¸í…”ë¦¬ì „ìŠ¤ ëª¨ë‹¬ ìƒì„±
                        market_modal = create_market_intelligence_modal_with_data(analyzed_data, data_source)
                        
                        # ëª¨ë‹¬ ì—…ë°ì´íŠ¸
                        update_response = client.views_update(
                            view_id=view_id,
                            view=market_modal
                        )
                        
                        if update_response.get("ok"):
                            logging.info("ì‹œì¥ ì¸í…”ë¦¬ì „ìŠ¤ ëª¨ë‹¬ ì—…ë°ì´íŠ¸ ì„±ê³µ")
                        else:
                            logging.error(f"ëª¨ë‹¬ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {update_response}")
                            
                    except Exception as e:
                        logging.error(f"ë°±ê·¸ë¼ìš´ë“œ ì‹œì¥ ì¸í…”ë¦¬ì „ìŠ¤ ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}", exc_info=True)
                        
                        # ì—ëŸ¬ ëª¨ë‹¬ í‘œì‹œ
                        error_modal = {
                            "type": "modal",
                            "callback_id": "market_error",
                            "title": {
                                "type": "plain_text",
                                "text": "âŒ ì˜¤ë¥˜ ë°œìƒ"
                            },
                            "blocks": [
                                {
                                    "type": "section",
                                    "text": {
                                        "type": "mrkdwn",
                                        "text": f"*ì‹œì¥ ì¸í…”ë¦¬ì „ìŠ¤ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.*\n\n```{str(e)}```\n\nì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
                                    }
                                }
                            ],
                            "close": {
                                "type": "plain_text",
                                "text": "ë‹«ê¸°"
                            }
                        }
                        
                        try:
                            client.views_update(view_id=view_id, view=error_modal)
                        except:
                            pass
                
                # ë°±ê·¸ë¼ìš´ë“œ ìŠ¤ë ˆë“œ ì‹œì‘
                import threading
                thread = threading.Thread(target=process_market_modal)
                thread.daemon = True
                thread.start()
                
                return "", 200
                
            except Exception as e:
                logging.error(f"ì‹œì¥ ì¸í…”ë¦¬ì „ìŠ¤ ëª¨ë‹¬ ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}", exc_info=True)
                return jsonify({"text": f"âŒ ì‹œì¥ ì¸í…”ë¦¬ì „ìŠ¤ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"}), 200
        
        return "ì•Œ ìˆ˜ ì—†ëŠ” ëª…ë ¹ì–´ì…ë‹ˆë‹¤.", 200
        
    except Exception as e:
        logging.error(f"ìŠ¬ë˜ì‹œ ì»¤ë§¨ë“œ ì „ì²´ ì˜¤ë¥˜: {str(e)}", exc_info=True)
        return f"ëª…ë ¹ì–´ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}", 200

# ê²½ìŸì‚¬ ì±„ìš© í˜„í™© ë¶„ì„ ê´€ë ¨ í•¨ìˆ˜ë“¤
def get_competitor_hiring_data(force_scraping=False):
    """ê²½ìŸì‚¬ ì±„ìš© í˜„í™© - ì„ íƒì  ìŠ¤í¬ë˜í•‘"""
    if force_scraping:
        # ìƒˆë¡œê³ ì¹¨ ë²„íŠ¼ í´ë¦­ ì‹œì—ë§Œ ì‹¤ì œ ìŠ¤í¬ë˜í•‘
        try:
            logging.info("ê°•ì œ ìŠ¤í¬ë˜í•‘ ëª¨ë“œ: ì‹¤ì œ ì›í‹°ë“œ ë°ì´í„° ìˆ˜ì§‘")
            scraped_jobs = scrape_wanted_jobs()
            
            if scraped_jobs:
                logging.info(f"ìŠ¤í¬ë˜í•‘ ì„±ê³µ: {len(scraped_jobs)}ê°œ ê³µê³ ")
                return analyze_scraped_data(scraped_jobs)
            else:
                logging.warning("ìŠ¤í¬ë˜í•‘ ë°ì´í„°ê°€ ì—†ì–´ ëª©ì—… ë°ì´í„° ì‚¬ìš©")
                return get_mock_data()
                
        except Exception as e:
            logging.error(f"ìŠ¤í¬ë˜í•‘ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}, ëª©ì—… ë°ì´í„° ì‚¬ìš©")
            return get_mock_data()
    else:
        # ê¸°ë³¸ì ìœ¼ë¡œëŠ” ë¹ ë¥¸ ëª©ì—… ë°ì´í„° ì‚¬ìš©
        logging.info("ê¸°ë³¸ ëª¨ë“œ: ëª©ì—… ë°ì´í„° ì‚¬ìš© (ë¹ ë¥¸ ì‘ë‹µ)")
        return get_mock_data()

def get_mock_data():
    """ëª©ì—… ë°ì´í„° (ìŠ¤í¬ë˜í•‘ ì‹¤íŒ¨ ì‹œ í´ë°±)"""
    return {
        "last_updated": "2025-06-04 21:30",
        "total_jobs": 1247,
        "growth_rate": 18,  # ì „ì›” ëŒ€ë¹„ ì¦ê°€ìœ¨
        "companies": [
            {
                "name": "ì‚¼ì„±ì „ì",
                "jobs_count": 23,
                "change": 5,
                "trend": "up",
                "hot_positions": ["í´ë¼ìš°ë“œ ì—”ì§€ë‹ˆì–´", "AI ì—°êµ¬ì›", "ë°±ì—”ë“œ ê°œë°œì"],
                "avg_salary": "5200ë§Œì›",
                "logo_emoji": "ğŸ“±"
            },
            {
                "name": "ë„¤ì´ë²„",
                "jobs_count": 18,
                "change": 0,
                "trend": "stable",
                "hot_positions": ["í”„ë¡ íŠ¸ì—”ë“œ ê°œë°œì", "ë°ì´í„° ì‚¬ì´ì–¸í‹°ìŠ¤íŠ¸", "UX ë””ìì´ë„ˆ"],
                "avg_salary": "4800ë§Œì›",
                "logo_emoji": "ğŸŸ¢"
            },
            {
                "name": "ì¹´ì¹´ì˜¤",
                "jobs_count": 15,
                "change": -2,
                "trend": "down",
                "hot_positions": ["iOS ê°œë°œì", "ê²Œì„ ê°œë°œì", "DevOps ì—”ì§€ë‹ˆì–´"],
                "avg_salary": "4600ë§Œì›",
                "logo_emoji": "ğŸ’¬"
            },
            {
                "name": "í† ìŠ¤",
                "jobs_count": 31,
                "change": 12,
                "trend": "hot",
                "hot_positions": ["í’€ìŠ¤íƒ ê°œë°œì", "ë³´ì•ˆ ì—”ì§€ë‹ˆì–´", "í”„ë¡œë•íŠ¸ ë§¤ë‹ˆì €"],
                "avg_salary": "5500ë§Œì›",
                "logo_emoji": "ğŸ’³"
            },
            {
                "name": "ì¿ íŒ¡",
                "jobs_count": 27,
                "change": 8,
                "trend": "up",
                "hot_positions": ["ë°ì´í„° ì—”ì§€ë‹ˆì–´", "ML ì—”ì§€ë‹ˆì–´", "ì‹œìŠ¤í…œ ì—”ì§€ë‹ˆì–´"],
                "avg_salary": "5000ë§Œì›",
                "logo_emoji": "ğŸ“¦"
            },
            {
                "name": "ë°°ë‹¬ì˜ë¯¼ì¡±",
                "jobs_count": 19,
                "change": 3,
                "trend": "up",
                "hot_positions": ["ë°±ì—”ë“œ ê°œë°œì", "ì•ˆë“œë¡œì´ë“œ ê°œë°œì", "QA ì—”ì§€ë‹ˆì–´"],
                "avg_salary": "4700ë§Œì›",
                "logo_emoji": "ğŸ”"
            }
        ],
        "insights": [
            "í† ìŠ¤ê°€ ëŒ€ê·œëª¨ ì±„ìš© ì¤‘! í•€í…Œí¬ ë¶„ì•¼ ê²½ìŸ ì‹¬í™” ì˜ˆìƒ",
            "DevOps/í´ë¼ìš°ë“œ ì—”ì§€ë‹ˆì–´ ìˆ˜ìš”ê°€ ì „ ì—…ê³„ì—ì„œ ê¸‰ì¦",
            "í‰ê·  ì—°ë´‰ì´ ì „ì›” ëŒ€ë¹„ 7% ìƒìŠ¹, ì¸ì¬ í™•ë³´ ê²½ìŸ ì¹˜ì—´"
        ],
        "hot_skills": [
            {"skill": "Kubernetes", "growth": 25, "companies": 8},
            {"skill": "React", "growth": 15, "companies": 12},
            {"skill": "Python", "growth": 12, "companies": 15},
            {"skill": "AWS", "growth": 20, "companies": 10},
            {"skill": "TypeScript", "growth": 18, "companies": 9}
        ]
    }

def create_market_intelligence_modal(force_scraping=False, user_id=None):
    """ì±„ìš© ì‹œì¥ ì¸í…”ë¦¬ì „ìŠ¤ Modal ìƒì„± (ê¸°ìˆ ìŠ¤íƒ ë¶„í¬ ì°¨íŠ¸ í¬í•¨)"""
    data = get_competitor_hiring_data(force_scraping=force_scraping)
    blocks = []
    # ... ê¸°ì¡´ í—¤ë”/í†µê³„ ë¸”ë¡ ...
    header_text = "ğŸ¢ ê²½ìŸì‚¬ ì±„ìš© í˜„í™© ë¶„ì„"
    if force_scraping:
        header_text += " (ì‹¤ì‹œê°„ ë°ì´í„°)"
    else:
        header_text += " (Demo ë°ì´í„°)"
    blocks.append({
        "type": "header",
        "text": {"type": "plain_text", "text": header_text, "emoji": True}
    })
    blocks.append({
        "type": "section",
        "text": {"type": "mrkdwn", "text": f"*ğŸ“Š ì „ì²´ ì‹œì¥ í˜„í™©*\nâ€¢ ì´ ê³µê³  ìˆ˜: *{data['total_jobs']:,}ê°œ* (â†‘{data['growth_rate']}%)\nâ€¢ ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸: {data['last_updated']}"}
    })
    blocks.append({"type": "divider"})
    # ... ê²½ìŸì‚¬ë³„ í˜„í™© ...
    blocks.append({
        "type": "section",
        "text": {"type": "mrkdwn", "text": "*ğŸ¢ ì£¼ìš” ê¸°ì—… ì±„ìš© í˜„í™©*"}
    })
    for company in data['companies']:
        trend_emoji = "ğŸ”¥" if company['trend'] == "hot" else "ğŸ“ˆ" if company['trend'] == "up" else "ğŸ“Š" if company['trend'] == "stable" else "ğŸ“‰"
        change_text = f"â†‘{company['change']}" if company['change'] > 0 else f"â†“{abs(company['change'])}" if company['change'] < 0 else "â†’"
        blocks.append({
            "type": "section",
            "text": {"type": "mrkdwn",
                "text": f"{company['logo_emoji']} *{company['name']}* {trend_emoji}\n"
                        f"ğŸ“‹ {company['jobs_count']}ê°œ ê³µê³  ({change_text}ê°œ)\n"
                        f"ğŸ’° í‰ê·  ì—°ë´‰: {company['avg_salary']}\n"
                        f"ğŸ”¥ ì¸ê¸° í¬ì§€ì…˜: {', '.join(company['hot_positions'][:2])}"
            }
        })
    # ê¸°ìˆ ìŠ¤íƒ ë¶„í¬ ì°¨íŠ¸ ìƒì„± ë° DM ì „ì†¡ (ì•ˆì „ì„±ì„ ìœ„í•´ ë¹„í™œì„±í™”)
    try:
        logging.info("ì°¨íŠ¸ ìƒì„± ì‹œì‘")
        # ì°¨íŠ¸ ìƒì„±ì„ ë¹„í™œì„±í™”í•˜ì—¬ ì•ˆì •ì„± í™•ë³´
        # TODO: ì°¨íŠ¸ ê¸°ëŠ¥ì€ ë³„ë„ ìŠ¤ë ˆë“œë‚˜ ë¹„ë™ê¸°ë¡œ ì²˜ë¦¬ í•„ìš”
        logging.info("ì°¨íŠ¸ ìƒì„± ì™„ë£Œ (ì•ˆì •ì„±ì„ ìœ„í•´ ë¹„í™œì„±í™”ë¨)")
    except Exception as e:
        logging.error(f"ê¸°ìˆ ìŠ¤íƒ ì°¨íŠ¸ ìƒì„±/ì—…ë¡œë“œ ì˜¤ë¥˜: {str(e)}", exc_info=True)
    # ëª¨ë‹¬ì— ì•ˆë‚´ í…ìŠ¤íŠ¸ block ì¶”ê°€
    blocks.append({
        "type": "section",
        "text": {"type": "mrkdwn", "text": "ğŸ”¥ *ê¸°ìˆ ìŠ¤íƒ ë¶„í¬ ì°¨íŠ¸ëŠ” DM(Direct Message)ìœ¼ë¡œ ì „ì†¡ë˜ì—ˆìŠµë‹ˆë‹¤.*"}
    })
    # í•«í•œ ê¸°ìˆ ìŠ¤íƒ
    blocks.append({"type": "divider"})
    blocks.append({
        "type": "section",
        "text": {"type": "mrkdwn", "text": "*ğŸ”¥ ê¸‰ìƒìŠ¹ ê¸°ìˆ ìŠ¤íƒ TOP 5*"}
    })
    for i, skill in enumerate(data['hot_skills'][:5], 1):
        blocks.append({
            "type": "section",
            "text": {"type": "mrkdwn", "text": f"*{i}. {skill['skill']}* (â†‘{skill['growth']}%)\\n{skill['companies']}ê°œ ê¸°ì—…ì—ì„œ ì±„ìš© ì¤‘"}
        })
    # ... ì´í•˜ ê¸°ì¡´ ì¸ì‚¬ì´íŠ¸, ìƒˆë¡œê³ ì¹¨ ë²„íŠ¼ ë“± ...
    blocks.extend([
        {"type": "divider"},
        {"type": "section", "text": {"type": "mrkdwn", "text": "*ğŸ’¡ ì‹œì¥ ì¸ì‚¬ì´íŠ¸*"}},
    ])
    for insight in data['insights']:
        blocks.append({"type": "section", "text": {"type": "mrkdwn", "text": f"â€¢ {insight}"}})
    blocks.extend([
        {"type": "divider"},
        {"type": "actions", "elements": [
            {"type": "button", "text": {"type": "plain_text", "text": "ğŸ”„ ë°ì´í„° ìƒˆë¡œê³ ì¹¨", "emoji": True}, "action_id": "refresh_market_data", "style": "primary"}
        ]}
    ])
    return {
        "type": "modal",
        "callback_id": "market_intelligence_modal",
        "title": {"type": "plain_text", "text": "ğŸ“Š ì±„ìš© ì‹œì¥ ì¸í…”ë¦¬ì „ìŠ¤"},
        "blocks": blocks,
        "close": {"type": "plain_text", "text": "ë‹«ê¸°"}
    }

# ì‹¤ì œ ì›í‹°ë“œ ìŠ¤í¬ë˜í•‘ í•¨ìˆ˜ë“¤
def scrape_wanted_jobs():
    """ì›í‹°ë“œì—ì„œ IT ì±„ìš©ê³µê³  ì‹¤ì œ ìŠ¤í¬ë˜í•‘ (Selenium ì‚¬ìš©) - ê°œì„ ëœ ì…€ë ‰í„°"""
    chrome_options = Options()
    chrome_options.add_argument("--headless")
    chrome_options.add_argument("--no-sandbox")
    chrome_options.add_argument("--disable-dev-shm-usage")
    chrome_options.add_argument("--disable-gpu")
    chrome_options.add_argument("--window-size=1920,1080")
    chrome_options.add_argument("--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36")
    
    driver = None
    jobs_data = []
    
    try:
        driver = webdriver.Chrome(options=chrome_options)
        logging.info("Chrome ë¸Œë¼ìš°ì € ì‹œì‘ë¨")
        
        # ì›í‹°ë“œ ê°œë°œì ì±„ìš©ê³µê³  í˜ì´ì§€
        url = "https://www.wanted.co.kr/wdlist/518?country=kr&job_sort=job.latest_order&years=-1&locations=all"
        driver.get(url)
        logging.info(f"í˜ì´ì§€ ë¡œë“œ ì™„ë£Œ: {url}")
        
        # í˜ì´ì§€ ë¡œë”© ëŒ€ê¸°
        time.sleep(5)
        
        # ì‹¤ì œë¡œ ì‘ë™í•˜ëŠ” ì…€ë ‰í„° ì‚¬ìš©: ì±„ìš©ê³µê³  ë§í¬ë“¤ ì°¾ê¸°
        job_links = driver.find_elements(By.CSS_SELECTOR, "a[href*='/wd/']")
        logging.info(f"ë°œê²¬ëœ ì±„ìš©ê³µê³  ë§í¬ ìˆ˜: {len(job_links)}")
        
        if not job_links:
            logging.warning("ì±„ìš©ê³µê³  ë§í¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ")
            return []
        
        # ê° ì±„ìš©ê³µê³ ì—ì„œ ë°ì´í„° ì¶”ì¶œ
        for index, link in enumerate(job_links[:20]):  # ìµœëŒ€ 20ê°œ
            try:
                # ì „ì²´ í…ìŠ¤íŠ¸ì—ì„œ ì •ë³´ ì¶”ì¶œ
                full_text = link.text.strip()
                if not full_text or len(full_text) < 10:
                    continue
                
                logging.info(f"ê³µê³  {index+1} í…ìŠ¤íŠ¸: {full_text[:100]}...")
                
                # í…ìŠ¤íŠ¸ íŒŒì‹±ìœ¼ë¡œ íšŒì‚¬ëª…ê³¼ í¬ì§€ì…˜ ì¶”ì¶œ
                lines = [line.strip() for line in full_text.split('\n') if line.strip()]
                
                company_name = None
                position_name = None
                
                # í…ìŠ¤íŠ¸ ë¼ì¸ ë¶„ì„
                for line in lines:
                    # íšŒì‚¬ëª… ì°¾ê¸° (í•œê¸€ + ì˜ë¬¸ + ê´„í˜¸ ì¡°í•©, ë³´í†µ ì§§ìŒ)
                    if not company_name and 2 <= len(line) <= 30:
                        # í¬ì§€ì…˜ëª…ì´ ì•„ë‹Œ ê²ƒ ê°™ì€ ê²ƒë“¤
                        if not any(keyword in line.lower() for keyword in 
                            ['developer', 'ê°œë°œì', 'engineer', 'ì—”ì§€ë‹ˆì–´', 'backend', 'frontend', 
                             'fullstack', 'react', 'java', 'python', 'php', 'í•©ê²©ë³´ìƒê¸ˆ', '100ë§Œì›']):
                            company_name = line
                    
                    # í¬ì§€ì…˜ëª… ì°¾ê¸° (ê°œë°œ ê´€ë ¨ í‚¤ì›Œë“œ í¬í•¨)
                    if not position_name and 5 <= len(line) <= 80:
                        if any(keyword in line.lower() for keyword in 
                            ['developer', 'ê°œë°œì', 'engineer', 'ì—”ì§€ë‹ˆì–´', 'backend', 'frontend', 
                             'fullstack', 'react', 'vue', 'angular', 'java', 'python', 'php', 
                             'javascript', 'kotlin', 'swift', 'node', 'spring', 'django']):
                            position_name = line
                
                # ê¸°ë³¸ê°’ ì„¤ì •
                if not company_name:
                    # ë§ˆì§€ë§‰ì—ì„œ ë‘ ë²ˆì§¸ ë¼ì¸ì´ íšŒì‚¬ëª…ì¼ ê°€ëŠ¥ì„±
                    if len(lines) >= 2:
                        company_name = lines[-2] if lines[-2] and 'í•©ê²©ë³´ìƒê¸ˆ' not in lines[-2] else "ì•Œ ìˆ˜ ì—†ìŒ"
                    else:
                        company_name = "ì•Œ ìˆ˜ ì—†ìŒ"
                
                if not position_name:
                    # ì²« ë²ˆì§¸ë‚˜ ë‘ ë²ˆì§¸ ë¼ì¸ì—ì„œ í¬ì§€ì…˜ëª… ì°¾ê¸°
                    for line in lines[:3]:
                        if 'í•©ê²©ë³´ìƒê¸ˆ' not in line and len(line) > 5:
                            position_name = line
                            break
                    if not position_name:
                        position_name = "ê°œë°œì"
                
                # ê¸°ìˆ ìŠ¤íƒ ì¶”ì¶œ
                tech_skills = extract_tech_skills_from_text(full_text)
                
                # ê²°ê³¼ ì €ì¥
                job_data = {
                    'company': company_name,
                    'position': position_name,
                    'tech_skills': tech_skills
                }
                
                jobs_data.append(job_data)
                logging.info(f"ì¶”ì¶œ ì™„ë£Œ {index+1}: {company_name} | {position_name} | {tech_skills}")
                
            except Exception as e:
                logging.error(f"ì±„ìš©ê³µê³  {index+1} ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}")
                continue
        
        logging.info(f"ì´ {len(jobs_data)}ê°œ ì±„ìš©ê³µê³  ìŠ¤í¬ë˜í•‘ ì™„ë£Œ")
        return jobs_data
        
    except Exception as e:
        logging.error(f"ìŠ¤í¬ë˜í•‘ ì˜¤ë¥˜: {str(e)}", exc_info=True)
        return []
        
    finally:
        if driver:
            driver.quit()
            logging.info("ë¸Œë¼ìš°ì € ì¢…ë£Œë¨")

def extract_tech_skills_from_text(text):
    """í…ìŠ¤íŠ¸ì—ì„œ ì‹¤ì œ ê¸°ìˆ ìŠ¤íƒë§Œ ì¶”ì¶œ - ì™„ì „íˆ ê°œì„ ëœ ë²„ì „"""
    if not text:
        return []
    
    # ì‹¤ì œ ê¸°ìˆ ìŠ¤íƒ í‚¤ì›Œë“œ ëª©ë¡ (ì •í™•í•œ ë§¤ì¹­ì„ ìœ„í•´ ì„¸ë¶„í™”)
    tech_keywords = {
        # í”„ë¡œê·¸ë˜ë° ì–¸ì–´
        'python', 'java', 'javascript', 'typescript', 'kotlin', 'swift', 'go', 'rust',
        'c++', 'c#', 'php', 'ruby', 'scala', 'r', 'dart', 'objective-c',
        
        # ì›¹ í”„ë¡ íŠ¸ì—”ë“œ
        'react', 'vue', 'angular', 'svelte', 'next.js', 'nuxt.js', 'gatsby',
        'jquery', 'bootstrap', 'tailwind', 'sass', 'less', 'webpack', 'vite',
        
        # ë°±ì—”ë“œ í”„ë ˆì„ì›Œí¬
        'spring', 'django', 'flask', 'fastapi', 'express', 'nest.js', 'laravel',
        'rails', 'asp.net', 'gin', 'echo', 'fiber',
        
        # ë°ì´í„°ë² ì´ìŠ¤
        'mysql', 'postgresql', 'mongodb', 'redis', 'elasticsearch', 'oracle',
        'sqlite', 'mariadb', 'cassandra', 'dynamodb', 'neo4j', 'influxdb',
        
        # í´ë¼ìš°ë“œ & ì¸í”„ë¼
        'aws', 'azure', 'gcp', 'docker', 'kubernetes', 'jenkins', 'gitlab-ci',
        'github-actions', 'terraform', 'ansible', 'vagrant', 'nginx', 'apache',
        
        # ë°ì´í„° & AI/ML
        'tensorflow', 'pytorch', 'pandas', 'numpy', 'scikit-learn', 'spark',
        'hadoop', 'kafka', 'airflow', 'jupyter', 'tableau', 'power-bi',
        
        # ëª¨ë°”ì¼
        'android', 'ios', 'flutter', 'react-native', 'xamarin', 'ionic',
        
        # ê¸°íƒ€ ë„êµ¬ & ê¸°ìˆ 
        'git', 'jira', 'confluence', 'figma', 'sketch', 'linux', 'ubuntu',
        'graphql', 'rest', 'grpc', 'microservices', 'serverless'
    }
    
    # ì œì™¸í•  í‚¤ì›Œë“œ (ë” í¬ê´„ì ìœ¼ë¡œ)
    exclude_keywords = {
        # íšŒì‚¬ëª… ê´€ë ¨
        'í•©ê²©ë³´ìƒê¸ˆ', '100ë§Œì›', 'ë³´ìƒê¸ˆ', 'ì§€ë€ì§€êµë°ì´í„°', 'ê·¸ë˜í”½', 'ìœ„ëŒ€í•œìƒìƒ', 
        'ìš”ê¸°ìš”', 'ë°”ë¡œê³ ', 'barogo', 'ì›í‹°ë“œ', 'ë‚˜ë‹ˆì•„ë©ìŠ¤', 'ë”ë¸”ë¯¸ë””ì–´', 
        'ì´ìŠ¤íŠ¸ì†Œí”„íŠ¸', 'estsoft', 'ì—¬ê¸°ì–´ë•Œì»´í¼ë‹ˆ', 'ì—˜ë°•ìŠ¤', 'ì¹©ìŠ¤ì•¤ë¯¸ë””ì–´',
        'ë©”ê°€ìŠ¤í„°ë””êµìœ¡', 'ë¶ˆë§ˆì¼“ë©ìŠ¤',
        
        # ì§€ì—­ëª…
        'ì„œìš¸', 'ê²½ê¸°', 'ê°•ë‚¨êµ¬', 'ì„œì´ˆêµ¬', 'ìš©ì‚°êµ¬', 'ê°•ì„œêµ¬', 'ì„±ë‚¨ì‹œ', 'íŒêµ',
        'ë¶€ì‚°', 'ëŒ€êµ¬', 'ì¸ì²œ', 'ê´‘ì£¼', 'ëŒ€ì „', 'ìš¸ì‚°', 'ì„¸ì¢…',
        
        # ì¼ë°˜ ë‹¨ì–´
        'ì‹ ì…', 'ê²½ë ¥', 'ë…„', 'ì´ìƒ', 'ê°œë°œì', 'engineer', 'developer', 'ë‹´ë‹¹ì',
        'application', 'product', 'sres', 'apps', 'ê·¼ë¬´ì§€', 'ì¼ë³¸', 'ì£¼ì‹íšŒì‚¬',
        'ì±„ìš©', 'ê³µê³ ', 'í¬ì§€ì…˜', 'ì—…ë¬´', 'ë‹´ë‹¹', 'ê´€ë¦¬', 'ìš´ì˜', 'ê¸°íš', 'ì„¤ê³„',
        'ë¶„ì„', 'êµ¬ì¶•', 'ê°œë°œ', 'ìœ ì§€ë³´ìˆ˜', 'ìµœì í™”', 'ì„±ëŠ¥', 'í’ˆì§ˆ', 'í…ŒìŠ¤íŠ¸',
        
        # ê¸°íƒ€ ë¶ˆí•„ìš”í•œ ë‹¨ì–´
        'front-end', 'back-end', 'full-stack', 'devops', 'qa', 'ui', 'ux',
        'pm', 'po', 'scrum', 'agile', 'team', 'lead', 'senior', 'junior'
    }
    
    found_skills = []
    text_lower = text.lower()
    
    # ì •í™•í•œ ê¸°ìˆ ìŠ¤íƒ í‚¤ì›Œë“œë§Œ ì°¾ê¸°
    for keyword in tech_keywords:
        # ë‹¨ì–´ ê²½ê³„ë¥¼ ê³ ë ¤í•œ ì •í™•í•œ ë§¤ì¹­
        import re
        
        # íŠ¹ìˆ˜ ë¬¸ìê°€ í¬í•¨ëœ í‚¤ì›Œë“œ ì²˜ë¦¬ (ì˜ˆ: next.js, c++)
        escaped_keyword = re.escape(keyword)
        
        # ë‹¨ì–´ ê²½ê³„ íŒ¨í„´ ìƒì„±
        patterns = [
            rf'\b{escaped_keyword}\b',  # ê¸°ë³¸ ë‹¨ì–´ ê²½ê³„
            rf'(?<!\w){escaped_keyword}(?!\w)',  # ë” ì—„ê²©í•œ ê²½ê³„
            rf'(?<![a-zA-Z]){escaped_keyword}(?![a-zA-Z])'  # ì•ŒíŒŒë²³ ê²½ê³„ë§Œ
        ]
        
        for pattern in patterns:
            if re.search(pattern, text_lower, re.IGNORECASE):
                # ì œì™¸ í‚¤ì›Œë“œì™€ ê²¹ì¹˜ì§€ ì•ŠëŠ”ì§€ í™•ì¸
                if not any(exclude in keyword.lower() for exclude in exclude_keywords):
                    found_skills.append(keyword.title())
                    break
    
    # ì¤‘ë³µ ì œê±° ë° ì •ë ¬
    unique_skills = sorted(list(set(found_skills)))
    
    # ë¡œê¹…ìœ¼ë¡œ ë””ë²„ê¹…
    if unique_skills:
        logging.info(f"ì¶”ì¶œëœ ê¸°ìˆ ìŠ¤íƒ: {unique_skills} (ì›ë³¸: {text[:100]}...)")
    
    return unique_skills

def analyze_scraped_data(jobs_data):
    """ìŠ¤í¬ë˜í•‘ëœ ë°ì´í„° ë¶„ì„ - ê¸°ìˆ ìŠ¤íƒ í•„í„°ë§ ê°•í™” ë²„ì „"""
    if not jobs_data:
        return get_mock_data()
    
    logging.info(f"ë¶„ì„í•  ë°ì´í„°: {len(jobs_data)}ê°œ ê³µê³ ")
    
    # Counter ì‚¬ìš©ìœ¼ë¡œ ë³€ê²½
    from collections import Counter
    
    company_counts = Counter()
    skill_counts = Counter()
    position_counts = Counter()
    
    for job in jobs_data:
        company = job.get('company', 'ì•Œ ìˆ˜ ì—†ìŒ')
        position = job.get('position', 'ê°œë°œì')
        tech_skills = job.get('tech_skills', [])
        
        # íšŒì‚¬ë³„ ì¹´ìš´íŠ¸
        if company != 'ì•Œ ìˆ˜ ì—†ìŒ':
            company_counts[company] += 1
        
        # í¬ì§€ì…˜ë³„ ì¹´ìš´íŠ¸ (ì‹¤ì œ í¬ì§€ì…˜ë§Œ)
        if position and position != 'ê°œë°œì' and len(position) < 100:
            # ë¶ˆí•„ìš”í•œ í…ìŠ¤íŠ¸ê°€ í¬í•¨ë˜ì§€ ì•Šì€ ì‹¤ì œ í¬ì§€ì…˜ë§Œ
            if not any(exclude in position.lower() for exclude in 
                      ['í•©ê²©ë³´ìƒê¸ˆ', '100ë§Œì›', 'ì„œìš¸', 'ê²½ê¸°', 'ê°•ë‚¨êµ¬', 'ì„œì´ˆêµ¬']):
                position_counts[position] += 1
        
        # ê¸°ìˆ ìŠ¤íƒ ì¹´ìš´íŠ¸ (ì‹¤ì œ ê¸°ìˆ ë§Œ)
        for skill in tech_skills:
            if skill and len(skill) > 1:  # ë¹ˆ ë¬¸ìì—´ì´ë‚˜ ë„ˆë¬´ ì§§ì€ ê²ƒ ì œì™¸
                # ì‹¤ì œ ê¸°ìˆ ì¸ì§€ í•œë²ˆ ë” ê²€ì¦
                if is_valid_tech_skill(skill):
                    skill_counts[skill] += 1
    
    # ìƒìœ„ íšŒì‚¬ë“¤ (ìµœì†Œ 1ê°œ ì´ìƒ ê³µê³ )
    top_companies = company_counts.most_common(6)
    
    # ìƒìœ„ ê¸°ìˆ ìŠ¤íƒë“¤ (ì‹¤ì œ ê¸°ìˆ ë§Œ, ìµœì†Œ 1ê°œ ì´ìƒ)
    top_skills = skill_counts.most_common(5)
    
    # ìƒìœ„ í¬ì§€ì…˜ë“¤
    top_positions = position_counts.most_common(5)
    
    logging.info(f"ìƒìœ„ íšŒì‚¬: {top_companies}")
    logging.info(f"ìƒìœ„ ê¸°ìˆ ìŠ¤íƒ: {top_skills}")
    logging.info(f"ìƒìœ„ í¬ì§€ì…˜: {top_positions}")
    
    # ë¶„ì„ ê²°ê³¼ êµ¬ì„±
    companies_data = []
    for company, count in top_companies:
        # í•´ë‹¹ íšŒì‚¬ì˜ í¬ì§€ì…˜ë“¤ ì°¾ê¸° (ìƒìœ„ 3ê°œê¹Œì§€)
        company_jobs = [job for job in jobs_data if job.get('company') == company]
        top_positions = []
        if company_jobs:
            positions = [job.get('position', 'ê°œë°œì') for job in company_jobs]
            logging.info(f"[ë””ë²„ê·¸] {company} ì›ë³¸ í¬ì§€ì…˜ë“¤: {positions}")
            
            # ì‹¤ì œ í¬ì§€ì…˜ë§Œ í•„í„°ë§ (ê°œë°œìë„ í—ˆìš©í•˜ë˜ ë” êµ¬ì²´ì ì¸ ê²ƒ ìš°ì„ )
            valid_positions = []
            specific_positions = []  # êµ¬ì²´ì ì¸ í¬ì§€ì…˜ë“¤
            generic_positions = []   # 'ê°œë°œì' ê°™ì€ ì¼ë°˜ì ì¸ í¬ì§€ì…˜ë“¤
            
            for pos in positions:
                if pos and len(pos) < 100 and not any(exclude in pos.lower() for exclude in 
                    ['í•©ê²©ë³´ìƒê¸ˆ', '100ë§Œì›', 'ì„œìš¸', 'ê²½ê¸°', 'íŒêµ', 'ê·¼ë¬´ì§€', 'ì‹ ì…', 'ê²½ë ¥', 'ì±„ìš©']):
                    
                    # ë” êµ¬ì²´ì ì¸ í¬ì§€ì…˜ì¸ì§€ í™•ì¸
                    if any(keyword in pos.lower() for keyword in 
                        ['í”„ë¡ íŠ¸ì—”ë“œ', 'ë°±ì—”ë“œ', 'í’€ìŠ¤íƒ', 'ëª¨ë°”ì¼', 'frontend', 'backend', 'fullstack', 
                         'react', 'vue', 'angular', 'java', 'python', 'ios', 'android', 'devops', 
                         'ë°ì´í„°', 'ml', 'ai', 'ë¨¸ì‹ ëŸ¬ë‹', 'ì¸ê³µì§€ëŠ¥', 'software', 'senior', 'junior']):
                        specific_positions.append(pos)
                    elif pos == 'ê°œë°œì':
                        generic_positions.append(pos)
                    else:
                        valid_positions.append(pos)
            
            # ìš°ì„ ìˆœìœ„: êµ¬ì²´ì ì¸ í¬ì§€ì…˜ > ì¼ë°˜ í¬ì§€ì…˜ > 'ê°œë°œì'
            all_positions = specific_positions + valid_positions + generic_positions
            logging.info(f"[ë””ë²„ê·¸] {company} í•„í„°ë§ëœ í¬ì§€ì…˜ë“¤: {all_positions}")
            
            if all_positions:
                position_freq = Counter(all_positions)
                # ìƒìœ„ 3ê°œ í¬ì§€ì…˜ ê°€ì ¸ì˜¤ê¸°
                top_positions = [pos for pos, _ in position_freq.most_common(3)]
            
            # í¬ì§€ì…˜ì´ ì—†ìœ¼ë©´ ê¸°ë³¸ê°’
            if not top_positions:
                top_positions = ["ê°œë°œì"]
                
            logging.info(f"[ë””ë²„ê·¸] {company} ìµœì¢… ì„ íƒëœ í¬ì§€ì…˜ë“¤: {top_positions}")
        else:
            top_positions = ["ê°œë°œì"]
        
        companies_data.append({
            "name": company,
            "jobs_count": count,
            "trend": "+2",  # ì„ì‹œ íŠ¸ë Œë“œ
            "top_positions": top_positions  # ì—¬ëŸ¬ í¬ì§€ì…˜ ì €ì¥
        })
    
    # ê¸°ìˆ ìŠ¤íƒ ë°ì´í„° (ì‹¤ì œ ê¸°ìˆ ë§Œ)
    skills_data = []
    for skill, count in top_skills:
        if is_valid_tech_skill(skill):  # í•œë²ˆ ë” ê²€ì¦
            skills_data.append({
                "name": skill,
                "growth": f"+{min(30, count * 10)}%",  # ì„±ì¥ë¥  ê³„ì‚°
                "companies_using": count
            })
    
    # ê¸°ìˆ ìŠ¤íƒì´ ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ ì œê³µ
    if not skills_data:
        skills_data = [
            {"name": "JavaScript", "growth": "+15%", "companies_using": 3},
            {"name": "Python", "growth": "+12%", "companies_using": 2},
            {"name": "React", "growth": "+18%", "companies_using": 2}
        ]
    
    return {
        "total_jobs": len(jobs_data),
        "growth_rate": "+15%",
        "last_updated": "2025-06-16 14:35",
        "companies": companies_data,
        "skills": skills_data,
        "insights": generate_insights(jobs_data, skill_counts, company_counts)
    }

def is_valid_tech_skill(skill):
    """ê¸°ìˆ ìŠ¤íƒì´ ì‹¤ì œ ê¸°ìˆ ì¸ì§€ ê²€ì¦í•˜ëŠ” í•¨ìˆ˜"""
    if not skill or len(skill) < 2 or len(skill) > 30:
        return False
    
    # ì‹¤ì œ ê¸°ìˆ  í‚¤ì›Œë“œ ëª©ë¡ (ì†Œë¬¸ì)
    valid_tech_keywords = {
        'python', 'java', 'javascript', 'typescript', 'kotlin', 'swift', 'go', 'rust',
        'c++', 'c#', 'php', 'ruby', 'scala', 'r', 'dart',
        'react', 'vue', 'angular', 'svelte', 'next.js', 'nuxt.js',
        'spring', 'django', 'flask', 'fastapi', 'express', 'laravel',
        'mysql', 'postgresql', 'mongodb', 'redis', 'elasticsearch',
        'aws', 'azure', 'gcp', 'docker', 'kubernetes', 'jenkins',
        'tensorflow', 'pytorch', 'pandas', 'numpy', 'spark',
        'android', 'ios', 'flutter', 'react-native',
        'git', 'linux', 'ubuntu', 'nginx', 'apache'
    }
    
    # ì œì™¸í•  í‚¤ì›Œë“œ
    invalid_keywords = {
        'í•©ê²©ë³´ìƒê¸ˆ', '100ë§Œì›', 'ì„œìš¸', 'ê²½ê¸°', 'ê°•ë‚¨êµ¬', 'ì„œì´ˆêµ¬', 'ì„±ë‚¨ì‹œ',
        'ì‹ ì…', 'ê²½ë ¥', 'ë…„', 'ì´ìƒ', 'ê°œë°œì', 'engineer', 'developer',
        'íšŒì‚¬', 'ê¸°ì—…', 'ì±„ìš©', 'ê³µê³ ', 'í¬ì§€ì…˜'
    }
    
    skill_lower = skill.lower()
    
    # ì œì™¸ í‚¤ì›Œë“œ ì²´í¬
    for invalid in invalid_keywords:
        if invalid.lower() in skill_lower:
            return False
    
    # ì‹¤ì œ ê¸°ìˆ  í‚¤ì›Œë“œ ì²´í¬
    for valid_tech in valid_tech_keywords:
        if valid_tech in skill_lower:
            return True
    
    return False

def get_company_emoji(company_name):
    """íšŒì‚¬ëª…ì— ë”°ë¥¸ ì´ëª¨ì§€ ë°˜í™˜"""
    emoji_map = {
        'ì‚¼ì„±': 'ğŸ“±', 'ë„¤ì´ë²„': 'ğŸŸ¢', 'ì¹´ì¹´ì˜¤': 'ğŸ’¬', 'í† ìŠ¤': 'ğŸ’³',
        'ì¿ íŒ¡': 'ğŸ“¦', 'ë°°ë‹¬ì˜ë¯¼ì¡±': 'ğŸ”', 'ë¼ì¸': 'ğŸ’š', 'SK': 'ğŸ”´',
        'í˜„ëŒ€': 'ğŸš—', 'LG': 'ğŸ“º', 'ìš°ì•„í•œí˜•ì œë“¤': 'ğŸ”'
    }
    
    for keyword, emoji in emoji_map.items():
        if keyword in company_name:
            return emoji
    
    return 'ğŸ¢'  # ê¸°ë³¸ ì´ëª¨ì§€

def generate_insights(jobs_data, skill_counts, company_counts):
    """ìˆ˜ì§‘ëœ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì¸ì‚¬ì´íŠ¸ ìƒì„± - ìˆ˜ì •ëœ ë²„ì „"""
    from collections import Counter
    
    insights = []
    
    try:
        # dictë¥¼ Counterë¡œ ë³€í™˜
        if isinstance(skill_counts, dict):
            skill_counts = Counter(skill_counts)
        if isinstance(company_counts, dict):
            company_counts = Counter(company_counts)
        
        # ì‹¤ì œ ê¸°ìˆ ìŠ¤íƒë§Œ í•„í„°ë§í•˜ëŠ” í•¨ìˆ˜
        def is_real_tech(skill):
            if not skill or len(skill) > 30:
                return False
            
            exclude_words = ['í•©ê²©ë³´ìƒê¸ˆ', '100ë§Œì›', 'ì„œìš¸', 'ê²½ê¸°', 'ê°•ë‚¨êµ¬', 'ì„œì´ˆêµ¬', 
                           'ì„±ë‚¨ì‹œ', 'ê²½ë ¥', 'ì‹ ì…', 'ë…„', 'ì´ìƒ', 'ê°œë°œì', 'ì—”ì§€ë‹ˆì–´', 
                           'ë‹´ë‹¹ì', 'íŒêµ', 'ê·¼ë¬´ì§€', 'ì¼ë³¸', 'æ ªå¼ä¼šç¤¾']
            
            skill_lower = skill.lower()
            for word in exclude_words:
                if word.lower() in skill_lower:
                    return False
            
            # ì‹¤ì œ ê¸°ìˆ  í‚¤ì›Œë“œ í™•ì¸
            tech_words = ['javascript', 'python', 'java', 'react', 'vue', 'angular', 
                         'node', 'spring', 'django', 'mysql', 'postgresql', 'mongodb',
                         'aws', 'azure', 'docker', 'kubernetes', 'typescript', 'php']
            
            for tech in tech_words:
                if tech in skill_lower:
                    return True
            
            return False
        
        # íšŒì‚¬ ì¸ì‚¬ì´íŠ¸
        if company_counts:
            top_company = company_counts.most_common(1)[0][0]
            top_count = company_counts.most_common(1)[0][1]
            insights.append(f"{top_company}ê°€ {top_count}ê°œ ê³µê³ ë¡œ ê°€ì¥ í™œë°œíˆ ì±„ìš© ì¤‘ì…ë‹ˆë‹¤")
        
        # ê¸°ìˆ ìŠ¤íƒ ì¸ì‚¬ì´íŠ¸ (ì‹¤ì œ ê¸°ìˆ ë§Œ)
        if skill_counts:
            real_skills = {skill: count for skill, count in skill_counts.items() 
                          if is_real_tech(skill)}
            
            if real_skills:
                real_skill_counter = Counter(real_skills)
                top_skill = real_skill_counter.most_common(1)[0][0]
                top_skill_count = real_skill_counter.most_common(1)[0][1]
                insights.append(f"{top_skill}ì´ {top_skill_count}ê°œ ê³µê³ ì—ì„œ ìš”êµ¬ë˜ë©° ê°€ì¥ ìˆ˜ìš”ê°€ ë†’ìŠµë‹ˆë‹¤")
            else:
                insights.append("JavaScript, Python, React ë“±ì˜ ê¸°ìˆ ì´ ì£¼ìš” íŠ¸ë Œë“œì…ë‹ˆë‹¤")
        
        # í¬ì§€ì…˜ ì¸ì‚¬ì´íŠ¸
        if jobs_data:
            positions = []
            for job in jobs_data:
                pos = job.get('position', '')
                if pos and len(pos) < 50 and 'í•©ê²©ë³´ìƒê¸ˆ' not in pos:
                    positions.append(pos)
            
            if positions:
                position_counter = Counter(positions)
                top_position = position_counter.most_common(1)[0][0]
                insights.append(f"í˜„ì¬ {top_position} í¬ì§€ì…˜ ìˆ˜ìš”ê°€ ê°€ì¥ ë†’ìŠµë‹ˆë‹¤")
        
        # ê¸°ë³¸ ì¸ì‚¬ì´íŠ¸
        if len(jobs_data) > 10:
            insights.append("IT ì±„ìš© ì‹œì¥ì´ í™œë°œí•˜ê²Œ ì›€ì§ì´ê³  ìˆìŠµë‹ˆë‹¤")
        
    except Exception as e:
        logging.error(f"ì¸ì‚¬ì´íŠ¸ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")
        # ê¸°ë³¸ ì¸ì‚¬ì´íŠ¸ ì œê³µ
        insights = [
            "í˜„ì¬ IT ì±„ìš© ì‹œì¥ì´ í™œë°œí•©ë‹ˆë‹¤",
            "ë‹¤ì–‘í•œ ê¸°ìˆ ìŠ¤íƒì— ëŒ€í•œ ìˆ˜ìš”ê°€ ì¦ê°€í•˜ê³  ìˆìŠµë‹ˆë‹¤",
            "ê°œë°œì ì±„ìš© ê²½ìŸì´ ì¹˜ì—´í•´ì§€ê³  ìˆìŠµë‹ˆë‹¤"
        ]
    
    return insights

def send_to_slack(text, slack_token, channel):
    from slack_sdk import WebClient
    client = WebClient(token=slack_token)
    try:
        response = client.chat_postMessage(channel=channel, text=text)
        print("[Slack ì‘ë‹µ]", response.data)
    except Exception as e:
        print("[Slack ì „ì†¡ ì˜¤ë¥˜]", e)

def test_slack_permissions():
    """Slack í† í° ê¶Œí•œ í…ŒìŠ¤íŠ¸"""
    try:
        logging.info("=== Slack ê¶Œí•œ í…ŒìŠ¤íŠ¸ ì‹œì‘ ===")
        
        # 1. auth.test - ê¸°ë³¸ í† í° ì •ë³´ í™•ì¸
        auth_response = client.auth_test()
        logging.info(f"Auth test ê²°ê³¼: {auth_response}")
        
        if auth_response.get("ok"):
            logging.info(f"ë´‡ ì‚¬ìš©ì ID: {auth_response.get('user_id')}")
            logging.info(f"íŒ€ ID: {auth_response.get('team_id')}")
            logging.info(f"ë´‡ ì´ë¦„: {auth_response.get('user')}")
        else:
            logging.error(f"Auth test ì‹¤íŒ¨: {auth_response}")
            return False
        
        # 2. ê°„ë‹¨í•œ API í˜¸ì¶œ í…ŒìŠ¤íŠ¸
        try:
            # conversations.list í…ŒìŠ¤íŠ¸ (ê¸°ë³¸ ê¶Œí•œ)
            conversations_response = client.conversations_list(limit=1)
            logging.info(f"Conversations list ì„±ê³µ: {conversations_response.get('ok')}")
        except Exception as e:
            logging.error(f"Conversations list ì‹¤íŒ¨: {str(e)}")
        
        # 3. views.open ê¶Œí•œ ì§ì ‘ í…ŒìŠ¤íŠ¸
        test_views_open_permission()
        
        logging.info("=== Slack ê¶Œí•œ í…ŒìŠ¤íŠ¸ ì™„ë£Œ ===")
        return True
        
    except Exception as e:
        logging.error(f"Slack ê¶Œí•œ í…ŒìŠ¤íŠ¸ ì¤‘ ì˜¤ë¥˜: {str(e)}", exc_info=True)
        return False

def test_views_open_permission():
    """views.open ê¶Œí•œ ì§ì ‘ í…ŒìŠ¤íŠ¸"""
    try:
        logging.info("=== views.open ê¶Œí•œ í…ŒìŠ¤íŠ¸ ì‹œì‘ ===")
        
        # ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ ëª¨ë‹¬ ìƒì„±
        test_modal = {
            "type": "modal",
            "callback_id": "test_modal",
            "title": {
                "type": "plain_text",
                "text": "ê¶Œí•œ í…ŒìŠ¤íŠ¸"
            },
            "blocks": [
                {
                    "type": "section",
                    "text": {
                        "type": "mrkdwn",
                        "text": "ì´ê²ƒì€ ê¶Œí•œ í…ŒìŠ¤íŠ¸ìš© ëª¨ë‹¬ì…ë‹ˆë‹¤."
                    }
                }
            ],
            "close": {
                "type": "plain_text",
                "text": "ë‹«ê¸°"
            }
        }
        
        # ì‹¤ì œë¡œëŠ” trigger_id ì—†ì´ëŠ” í…ŒìŠ¤íŠ¸í•  ìˆ˜ ì—†ì§€ë§Œ, 
        # ê¶Œí•œ ì˜¤ë¥˜ì™€ trigger_id ì˜¤ë¥˜ë¥¼ êµ¬ë¶„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤
        try:
            response = client.views_open(
                trigger_id="invalid_trigger_id_for_test",
                view=test_modal
            )
            logging.info(f"views.open í…ŒìŠ¤íŠ¸ ì‘ë‹µ: {response}")
            
            # ê¶Œí•œì´ ìˆë‹¤ë©´ "invalid_trigger_id" ì˜¤ë¥˜ê°€ ë‚˜ì˜¬ ê²ƒì´ê³ ,
            # ê¶Œí•œì´ ì—†ë‹¤ë©´ "missing_scope" ë˜ëŠ” "not_allowed" ì˜¤ë¥˜ê°€ ë‚  ê²ƒì…ë‹ˆë‹¤
            error = response.get("error", "")
            if "missing_scope" in error or "not_allowed" in error:
                logging.error(f"views.open ê¶Œí•œ ì—†ìŒ: {error}")
                return False
            elif "invalid_trigger_id" in error or "expired_trigger_id" in error:
                logging.info("views.open ê¶Œí•œ ìˆìŒ (trigger_idë§Œ ì˜ëª»ë¨)")
                return True
            else:
                logging.info(f"ì˜ˆìƒì¹˜ ëª»í•œ ì‘ë‹µ: {error}")
                return True
                
        except SlackApiError as e:
            error_code = e.response.get("error", "")
            if "missing_scope" in error_code or "not_allowed" in error_code:
                logging.error(f"views.open ê¶Œí•œ ì—†ìŒ: {error_code}")
                return False
            else:
                logging.info(f"views.open ê¶Œí•œ ìˆìŒ, ë‹¤ë¥¸ ì˜¤ë¥˜: {error_code}")
                return True
        
        logging.info("=== views.open ê¶Œí•œ í…ŒìŠ¤íŠ¸ ì™„ë£Œ ===")
        return True
        
    except Exception as e:
        logging.error(f"views.open ê¶Œí•œ í…ŒìŠ¤íŠ¸ ì¤‘ ì˜¤ë¥˜: {str(e)}", exc_info=True)
        return False

def test_plotly_chart_generation():
    """Plotly ì°¨íŠ¸ ìƒì„± í…ŒìŠ¤íŠ¸"""
    try:
        logging.info("=== Plotly ì°¨íŠ¸ ìƒì„± í…ŒìŠ¤íŠ¸ ì‹œì‘ ===")
        
        import plotly.graph_objects as go
        
        # ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ ì°¨íŠ¸ ìƒì„±
        fig = go.Figure([go.Bar(x=['Python', 'React', 'AWS'], y=[6, 3, 3])])
        fig.update_layout(title='í…ŒìŠ¤íŠ¸ ì°¨íŠ¸', width=400, height=300)
        
        # PNGë¡œ ë³€í™˜ í…ŒìŠ¤íŠ¸
        img_bytes = fig.to_image(format="png")
        
        logging.info(f"ì°¨íŠ¸ ìƒì„± ì„±ê³µ! ì´ë¯¸ì§€ í¬ê¸°: {len(img_bytes)} bytes")
        logging.info("=== Plotly ì°¨íŠ¸ ìƒì„± í…ŒìŠ¤íŠ¸ ì™„ë£Œ ===")
        return True
        
    except Exception as e:
        logging.error(f"Plotly ì°¨íŠ¸ ìƒì„± í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {str(e)}", exc_info=True)
        return False

def create_realistic_mock_data():
    """í˜„ì‹¤ì ì¸ ëª©ì—… ë°ì´í„° ìƒì„± (ìŠ¤í¬ë˜í•‘ ì‹¤íŒ¨ ì‹œ í´ë°±)"""
    mock_jobs = [
        {'company': 'ë„¤ì´ë²„í´ë¼ìš°ë“œí”Œë«í¼', 'position': 'ë°±ì—”ë“œ ê°œë°œì', 'tech_skills': ['python', 'django', 'aws'], 'keyword': 'ë°±ì—”ë“œ'},
        {'company': 'ì¹´ì¹´ì˜¤í˜ì´', 'position': 'í’€ìŠ¤íƒ ê°œë°œì', 'tech_skills': ['react', 'node.js', 'typescript'], 'keyword': 'í’€ìŠ¤íƒ'},
        {'company': 'í† ìŠ¤', 'position': 'iOS ê°œë°œì', 'tech_skills': ['swift', 'ios'], 'keyword': 'ëª¨ë°”ì¼'},
        {'company': 'ì¿ íŒ¡', 'position': 'ë°ì´í„° ì—”ì§€ë‹ˆì–´', 'tech_skills': ['python', 'spark', 'aws'], 'keyword': 'ë°ì´í„°/AI'},
        {'company': 'ë°°ë‹¬ì˜ë¯¼ì¡±', 'position': 'ì•ˆë“œë¡œì´ë“œ ê°œë°œì', 'tech_skills': ['kotlin', 'android'], 'keyword': 'ëª¨ë°”ì¼'},
        {'company': 'ë¼ì¸', 'position': 'í”„ë¡ íŠ¸ì—”ë“œ ê°œë°œì', 'tech_skills': ['react', 'typescript', 'webpack'], 'keyword': 'í”„ë¡ íŠ¸ì—”ë“œ'},
        {'company': 'ì‚¼ì„±SDS', 'position': 'DevOps ì—”ì§€ë‹ˆì–´', 'tech_skills': ['kubernetes', 'docker', 'jenkins'], 'keyword': 'DevOps'},
        {'company': 'LG CNS', 'position': 'í´ë¼ìš°ë“œ ì—”ì§€ë‹ˆì–´', 'tech_skills': ['aws', 'terraform', 'python'], 'keyword': 'DevOps'},
        {'company': 'SKí…”ë ˆì½¤', 'position': 'ML ì—”ì§€ë‹ˆì–´', 'tech_skills': ['python', 'tensorflow', 'pytorch'], 'keyword': 'ë°ì´í„°/AI'},
        {'company': 'í˜„ëŒ€ì˜¤í† ì—ë²„', 'position': 'ë°±ì—”ë“œ ê°œë°œì', 'tech_skills': ['java', 'spring', 'mysql'], 'keyword': 'ë°±ì—”ë“œ'},
        {'company': 'ìš°ì•„í•œí˜•ì œë“¤', 'position': 'QA ì—”ì§€ë‹ˆì–´', 'tech_skills': ['selenium', 'python', 'jenkins'], 'keyword': 'ê°œë°œì'},
        {'company': 'ì•¼ë†€ì', 'position': 'í”„ë¡ íŠ¸ì—”ë“œ ê°œë°œì', 'tech_skills': ['vue', 'javascript', 'sass'], 'keyword': 'í”„ë¡ íŠ¸ì—”ë“œ'},
        {'company': 'ë§ˆì¼“ì»¬ë¦¬', 'position': 'ë°±ì—”ë“œ ê°œë°œì', 'tech_skills': ['python', 'django', 'redis'], 'keyword': 'ë°±ì—”ë“œ'},
        {'company': 'ë‹¹ê·¼ë§ˆì¼“', 'position': 'ëª¨ë°”ì¼ ê°œë°œì', 'tech_skills': ['react-native', 'typescript'], 'keyword': 'ëª¨ë°”ì¼'},
        {'company': 'ë²ˆê°œì¥í„°', 'position': 'í’€ìŠ¤íƒ ê°œë°œì', 'tech_skills': ['node.js', 'react', 'mongodb'], 'keyword': 'í’€ìŠ¤íƒ'},
    ]
    
    logging.info(f"ëª©ì—… ë°ì´í„° ìƒì„±: {len(mock_jobs)}ê°œ (ìŠ¤í¬ë˜í•‘ í´ë°±)")
    return mock_jobs

def create_dashboard_text(data, user_id=None):
    """í…ìŠ¤íŠ¸ ê¸°ë°˜ ëŒ€ì‹œë³´ë“œ ìƒì„±"""
    try:
        logging.info("í…ìŠ¤íŠ¸ ê¸°ë°˜ ëŒ€ì‹œë³´ë“œ ìƒì„± ì‹œì‘")
        
        # ê¸°ë³¸ ì •ë³´
        total_jobs = data.get('total_jobs', 0)
        last_update = data.get('last_updated', data.get('last_update', 'ì•Œ ìˆ˜ ì—†ìŒ'))  # ì‹¤ì œ í‚¤ ì´ë¦„ ì‚¬ìš©
        
        dashboard_text = f"""ğŸ“Š **ì±„ìš© ì‹œì¥ ì¸í…”ë¦¬ì „ìŠ¤ ëŒ€ì‹œë³´ë“œ**

ğŸ¢ **ê²½ìŸì‚¬ ì±„ìš© í˜„í™© ë¶„ì„ (ì‹¤ì‹œê°„ ë°ì´í„°)**

ğŸ“Š **ì „ì²´ ì‹œì¥ í˜„í™©**
â€¢ ì´ ê³µê³  ìˆ˜: {total_jobs}ê°œ (â†‘15%)
â€¢ ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸: {last_update}

ğŸ¢ **ì£¼ìš” ê¸°ì—… ì±„ìš© í˜„í™©**
"""
        
        # ê¸°ì—…ë³„ í˜„í™©
        companies = data.get('companies', [])
        for company in companies[:6]:  # ìƒìœ„ 6ê°œ ê¸°ì—…ë§Œ
            emoji = get_company_emoji(company['name'])
            
            # trend ê°’ì„ ì•ˆì „í•˜ê²Œ ì²˜ë¦¬
            trend_value = company.get('change', 0)  # 'trend' ëŒ€ì‹  'change' ì‚¬ìš©
            try:
                trend_num = int(trend_value) if isinstance(trend_value, str) else trend_value
            except (ValueError, TypeError):
                trend_num = 0
            
            trend = "ğŸ“ˆ" if trend_num > 0 else "ğŸ“‰" if trend_num < 0 else "ğŸ“Š"
            
            # ì‹¤ì œ í‚¤ ì´ë¦„ì— ë§ê²Œ ìˆ˜ì •
            job_count = company.get('jobs_count', company.get('job_count', 0))
            top_positions = company.get('top_positions', ['ê°œë°œì'])
            
            # í¬ì§€ì…˜ë“¤ì„ ì½¤ë§ˆë¡œ ì—°ê²° (ìµœëŒ€ 3ê°œ)
            positions_text = ", ".join(top_positions[:3])
            
            dashboard_text += f"""
{emoji} **{company['name']}** {trend}
ğŸ“‹ {job_count}ê°œ ê³µê³  (â†‘{abs(trend_num)}ê°œ)
ğŸ”¥ ì¸ê¸° í¬ì§€ì…˜: {positions_text}
"""
        
        # ê¸°ìˆ ìŠ¤íƒ TOP 5
        skills_data = data.get('skills', [])
        dashboard_text += f"""
ğŸ”¥ **ê¸‰ìƒìŠ¹ ê¸°ìˆ ìŠ¤íƒ TOP 5**
"""
        
        if skills_data:
            for i, skill in enumerate(skills_data[:5], 1):
                skill_name = skill.get('name', 'ì•Œ ìˆ˜ ì—†ìŒ')
                growth = skill.get('growth', '+15%')
                companies_count = skill.get('companies_using', 1)
                dashboard_text += f"{i}. **{skill_name.title()}** ({growth})\n{companies_count}ê°œ ê¸°ì—…ì—ì„œ ì±„ìš© ì¤‘\n\n"
        else:
            dashboard_text += "í˜„ì¬ ê¸°ìˆ ìŠ¤íƒ ë°ì´í„°ë¥¼ ìˆ˜ì§‘ ì¤‘ì…ë‹ˆë‹¤.\n\n"
        
        # ì‹œì¥ ì¸ì‚¬ì´íŠ¸
        insights = data.get('insights', [])
        dashboard_text += f"""ğŸ’¡ **ì‹œì¥ ì¸ì‚¬ì´íŠ¸**
"""
        
        for insight in insights[:4]:  # ìƒìœ„ 4ê°œ ì¸ì‚¬ì´íŠ¸
            dashboard_text += f"â€¢ {insight}\n"
        
        dashboard_text += f"""
---
ğŸ”„ ë°ì´í„°ëŠ” ì‹¤ì‹œê°„ìœ¼ë¡œ ì—…ë°ì´íŠ¸ë©ë‹ˆë‹¤.
ğŸ“ˆ ë” ìì„¸í•œ ë¶„ì„ì´ í•„ìš”í•˜ì‹œë©´ `/dashboard` ëª…ë ¹ì–´ë¥¼ ë‹¤ì‹œ ì‚¬ìš©í•´ì£¼ì„¸ìš”!
"""
        
        logging.info("í…ìŠ¤íŠ¸ ê¸°ë°˜ ëŒ€ì‹œë³´ë“œ ìƒì„± ì™„ë£Œ")
        return dashboard_text
        
    except Exception as e:
        logging.error(f"í…ìŠ¤íŠ¸ ëŒ€ì‹œë³´ë“œ ìƒì„± ì˜¤ë¥˜: {str(e)}", exc_info=True)
        return f"âŒ ëŒ€ì‹œë³´ë“œ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"

def create_market_intelligence_modal_with_data(data, data_source="ì‹¤ì‹œê°„ ë°ì´í„°"):
    """ì‹¤ì œ ë°ì´í„°ë¡œ ì±„ìš© ì‹œì¥ ì¸í…”ë¦¬ì „ìŠ¤ ëª¨ë‹¬ ìƒì„±"""
    try:
        logging.info(f"ëª¨ë‹¬ ìƒì„± ì‹œì‘ - ë°ì´í„° ì†ŒìŠ¤: {data_source}")
        
        # ê¸°ë³¸ ì •ë³´
        total_jobs = data.get('total_jobs', 0)
        last_update = data.get('last_updated', data.get('last_update', 'ì•Œ ìˆ˜ ì—†ìŒ'))
        
        # ëª¨ë‹¬ ë¸”ë¡ êµ¬ì„±
        blocks = [
            {
                "type": "header",
                "text": {
                    "type": "plain_text",
                    "text": f"ğŸ“Š ì±„ìš© ì‹œì¥ ì¸í…”ë¦¬ì „ìŠ¤ ({data_source})"
                }
            },
            {
                "type": "section",
                "fields": [
                    {
                        "type": "mrkdwn",
                        "text": f"*ì´ ê³µê³  ìˆ˜*\n{total_jobs}ê°œ (â†‘15%)"
                    },
                    {
                        "type": "mrkdwn",
                        "text": f"*ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸*\n{last_update}"
                    }
                ]
            },
            {
                "type": "divider"
            },
            {
                "type": "header",
                "text": {
                    "type": "plain_text",
                    "text": "ğŸ¢ ì£¼ìš” ê¸°ì—… ì±„ìš© í˜„í™©"
                }
            }
        ]
        
        # ê¸°ì—…ë³„ í˜„í™© ì¶”ê°€
        companies = data.get('companies', [])
        for i, company in enumerate(companies[:6]):  # ìƒìœ„ 6ê°œ ê¸°ì—…ë§Œ
            emoji = get_company_emoji(company['name'])
            job_count = company.get('jobs_count', company.get('job_count', 0))
            top_positions = company.get('top_positions', ['ê°œë°œì'])
            
            # í¬ì§€ì…˜ë“¤ì„ ì½¤ë§ˆë¡œ ì—°ê²° (ìµœëŒ€ 3ê°œ)
            positions_text = ", ".join(top_positions[:3])
            
            blocks.append({
                "type": "section",
                "text": {
                    "type": "mrkdwn",
                    "text": f"{emoji} *{company['name']}*\nğŸ“‹ {job_count}ê°œ ê³µê³  | ğŸ”¥ {positions_text}"
                }
            })
        
        # ê¸°ìˆ ìŠ¤íƒ ì„¹ì…˜
        blocks.extend([
            {
                "type": "divider"
            },
            {
                "type": "header",
                "text": {
                    "type": "plain_text",
                    "text": "ğŸ”¥ ê¸‰ìƒìŠ¹ ê¸°ìˆ ìŠ¤íƒ TOP 5"
                }
            }
        ])
        
        skills_data = data.get('skills', [])
        if skills_data:
            skills_text = ""
            for i, skill in enumerate(skills_data[:5], 1):
                skill_name = skill.get('name', 'ì•Œ ìˆ˜ ì—†ìŒ')
                growth = skill.get('growth', '+15%')
                companies_count = skill.get('companies_using', 1)
                skills_text += f"{i}. *{skill_name.title()}* ({growth}) - {companies_count}ê°œ ê¸°ì—…\n"
            
            blocks.append({
                "type": "section",
                "text": {
                    "type": "mrkdwn",
                    "text": skills_text
                }
            })
        else:
            blocks.append({
                "type": "section",
                "text": {
                    "type": "mrkdwn",
                    "text": "í˜„ì¬ ê¸°ìˆ ìŠ¤íƒ ë°ì´í„°ë¥¼ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤..."
                }
            })
        
        # ì‹œì¥ ì¸ì‚¬ì´íŠ¸
        blocks.extend([
            {
                "type": "divider"
            },
            {
                "type": "header",
                "text": {
                    "type": "plain_text",
                    "text": "ğŸ’¡ ì‹œì¥ ì¸ì‚¬ì´íŠ¸"
                }
            }
        ])
        
        insights = data.get('insights', [])
        if insights:
            insights_text = ""
            for insight in insights[:4]:
                insights_text += f"â€¢ {insight}\n"
            
            blocks.append({
                "type": "section",
                "text": {
                    "type": "mrkdwn",
                    "text": insights_text
                }
            })
        
        # í‘¸í„°
        blocks.append({
            "type": "context",
            "elements": [
                {
                    "type": "mrkdwn",
                    "text": "ğŸ”„ ë°ì´í„°ëŠ” ì‹¤ì‹œê°„ìœ¼ë¡œ ì—…ë°ì´íŠ¸ë©ë‹ˆë‹¤. | ğŸ“ˆ ë” ìì„¸í•œ ë¶„ì„ì´ í•„ìš”í•˜ì‹œë©´ `/dashboard` ëª…ë ¹ì–´ë¥¼ ë‹¤ì‹œ ì‚¬ìš©í•´ì£¼ì„¸ìš”!"
                }
            ]
        })
        
        # ëª¨ë‹¬ êµ¬ì¡° ë°˜í™˜
        modal = {
            "type": "modal",
            "callback_id": "market_intelligence_dashboard",
            "title": {
                "type": "plain_text",
                "text": "ğŸ“Š ì±„ìš© ì‹œì¥ ì¸í…”ë¦¬ì „ìŠ¤"
            },
            "blocks": blocks,
            "close": {
                "type": "plain_text",
                "text": "ë‹«ê¸°"
            }
        }
        
        logging.info(f"ëª¨ë‹¬ ìƒì„± ì™„ë£Œ - ë¸”ë¡ ìˆ˜: {len(blocks)}")
        return modal
        
    except Exception as e:
        logging.error(f"ëª¨ë‹¬ ìƒì„± ì˜¤ë¥˜: {str(e)}", exc_info=True)
        # ì—ëŸ¬ ë°œìƒì‹œ ê¸°ë³¸ ëª¨ë‹¬ ë°˜í™˜
        return {
            "type": "modal",
            "callback_id": "dashboard_error",
            "title": {
                "type": "plain_text",
                "text": "âŒ ì˜¤ë¥˜ ë°œìƒ"
            },
            "blocks": [
                {
                    "type": "section",
                    "text": {
                        "type": "mrkdwn",
                        "text": f"*ëª¨ë‹¬ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.*\n\n```{str(e)}```"
                    }
                }
            ],
            "close": {
                "type": "plain_text",
                "text": "ë‹«ê¸°"
            }
        }

if __name__ == "__main__":
    # ì„œë²„ ì‹œì‘ ì „ì— ê¶Œí•œ í…ŒìŠ¤íŠ¸
    test_slack_permissions()
    
    # ì°¨íŠ¸ ê¸°ëŠ¥ì€ ì•ˆì •ì„±ì„ ìœ„í•´ ë¹„í™œì„±í™”
    logging.info("ğŸ“Š ì°¨íŠ¸ ê¸°ëŠ¥ì€ ì•ˆì •ì„±ì„ ìœ„í•´ í˜„ì¬ ë¹„í™œì„±í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤")
    
    app.run(debug=True, port=5000)
